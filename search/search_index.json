{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"welcome/","text":"About Gtz4All \u00b6","title":"Welcome"},{"location":"welcome/#about-gtz4all","text":"","title":"About Gtz4All"},{"location":"cloud/intro/","text":"AWS Documentation AWS is currently the leading cloud provider. Azure Documentation Azure is currently the leading cloud provider. GCP Documentation GCP is currently the leading cloud provider.","title":"Introduction"},{"location":"cloud/aws/default-vpc-cleanup/","text":"Delete DefaultVPC Lambda \u00b6 This lambda is used to delete all DefaultVPCs and their resources in every region * Log all work * push to BD for historical reference IAM Roles \u00b6 In order to provide this solution we need to create IAM roles in both core and child account. Core Network Lambda Role \u00b6 Access DynamoDB Table 'DefaultVPC_Cleanup' used for inventory purposes. Allows lambda to assume role 'core-network-delete-defaultvpc-lambda-role' on other accounts Logging core-network-delete-defaultvpc-lambda-policy \u00b6 { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"DefaultVPCCleanupDB\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"dynamodb:DeleteItem\" , \"dynamodb:PutItem\" , \"dynamodb:UpdateItem\" ], \"Resource\" : \"arn:aws:dynamodb:us-east-1:860014166701:table/DefaultVPC_Cleanup\" }, { \"Sid\" : \"SwitchRole\" , \"Effect\" : \"Allow\" , \"Action\" : \"sts:AssumeRole\" , \"Resource\" : [ \"arn:aws:iam::*:role/core-network-delete-defaultvpc-lambda-role\" , \"arn:aws:iam::*:role/core-network-restricted-access-lambda-role\" ] }, { \"Sid\" : \"Logging\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"logs:CreateLogGroup\" , \"logs:PutLogEvents\" ], \"Resource\" : \"*\" } ] } Trust Relationship \u00b6 { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Action\" : \"sts:AssumeRole\" } ] } Lambda \u00b6 import sys import boto3 import botocore import json import requests from datetime import datetime from botocore.exceptions import ClientError # a way to print messages - VERBOSE = 0 will not print messages VERBOSE = 1 DeleteDefaultVpcDB = 'DefaultVPC_Cleanup' print ( 'Loading function ' + datetime . now () . time () . isoformat ()) def lambda_handler ( event , context ): print ( event ) # API Gateway Response response = { \"statusCode\" : 200 , \"headers\" : { \"Access-Control-Allow-Origin\" : \"*\" , \"Content-Type\" : \"application/json;\" , }, \"isBase64Encoded\" : False } if \"FormAwsAcct\" in event [ 'queryStringParameters' ]: #get Org Accounts getOrgAccounts = requests . get ( 'https://7bzbqo4224.execute-api.us-east-1.amazonaws.com/Production/listaccounts' ) OrgAccountsDB = getOrgAccounts . json () #print(OrgAccountsDB) for account in OrgAccountsDB : print ( 'Validating Account: ' + event [ 'queryStringParameters' ][ 'FormAwsAcct' ]) #print(account['Id']) #print(event['queryStringParameters']['FormAwsAcct']) if account [ 'Id' ] == event [ 'queryStringParameters' ][ 'FormAwsAcct' ]: account_id = event [ 'queryStringParameters' ][ 'FormAwsAcct' ] role_id = event [ 'queryStringParameters' ][ 'FormSwitchRole' ] region_id = 'us-east-1' type_id = 'ec2' # get account regions ec2 , client = switch_role ( account_id , role_id , region_id , type_id ) regions = get_regions ( client ) account_list = {} account_list [ 'AccountCleanup' ] = {} account_list [ 'AccountId' ] = account_id account_list [ 'DateTime' ] = datetime . now () . strftime ( \" %d -%m-%Y %H:%M:%S\" ) for region in regions : #if region == 'us-east-1': print ( region ) account_list [ region ] = {} try : ec2 , client = switch_role ( account_id , role_id , region , type_id ) vpcs = get_default_vpcs ( client ) print ( vpcs ) except ClientError as e : #print(e.response['Error']['Message'] + 'this is my msg test' + \"\\n\") ## for any errors add a dynamodb tab with the error msg per region account_list [ 'AccountCleanup' ][ region ] = ( 'GetDefaultVpc: ' + ( e . response [ 'Error' ][ 'Message' ])) continue #else: if ( vpcs ): #print(vpcs) for vpc in vpcs : #print(vpc) print ( \"REGION:\" + region + \" - \" + \"DefaultVPC Id: \" + vpc ) account_list [ region ][ 'DefaultVpcId' ] = ( vpc ) igw = del_igw ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcIgw' ] = ( igw ) subnets = del_sub ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcSubnets' ] = ( subnets ) rtb = del_rtb ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcRouteTable' ] = ( rtb ) rtb_acls = del_acl ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcRouteTableAcls' ] = ( rtb_acls ) secgroups = del_sgp ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcSecurityGroups' ] = ( secgroups ) cleanup = del_vpc ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcCleanup' ] = ( cleanup ) if ( 'Deleted Successfully' in account_list [ region ][ 'DefaultVpcCleanup' ]): account_list [ 'AccountCleanup' ][ region ] = 'Complete' else : account_list [ 'AccountCleanup' ][ region ] = 'Incomplete' else : print ( \"REGION:\" + region + \" - \" + \"DefaultVPC Id: \" + 'None' + \" \\n \" ) account_list [ region ] = { 'DefaultVpcId' : 'None' } account_list [ 'AccountCleanup' ][ region ] = 'Complete' # update DynamoDB Tables AccountList_dump = json . dumps ( account_list ) AccountList = json . loads ( AccountList_dump ) table = boto3 . resource ( 'dynamodb' ) . Table ( DeleteDefaultVpcDB ) table . put_item ( Item = AccountList ) response [ 'body' ] = ( AccountList_dump ) print ( response ) return ( response ) break else : response [ 'body' ] = ( '<p style=\"text-align: center;\">You have provided an invalid BCH Managed AWS Account. Please resubmit your request - <a href=\"http://websvc4:8090/display/AWS/Default+VPC+Removal+Webform\" target=\"_blank\">BCH AWS Default VPC Removal Webform.</a></p>' ) print ( response ) return ( response ) #update DynamoDB Tables #AccountList_dump = json.dumps(account_list) #AccountList = json.loads(AccountList_dump) #table = boto3.resource('dynamodb').Table(DeleteDefaultVpcDB) #table.put_item(Item = AccountList) #response['body'] = (AccountList_dump) #return(response) def switch_role ( acct , role , region , type ): ''' acct = aws_account# role = assume_role_name region = assume_role_region type = service type, ie ec2,s3 ''' ## some services have 'resource' resource_type = [ \"cloudformation\" , \"cloudwatch\" , \"dynamodb\" , \"ec2\" , \"glacier\" , \"iam\" , \"opsworks\" , \"s3\" , \"sns\" , \"sqs\" ] role_arn = \"arn:aws:iam:: %s :role/ %s \" % ( acct , role ) sts_connection = boto3 . client ( 'sts' ) try : assume_role = sts_connection . assume_role ( RoleArn = role_arn , RoleSessionName = \"switch_role_session\" ) except ClientError as e : print ( e . response [ 'Error' ][ 'Message' ]) sys . exit ( 1 ) try : access_key = assume_role [ 'Credentials' ][ 'AccessKeyId' ] secret_key = assume_role [ 'Credentials' ][ 'SecretAccessKey' ] session_token = assume_role [ 'Credentials' ][ 'SessionToken' ] # Creates services using Assumed role credentials if type in resource_type : resource_creds = boto3 . resource ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) client_creds = boto3 . client ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) else : resource_creds = 'none' client_creds = boto3 . client ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( resource_creds , client_creds ) def get_regions ( client ): \"\"\" Build a region list \"\"\" reg_list = [] regions = client . describe_regions () #print(regions) data_str = json . dumps ( regions ) resp = json . loads ( data_str ) region_str = json . dumps ( resp [ 'Regions' ]) region = json . loads ( region_str ) for reg in region : reg_list . append ( reg [ 'RegionName' ]) #print (reg_list) return reg_list def get_default_vpcs ( client ): vpc_list = [] vpcs = client . describe_vpcs ( Filters = [ { 'Name' : 'isDefault' , 'Values' : [ 'true' , ], }, ] ) vpcs_str = json . dumps ( vpcs ) resp = json . loads ( vpcs_str ) data = json . dumps ( resp [ 'Vpcs' ]) vpcs = json . loads ( data ) for vpc in vpcs : vpc_list . append ( vpc [ 'VpcId' ]) return vpc_list def del_igw ( ec2 , vpcid ): \"\"\" Detach and delete the internet-gateway \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) igws = vpc_resource . internet_gateways . all () if igws : for igw in igws : try : print ( \"Detaching and Removing igw-id: \" , igw . id ) if ( VERBOSE == 1 ) else \"\" igw . detach_from_vpc ( VpcId = vpcid ) igw . delete ( #DryRun=True ) return ( igw . id + ': detached and deleted' ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) #else: # return(vpcid + \": no IGW attached\") def del_sub ( ec2 , vpcid ): \"\"\" Delete the subnets \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) subnets = vpc_resource . subnets . all () vpc_subnets = [ ec2 . Subnet ( subnet . id ) for subnet in subnets ] if vpc_subnets : subnets = [] try : for sub in vpc_subnets : print ( \"Removing sub-id: \" , sub . id ) if ( VERBOSE == 1 ) else \"\" subnets . append ( sub . id ) sub . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( subnets ) def del_rtb ( ec2 , vpcid ): \"\"\" Delete the route-tables \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) rtbs = vpc_resource . route_tables . all () if rtbs : rtables = [] try : for rtb in rtbs : if ( rtb . associations_attribute ): if ( rtb . associations_attribute [ 0 ][ 'Main' ] == True ): print ( rtb . id + \" is the main route table, continue...\" ) if ( VERBOSE == 1 ) else \"\" rtables . append ( 'main route table: ' + rtb . id ) continue else : print ( \"Removing rtb-id: \" , rtb . id ) if ( VERBOSE == 1 ) else \"\" rtables . append ( rtb . id ) table = ec2 . RouteTable ( rtb . id ) table . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( rtables ) def del_acl ( ec2 , vpcid ): \"\"\" Delete the network-access-lists \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) acls = vpc_resource . network_acls . all () if acls : rtable_acls = [] try : for acl in acls : if acl . is_default : print ( acl . id + \" is the default NACL, continue...\" ) if ( VERBOSE == 1 ) else \"\" rtable_acls . append ( 'default_acl: ' + acl . id ) continue else : print ( \"Removing acl-id: \" , acl . id ) if ( VERBOSE == 1 ) else \"\" rtable_acls . append ( acl . id ) acl . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( rtable_acls ) def del_sgp ( ec2 , vpcid ): \"\"\" Delete any security-groups \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) sgps = vpc_resource . security_groups . all () if sgps : sgps_list = [] try : for sg in sgps : if sg . group_name == 'default' : print ( sg . id + \" is the default security group, continue...\" ) if ( VERBOSE == 1 ) else \"\" sgps_list . append ( 'default_security_group: ' + sg . id ) continue else : print ( \"Removing sg-id: \" , sg . id ) if ( VERBOSE == 1 ) else \"\" sgps_list . append ( sg . id ) sg . delete ( # DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( sgps_list ) def del_vpc ( ec2 , vpcid ): \"\"\" Delete the VPC \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) try : print ( \"Removing vpc-id: \" , vpc_resource . id ) vpc_resource . delete ( # DryRun=True ) return ( vpc_resource . id + ' Deleted Successfully.' ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) print ( \"Please remove dependencies and delete VPC manually.\" ) Confluence Webform \u00b6 Default VPC Removal Webform \u00b6 HTML/JavaScript \u00b6 < div > <!--- Submitted Animation--> < div class = \"aui\" id = \"spinner\" style = \"display: none\" > < aui-spinner size = \"large\" ></ aui-spinner > < div class = \"aui\" id = \"ClonfluenceUserName\" ></ div > < div class = \"aui\" id = \"ClonfluenceUserId\" ></ div > < p > Your request is being processed...Please wait </ p > </ div > <!--- Submitted Animation--> <!--- Webform--> < form class = \"aui\" id = \"RequestForm\" style = \"margin: 40px;\" > < h3 style = \"text-align: center;\" > AWS Account Default VPC Deletion Form </ h3 > < p style = \"text-align: center;\" > Please fill in this form to delete Default VPCs from an AWS Account. in the < a href = \"http://websvc4:8090/display/AWS/BCH+Cloud+Standard+Offerings\" target = \"_blank\" > BCH AWS Organization. </ a ></ p > < label for = \"fname\" > AWS Account Number </ label > < input type = \"text\" id = \"aws_acct\" name = \"FormAwsAcct\" placeholder = \"Valid AWS Account Number\" required > < label for = \"lname\" > AWS Switch Role </ label > < input type = \"text\" id = \"switch_role\" name = \"FormSwitchRole\" placeholder = \"AWS Assume Role - core-network-restricted-access-lambda-role\" required > < label for = \"email\" > Email Address </ label > < input type = \"text\" id = \"email\" name = \"FormEmail\" placeholder = \"Requester BCH Email Address - This is not currently being used but it is a required field\" required > < button class = \"aui-button aui-button-primary\" type = \"button\" id = \"button-spin-2\" onclick = \"runAPIGetRequest()\" > Submit </ button > < p >< small > When you click the \"Submit\" button, an API Call will be made with the information you've provided. If you need any assistance, please reach out to the BCH Cloud Team. </ small ></ p > </ form > <!--- Webform--> <!--- Response Placeholder--> < div class = \"aui\" id = \"submittedMsg\" ></ div > <!--- Response Placeholder--> </ div > < script type = \"text/javascript\" > //Get Information from confluence var UserName = AJS . params . userDisplayName ; var UserId = AJS . params . remoteUser . toUpperCase (); //alert(AJS.Meta.get(\"user-display-name\")); //alert(AJS.Meta.get(\"remote-user\")); function checkRequired () { var i , GetInputs , allowSubmit ; allowSubmit = true ; GetInputs = document . getElementsByTagName ( 'input' ); for ( i = 0 ; i < GetInputs . length ; i += 1 ) { if ( GetInputs [ i ]. hasAttribute ( 'required' )){ if (( GetInputs [ i ]. value == null ) || ( GetInputs [ i ]. value == \"\" )) { GetInputs [ i ]. style . backgroundColor = \"#e6f2ff\" ; allowSubmit = false ; console . log ( \"checkRequired():\" + \"Name:\" + GetInputs [ i ]. name + \" Missing: \" + GetInputs [ i ]. placeholder ) } else { GetInputs [ i ]. style . backgroundColor = \"#ffffff\" ; console . log ( \"checkRequired():\" + \"Name:\" + GetInputs [ i ]. name + \" Type: \" + GetInputs [ i ]. type . toLowerCase () + \" Value: \" + GetInputs [ i ]. value ) } } } return allowSubmit ; } function buildParms () { var GetInputs ; var i ; var parms , tok , parms = \"\" ; GetInputs = document . getElementsByTagName ( 'input' ); for ( i = 0 ; i < GetInputs . length ; i += 1 ) { if ( parms === \"\" ) { tok = \"?\" ;} else { tok = \"&\" ;} parms = parms + tok + GetInputs [ i ]. name + \"=\" + encodeURIComponent ( GetInputs [ i ]. value ); console . log ( GetInputs [ i ]. name + \"=\" + encodeURIComponent ( GetInputs [ i ]. value )); } console . log ( parms ); return parms ; } function runAPIGetRequest () { if ( checkRequired ()) { // Public API DNS Names //myAPI = \"https://609k7k2nn4.execute-api.us-east-1.amazonaws.com/core/getjson\" //myAPI = \"https://609k7k2nn4.execute-api.us-east-1.amazonaws.com/core/defaultvpcremoval\" // Private API DNS Names //myAPI = \"https://609k7k2nn4-vpce-0897455697c88d3cd.execute-api.us-east-1.amazonaws.com/core/getjson\" myAPI = \"https://609k7k2nn4-vpce-0897455697c88d3cd.execute-api.us-east-1.amazonaws.com/core/defaultvpcremoval\" formParms = \"\" ; formParms = buildParms (); // adding Confluence Information formParms = ( formParms + \"&\" + \"UserName\" + \"=\" + UserName + \"&\" + \"UserId\" + \"=\" + UserId ) document . getElementById ( \"RequestForm\" ). style . display = \"none\" ; // hide buttons document . getElementById ( \"spinner\" ). style . display = \"block\" ; // submitted animation document . getElementById ( \"ClonfluenceUserName\" ). innerHTML = UserName document . getElementById ( \"ClonfluenceUserId\" ). innerHTML = UserId var urlWithParms = myAPI + formParms ; xmlhttp = new XMLHttpRequest (); xmlhttp . open ( \"GET\" , urlWithParms , true ); xmlhttp . send (); xmlhttp . onreadystatechange = function () { if ( xmlhttp . readyState == 4 && xmlhttp . status == 200 ) { document . getElementById ( \"submittedMsg\" ). innerHTML = xmlhttp . responseText ; document . getElementById ( \"spinner\" ). style . display = \"none\" ; // submitted animation } else if ( xmlhttp . status != 200 ) { document . getElementById ( \"submittedMsg\" ). innerHTML = '<h6 style=\"color: #e63900; font-weight: bold;\" > There was an issue with your request. Please reach out to BCH Cloud Team</h6>' ; document . getElementById ( \"spinner\" ). style . display = \"none\" ; // submitted animation } }; } } </ script > CSS \u00b6 ```CSS .sectionMacroRow form{ border-radius: 5px; width: 800px; padding: 20px; -moz-box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); -webkit-box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); } .sectionMacroRow form input[type=text], select { width: 100%; padding: 12px 20px; margin: 8px 0; display: block; border: 1px solid #ccc; border-radius: 4px; box-sizing: border-box; } .sectionMacroRow form input[type=submit] { width: 100%; background-color: #42526e; color: white; padding: 14px 20px; margin: 8px 0; display: block; text-align: center; border: 3px solid #deebff; border-radius: 4px; cursor: pointer; } .sectionMacroRow form input[type=submit]:hover { background-color: #0049b0; } ```","title":"Default Vpc Cleanup"},{"location":"cloud/aws/default-vpc-cleanup/#delete-defaultvpc-lambda","text":"This lambda is used to delete all DefaultVPCs and their resources in every region * Log all work * push to BD for historical reference","title":"Delete DefaultVPC Lambda"},{"location":"cloud/aws/default-vpc-cleanup/#iam-roles","text":"In order to provide this solution we need to create IAM roles in both core and child account.","title":"IAM Roles"},{"location":"cloud/aws/default-vpc-cleanup/#core-network-lambda-role","text":"Access DynamoDB Table 'DefaultVPC_Cleanup' used for inventory purposes. Allows lambda to assume role 'core-network-delete-defaultvpc-lambda-role' on other accounts Logging","title":"Core Network  Lambda Role"},{"location":"cloud/aws/default-vpc-cleanup/#core-network-delete-defaultvpc-lambda-policy","text":"{ \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"DefaultVPCCleanupDB\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"dynamodb:DeleteItem\" , \"dynamodb:PutItem\" , \"dynamodb:UpdateItem\" ], \"Resource\" : \"arn:aws:dynamodb:us-east-1:860014166701:table/DefaultVPC_Cleanup\" }, { \"Sid\" : \"SwitchRole\" , \"Effect\" : \"Allow\" , \"Action\" : \"sts:AssumeRole\" , \"Resource\" : [ \"arn:aws:iam::*:role/core-network-delete-defaultvpc-lambda-role\" , \"arn:aws:iam::*:role/core-network-restricted-access-lambda-role\" ] }, { \"Sid\" : \"Logging\" , \"Effect\" : \"Allow\" , \"Action\" : [ \"logs:CreateLogGroup\" , \"logs:PutLogEvents\" ], \"Resource\" : \"*\" } ] }","title":"core-network-delete-defaultvpc-lambda-policy"},{"location":"cloud/aws/default-vpc-cleanup/#trust-relationship","text":"{ \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Effect\" : \"Allow\" , \"Principal\" : { \"Service\" : \"lambda.amazonaws.com\" }, \"Action\" : \"sts:AssumeRole\" } ] }","title":"Trust Relationship"},{"location":"cloud/aws/default-vpc-cleanup/#lambda","text":"import sys import boto3 import botocore import json import requests from datetime import datetime from botocore.exceptions import ClientError # a way to print messages - VERBOSE = 0 will not print messages VERBOSE = 1 DeleteDefaultVpcDB = 'DefaultVPC_Cleanup' print ( 'Loading function ' + datetime . now () . time () . isoformat ()) def lambda_handler ( event , context ): print ( event ) # API Gateway Response response = { \"statusCode\" : 200 , \"headers\" : { \"Access-Control-Allow-Origin\" : \"*\" , \"Content-Type\" : \"application/json;\" , }, \"isBase64Encoded\" : False } if \"FormAwsAcct\" in event [ 'queryStringParameters' ]: #get Org Accounts getOrgAccounts = requests . get ( 'https://7bzbqo4224.execute-api.us-east-1.amazonaws.com/Production/listaccounts' ) OrgAccountsDB = getOrgAccounts . json () #print(OrgAccountsDB) for account in OrgAccountsDB : print ( 'Validating Account: ' + event [ 'queryStringParameters' ][ 'FormAwsAcct' ]) #print(account['Id']) #print(event['queryStringParameters']['FormAwsAcct']) if account [ 'Id' ] == event [ 'queryStringParameters' ][ 'FormAwsAcct' ]: account_id = event [ 'queryStringParameters' ][ 'FormAwsAcct' ] role_id = event [ 'queryStringParameters' ][ 'FormSwitchRole' ] region_id = 'us-east-1' type_id = 'ec2' # get account regions ec2 , client = switch_role ( account_id , role_id , region_id , type_id ) regions = get_regions ( client ) account_list = {} account_list [ 'AccountCleanup' ] = {} account_list [ 'AccountId' ] = account_id account_list [ 'DateTime' ] = datetime . now () . strftime ( \" %d -%m-%Y %H:%M:%S\" ) for region in regions : #if region == 'us-east-1': print ( region ) account_list [ region ] = {} try : ec2 , client = switch_role ( account_id , role_id , region , type_id ) vpcs = get_default_vpcs ( client ) print ( vpcs ) except ClientError as e : #print(e.response['Error']['Message'] + 'this is my msg test' + \"\\n\") ## for any errors add a dynamodb tab with the error msg per region account_list [ 'AccountCleanup' ][ region ] = ( 'GetDefaultVpc: ' + ( e . response [ 'Error' ][ 'Message' ])) continue #else: if ( vpcs ): #print(vpcs) for vpc in vpcs : #print(vpc) print ( \"REGION:\" + region + \" - \" + \"DefaultVPC Id: \" + vpc ) account_list [ region ][ 'DefaultVpcId' ] = ( vpc ) igw = del_igw ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcIgw' ] = ( igw ) subnets = del_sub ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcSubnets' ] = ( subnets ) rtb = del_rtb ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcRouteTable' ] = ( rtb ) rtb_acls = del_acl ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcRouteTableAcls' ] = ( rtb_acls ) secgroups = del_sgp ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcSecurityGroups' ] = ( secgroups ) cleanup = del_vpc ( ec2 , vpc ) account_list [ region ][ 'DefaultVpcCleanup' ] = ( cleanup ) if ( 'Deleted Successfully' in account_list [ region ][ 'DefaultVpcCleanup' ]): account_list [ 'AccountCleanup' ][ region ] = 'Complete' else : account_list [ 'AccountCleanup' ][ region ] = 'Incomplete' else : print ( \"REGION:\" + region + \" - \" + \"DefaultVPC Id: \" + 'None' + \" \\n \" ) account_list [ region ] = { 'DefaultVpcId' : 'None' } account_list [ 'AccountCleanup' ][ region ] = 'Complete' # update DynamoDB Tables AccountList_dump = json . dumps ( account_list ) AccountList = json . loads ( AccountList_dump ) table = boto3 . resource ( 'dynamodb' ) . Table ( DeleteDefaultVpcDB ) table . put_item ( Item = AccountList ) response [ 'body' ] = ( AccountList_dump ) print ( response ) return ( response ) break else : response [ 'body' ] = ( '<p style=\"text-align: center;\">You have provided an invalid BCH Managed AWS Account. Please resubmit your request - <a href=\"http://websvc4:8090/display/AWS/Default+VPC+Removal+Webform\" target=\"_blank\">BCH AWS Default VPC Removal Webform.</a></p>' ) print ( response ) return ( response ) #update DynamoDB Tables #AccountList_dump = json.dumps(account_list) #AccountList = json.loads(AccountList_dump) #table = boto3.resource('dynamodb').Table(DeleteDefaultVpcDB) #table.put_item(Item = AccountList) #response['body'] = (AccountList_dump) #return(response) def switch_role ( acct , role , region , type ): ''' acct = aws_account# role = assume_role_name region = assume_role_region type = service type, ie ec2,s3 ''' ## some services have 'resource' resource_type = [ \"cloudformation\" , \"cloudwatch\" , \"dynamodb\" , \"ec2\" , \"glacier\" , \"iam\" , \"opsworks\" , \"s3\" , \"sns\" , \"sqs\" ] role_arn = \"arn:aws:iam:: %s :role/ %s \" % ( acct , role ) sts_connection = boto3 . client ( 'sts' ) try : assume_role = sts_connection . assume_role ( RoleArn = role_arn , RoleSessionName = \"switch_role_session\" ) except ClientError as e : print ( e . response [ 'Error' ][ 'Message' ]) sys . exit ( 1 ) try : access_key = assume_role [ 'Credentials' ][ 'AccessKeyId' ] secret_key = assume_role [ 'Credentials' ][ 'SecretAccessKey' ] session_token = assume_role [ 'Credentials' ][ 'SessionToken' ] # Creates services using Assumed role credentials if type in resource_type : resource_creds = boto3 . resource ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) client_creds = boto3 . client ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) else : resource_creds = 'none' client_creds = boto3 . client ( type , aws_access_key_id = access_key , aws_secret_access_key = secret_key , aws_session_token = session_token , region_name = region ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( resource_creds , client_creds ) def get_regions ( client ): \"\"\" Build a region list \"\"\" reg_list = [] regions = client . describe_regions () #print(regions) data_str = json . dumps ( regions ) resp = json . loads ( data_str ) region_str = json . dumps ( resp [ 'Regions' ]) region = json . loads ( region_str ) for reg in region : reg_list . append ( reg [ 'RegionName' ]) #print (reg_list) return reg_list def get_default_vpcs ( client ): vpc_list = [] vpcs = client . describe_vpcs ( Filters = [ { 'Name' : 'isDefault' , 'Values' : [ 'true' , ], }, ] ) vpcs_str = json . dumps ( vpcs ) resp = json . loads ( vpcs_str ) data = json . dumps ( resp [ 'Vpcs' ]) vpcs = json . loads ( data ) for vpc in vpcs : vpc_list . append ( vpc [ 'VpcId' ]) return vpc_list def del_igw ( ec2 , vpcid ): \"\"\" Detach and delete the internet-gateway \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) igws = vpc_resource . internet_gateways . all () if igws : for igw in igws : try : print ( \"Detaching and Removing igw-id: \" , igw . id ) if ( VERBOSE == 1 ) else \"\" igw . detach_from_vpc ( VpcId = vpcid ) igw . delete ( #DryRun=True ) return ( igw . id + ': detached and deleted' ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) #else: # return(vpcid + \": no IGW attached\") def del_sub ( ec2 , vpcid ): \"\"\" Delete the subnets \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) subnets = vpc_resource . subnets . all () vpc_subnets = [ ec2 . Subnet ( subnet . id ) for subnet in subnets ] if vpc_subnets : subnets = [] try : for sub in vpc_subnets : print ( \"Removing sub-id: \" , sub . id ) if ( VERBOSE == 1 ) else \"\" subnets . append ( sub . id ) sub . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( subnets ) def del_rtb ( ec2 , vpcid ): \"\"\" Delete the route-tables \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) rtbs = vpc_resource . route_tables . all () if rtbs : rtables = [] try : for rtb in rtbs : if ( rtb . associations_attribute ): if ( rtb . associations_attribute [ 0 ][ 'Main' ] == True ): print ( rtb . id + \" is the main route table, continue...\" ) if ( VERBOSE == 1 ) else \"\" rtables . append ( 'main route table: ' + rtb . id ) continue else : print ( \"Removing rtb-id: \" , rtb . id ) if ( VERBOSE == 1 ) else \"\" rtables . append ( rtb . id ) table = ec2 . RouteTable ( rtb . id ) table . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( rtables ) def del_acl ( ec2 , vpcid ): \"\"\" Delete the network-access-lists \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) acls = vpc_resource . network_acls . all () if acls : rtable_acls = [] try : for acl in acls : if acl . is_default : print ( acl . id + \" is the default NACL, continue...\" ) if ( VERBOSE == 1 ) else \"\" rtable_acls . append ( 'default_acl: ' + acl . id ) continue else : print ( \"Removing acl-id: \" , acl . id ) if ( VERBOSE == 1 ) else \"\" rtable_acls . append ( acl . id ) acl . delete ( #DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( rtable_acls ) def del_sgp ( ec2 , vpcid ): \"\"\" Delete any security-groups \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) sgps = vpc_resource . security_groups . all () if sgps : sgps_list = [] try : for sg in sgps : if sg . group_name == 'default' : print ( sg . id + \" is the default security group, continue...\" ) if ( VERBOSE == 1 ) else \"\" sgps_list . append ( 'default_security_group: ' + sg . id ) continue else : print ( \"Removing sg-id: \" , sg . id ) if ( VERBOSE == 1 ) else \"\" sgps_list . append ( sg . id ) sg . delete ( # DryRun=True ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) return ( sgps_list ) def del_vpc ( ec2 , vpcid ): \"\"\" Delete the VPC \"\"\" vpc_resource = ec2 . Vpc ( vpcid ) try : print ( \"Removing vpc-id: \" , vpc_resource . id ) vpc_resource . delete ( # DryRun=True ) return ( vpc_resource . id + ' Deleted Successfully.' ) except ClientError as e : return ( e . response [ 'Error' ][ 'Message' ]) print ( \"Please remove dependencies and delete VPC manually.\" )","title":"Lambda"},{"location":"cloud/aws/default-vpc-cleanup/#confluence-webform","text":"","title":"Confluence Webform"},{"location":"cloud/aws/default-vpc-cleanup/#default-vpc-removal-webform","text":"","title":"Default VPC Removal Webform"},{"location":"cloud/aws/default-vpc-cleanup/#htmljavascript","text":"< div > <!--- Submitted Animation--> < div class = \"aui\" id = \"spinner\" style = \"display: none\" > < aui-spinner size = \"large\" ></ aui-spinner > < div class = \"aui\" id = \"ClonfluenceUserName\" ></ div > < div class = \"aui\" id = \"ClonfluenceUserId\" ></ div > < p > Your request is being processed...Please wait </ p > </ div > <!--- Submitted Animation--> <!--- Webform--> < form class = \"aui\" id = \"RequestForm\" style = \"margin: 40px;\" > < h3 style = \"text-align: center;\" > AWS Account Default VPC Deletion Form </ h3 > < p style = \"text-align: center;\" > Please fill in this form to delete Default VPCs from an AWS Account. in the < a href = \"http://websvc4:8090/display/AWS/BCH+Cloud+Standard+Offerings\" target = \"_blank\" > BCH AWS Organization. </ a ></ p > < label for = \"fname\" > AWS Account Number </ label > < input type = \"text\" id = \"aws_acct\" name = \"FormAwsAcct\" placeholder = \"Valid AWS Account Number\" required > < label for = \"lname\" > AWS Switch Role </ label > < input type = \"text\" id = \"switch_role\" name = \"FormSwitchRole\" placeholder = \"AWS Assume Role - core-network-restricted-access-lambda-role\" required > < label for = \"email\" > Email Address </ label > < input type = \"text\" id = \"email\" name = \"FormEmail\" placeholder = \"Requester BCH Email Address - This is not currently being used but it is a required field\" required > < button class = \"aui-button aui-button-primary\" type = \"button\" id = \"button-spin-2\" onclick = \"runAPIGetRequest()\" > Submit </ button > < p >< small > When you click the \"Submit\" button, an API Call will be made with the information you've provided. If you need any assistance, please reach out to the BCH Cloud Team. </ small ></ p > </ form > <!--- Webform--> <!--- Response Placeholder--> < div class = \"aui\" id = \"submittedMsg\" ></ div > <!--- Response Placeholder--> </ div > < script type = \"text/javascript\" > //Get Information from confluence var UserName = AJS . params . userDisplayName ; var UserId = AJS . params . remoteUser . toUpperCase (); //alert(AJS.Meta.get(\"user-display-name\")); //alert(AJS.Meta.get(\"remote-user\")); function checkRequired () { var i , GetInputs , allowSubmit ; allowSubmit = true ; GetInputs = document . getElementsByTagName ( 'input' ); for ( i = 0 ; i < GetInputs . length ; i += 1 ) { if ( GetInputs [ i ]. hasAttribute ( 'required' )){ if (( GetInputs [ i ]. value == null ) || ( GetInputs [ i ]. value == \"\" )) { GetInputs [ i ]. style . backgroundColor = \"#e6f2ff\" ; allowSubmit = false ; console . log ( \"checkRequired():\" + \"Name:\" + GetInputs [ i ]. name + \" Missing: \" + GetInputs [ i ]. placeholder ) } else { GetInputs [ i ]. style . backgroundColor = \"#ffffff\" ; console . log ( \"checkRequired():\" + \"Name:\" + GetInputs [ i ]. name + \" Type: \" + GetInputs [ i ]. type . toLowerCase () + \" Value: \" + GetInputs [ i ]. value ) } } } return allowSubmit ; } function buildParms () { var GetInputs ; var i ; var parms , tok , parms = \"\" ; GetInputs = document . getElementsByTagName ( 'input' ); for ( i = 0 ; i < GetInputs . length ; i += 1 ) { if ( parms === \"\" ) { tok = \"?\" ;} else { tok = \"&\" ;} parms = parms + tok + GetInputs [ i ]. name + \"=\" + encodeURIComponent ( GetInputs [ i ]. value ); console . log ( GetInputs [ i ]. name + \"=\" + encodeURIComponent ( GetInputs [ i ]. value )); } console . log ( parms ); return parms ; } function runAPIGetRequest () { if ( checkRequired ()) { // Public API DNS Names //myAPI = \"https://609k7k2nn4.execute-api.us-east-1.amazonaws.com/core/getjson\" //myAPI = \"https://609k7k2nn4.execute-api.us-east-1.amazonaws.com/core/defaultvpcremoval\" // Private API DNS Names //myAPI = \"https://609k7k2nn4-vpce-0897455697c88d3cd.execute-api.us-east-1.amazonaws.com/core/getjson\" myAPI = \"https://609k7k2nn4-vpce-0897455697c88d3cd.execute-api.us-east-1.amazonaws.com/core/defaultvpcremoval\" formParms = \"\" ; formParms = buildParms (); // adding Confluence Information formParms = ( formParms + \"&\" + \"UserName\" + \"=\" + UserName + \"&\" + \"UserId\" + \"=\" + UserId ) document . getElementById ( \"RequestForm\" ). style . display = \"none\" ; // hide buttons document . getElementById ( \"spinner\" ). style . display = \"block\" ; // submitted animation document . getElementById ( \"ClonfluenceUserName\" ). innerHTML = UserName document . getElementById ( \"ClonfluenceUserId\" ). innerHTML = UserId var urlWithParms = myAPI + formParms ; xmlhttp = new XMLHttpRequest (); xmlhttp . open ( \"GET\" , urlWithParms , true ); xmlhttp . send (); xmlhttp . onreadystatechange = function () { if ( xmlhttp . readyState == 4 && xmlhttp . status == 200 ) { document . getElementById ( \"submittedMsg\" ). innerHTML = xmlhttp . responseText ; document . getElementById ( \"spinner\" ). style . display = \"none\" ; // submitted animation } else if ( xmlhttp . status != 200 ) { document . getElementById ( \"submittedMsg\" ). innerHTML = '<h6 style=\"color: #e63900; font-weight: bold;\" > There was an issue with your request. Please reach out to BCH Cloud Team</h6>' ; document . getElementById ( \"spinner\" ). style . display = \"none\" ; // submitted animation } }; } } </ script >","title":"HTML/JavaScript"},{"location":"cloud/aws/default-vpc-cleanup/#css","text":"```CSS .sectionMacroRow form{ border-radius: 5px; width: 800px; padding: 20px; -moz-box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); -webkit-box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); box-shadow:5px 5px 5px 5px rgba(0,0,0,0.3); } .sectionMacroRow form input[type=text], select { width: 100%; padding: 12px 20px; margin: 8px 0; display: block; border: 1px solid #ccc; border-radius: 4px; box-sizing: border-box; } .sectionMacroRow form input[type=submit] { width: 100%; background-color: #42526e; color: white; padding: 14px 20px; margin: 8px 0; display: block; text-align: center; border: 3px solid #deebff; border-radius: 4px; cursor: pointer; } .sectionMacroRow form input[type=submit]:hover { background-color: #0049b0; } ```","title":"CSS"},{"location":"cloud/aws/ec2-dynamic-dns/","text":"EC2 Dynamic DNS provides a simple integration betwee private and hybrid cloud. Dynamic DNS solutions for EC2's and ALB's - Tag Key: DNSName - Tag Value: must not include special characters Combine into a functional lambda Tagging solution - 3 into One - VPC must be shared -- maybe look for shared tag on remote accounts -- Function to tell the difference between EC2's Tags and ALBs split function and pull fuctions as needed Import event data as json def load_event ( file_name ): \"\"\"This function load file as variable.\"\"\" try : with open ( file_name ) as fileobj : event = json . loads ( fileobj . read ()) except ClientError as e : print ( e . response [ 'Error' ][ 'Message' ]) return event CloudWatch EC2 State Event \u00b6 { \"version\" : \"0\" , \"id\" : \"44265205-9501-dd5f-39b5-6af68926b286\" , \"detail-type\" : \"EC2 Instance State-change Notification\" , \"source\" : \"aws.ec2\" , \"account\" : \"089714066692\" , \"time\" : \"2021-08-29T17:03:52Z\" , \"region\" : \"us-east-1\" , \"resources\" :[ \"arn:aws:ec2:us-east-1:089714066692:instance/i-0389a92bd5b886c39\" ], \"detail\" :{ \"instance-id\" : \"i-0389a92bd5b886c39\" , \"state\" : \"running\" } } Steps \u00b6 Create VPC https://gitlab.com/gtz4all/aws-three-tier-vpc-cf/-/blob/main/gtz4all-three-tier-vpc-nested-conditions.yml Create Hosted Zone based on project name and domain sbox.gtz4all.com Associate Private Zone with VPC Create Lambda Role sbox-dev-ddns-lambda-role/policy { \"Statement\" : [ { \"Action\" : [ \"logs:CreateLogStream\" , \"ec2:Describe*\" , \"ec2:CreateTags\" , \"ec2:DeleteTags\" , \"route53:*\" , \"dynamodb:*\" , \"logs:CreateLogGroup\" , \"logs:PutLogEvents\" ], \"Condition\" : { \"ForAllValues:StringEquals\" : { \"aws:TagKeys\" : [ \"DDNS\" ] }, \"StringEquals\" : { \"aws:RequestedRegion\" : [ \"us-east-1\" , \"us-east-2\" ] } }, \"Effect\" : \"Allow\" , \"Resource\" : \"*\" , \"Sid\" : \"sboxDDNSNetwork\" }, { \"Action\" : \"sts:AssumeRole\" , \"Condition\" : { \"ForAllValues:StringEquals\" : { \"aws:TagKeys\" : [ \"DDNS\" ] }, \"StringEquals\" : { \"aws:RequestedRegion\" : [ \"us-east-1\" , \"us-east-2\" ] } }, \"Effect\" : \"Allow\" , \"Resource\" : \"*\" , \"Sid\" : \"sboxDDNSClient\" } ], \"Version\" : \"2012-10-17\" } Create lambda and associate created role Adjust timeout to 5min Create EventBridge sbox-dev-ec2-state","title":"EC2 Cross-Account Dynamic DNS Design"},{"location":"cloud/aws/ec2-dynamic-dns/#cloudwatch-ec2-state-event","text":"{ \"version\" : \"0\" , \"id\" : \"44265205-9501-dd5f-39b5-6af68926b286\" , \"detail-type\" : \"EC2 Instance State-change Notification\" , \"source\" : \"aws.ec2\" , \"account\" : \"089714066692\" , \"time\" : \"2021-08-29T17:03:52Z\" , \"region\" : \"us-east-1\" , \"resources\" :[ \"arn:aws:ec2:us-east-1:089714066692:instance/i-0389a92bd5b886c39\" ], \"detail\" :{ \"instance-id\" : \"i-0389a92bd5b886c39\" , \"state\" : \"running\" } }","title":"CloudWatch EC2 State Event"},{"location":"cloud/aws/ec2-dynamic-dns/#steps","text":"Create VPC https://gitlab.com/gtz4all/aws-three-tier-vpc-cf/-/blob/main/gtz4all-three-tier-vpc-nested-conditions.yml Create Hosted Zone based on project name and domain sbox.gtz4all.com Associate Private Zone with VPC Create Lambda Role sbox-dev-ddns-lambda-role/policy { \"Statement\" : [ { \"Action\" : [ \"logs:CreateLogStream\" , \"ec2:Describe*\" , \"ec2:CreateTags\" , \"ec2:DeleteTags\" , \"route53:*\" , \"dynamodb:*\" , \"logs:CreateLogGroup\" , \"logs:PutLogEvents\" ], \"Condition\" : { \"ForAllValues:StringEquals\" : { \"aws:TagKeys\" : [ \"DDNS\" ] }, \"StringEquals\" : { \"aws:RequestedRegion\" : [ \"us-east-1\" , \"us-east-2\" ] } }, \"Effect\" : \"Allow\" , \"Resource\" : \"*\" , \"Sid\" : \"sboxDDNSNetwork\" }, { \"Action\" : \"sts:AssumeRole\" , \"Condition\" : { \"ForAllValues:StringEquals\" : { \"aws:TagKeys\" : [ \"DDNS\" ] }, \"StringEquals\" : { \"aws:RequestedRegion\" : [ \"us-east-1\" , \"us-east-2\" ] } }, \"Effect\" : \"Allow\" , \"Resource\" : \"*\" , \"Sid\" : \"sboxDDNSClient\" } ], \"Version\" : \"2012-10-17\" } Create lambda and associate created role Adjust timeout to 5min Create EventBridge sbox-dev-ec2-state","title":"Steps"},{"location":"cloud/aws/intro/","text":"AWS is currently the leading cloud provider.","title":"Introduction"},{"location":"cloud/aws/lambda-functions/","text":"Headline \u00b6 test 1 ...","title":"Lambda Functions"},{"location":"cloud/aws/lambda-functions/#headline","text":"test 1 ...","title":"Headline"},{"location":"cloud/aws/plugin-test/","text":"About \u00b6 DDNS Cloudflare Bash Script for most Linux , Unix distributions and MacOS . Choose any source IP address to update external or internal (WAN/LAN) . For multiply lan interfaces like Wifi, Docker Networks and Bridges the script will automatically detects the primary Interface by priority. Cloudflare's options proxy and TTL configurable via the config file. Optional Telegram Notifications Requirements \u00b6 curl Cloudflare api-token with ZONE-DNS-EDIT Permissions DNS Record must be pre created (api-token should only edit dns records) Creating Cloudflare API Token \u00b6 To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps: Click Create Token Select Create Custom Token Provide the token a name, for example, example.com-dns-zone-readonly Grant the token the following permissions: Zone - DNS - Edit Set the zone resources to: Include - Specific Zone - example.com Complete the wizard and use the generated token at the CLOUDFLARE_API_TOKEN variable for the container Installation \u00b6 You can place the script at any location manually. MacOS : Don't use the /usr/local/bin/ for the script location. Create a separate folder under your user path /Users/${USER} The automatic install examples below will place the script at /usr/local/bin/ wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.sh sudo chmod +x update-cloudflare-dns.sh sudo mv update-cloudflare-dns.sh /usr/local/bin/update-cloudflare-dns Config file download wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.conf Place the config file in the directory as the update-cloudflare-dns for above example at /usr/local/bin/ sudo mv update-cloudflare-dns.conf /usr/local/bin/update-cloudflare-dns.conf Config Parameters \u00b6 Option Example Description what_ip internal Which IP should be used for the record: internal/external dns_record ddns.example.com DNS A record which will be updated cloudflare_zone_api_token ChangeMe Cloudflare API Token KEEP IT PRIVET!!!! zoneid ChangeMe Cloudflare's Zone ID proxied false Use Cloudflare proxy on dns record true/false ttl 120 120-7200 in seconds or 1 for Auto Optional Notifications Parameters \u00b6 Option Example Description notify_me_telegram yes Use Telegram notifications yes/no telegram_chat_id ChangeMe Chat ID of the bot telegtam_bot_API_Token ChangeMe Telegtam's Bot API Token Running The Script \u00b6 When placed in /usr/local/bin/ update-cloudflare-dns Or manually <path>/.update-cloudflare-dns.sh Automation With Crontab \u00b6 You can run the script via crontab crontab -e Examples \u00b6 Run every minute * * * * * /usr/local/bin/update-cloudflare-dns Run every 2 minutes */2 * * * * /usr/local/bin/update-cloudflare-dns Run at boot @reboot /usr/local/bin/update-cloudflare-dns Run 1 minute after boot @reboot sleep 60 && /usr/local/bin/update-cloudflare-dns Run at 08:00 0 8 * * * /usr/local/bin/update-cloudflare-dns Logs \u00b6 This Script will create a log file with only the last run information Log file will be located at the script's location. Example: /usr/local/bin/update-cloudflare-dns.log Limitations \u00b6 Does not support IPv6 License \u00b6 MIT License \u00b6 Copyright\u00a9 3os.org @2020 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Plugin test"},{"location":"cloud/aws/plugin-test/#about","text":"DDNS Cloudflare Bash Script for most Linux , Unix distributions and MacOS . Choose any source IP address to update external or internal (WAN/LAN) . For multiply lan interfaces like Wifi, Docker Networks and Bridges the script will automatically detects the primary Interface by priority. Cloudflare's options proxy and TTL configurable via the config file. Optional Telegram Notifications","title":"About"},{"location":"cloud/aws/plugin-test/#requirements","text":"curl Cloudflare api-token with ZONE-DNS-EDIT Permissions DNS Record must be pre created (api-token should only edit dns records)","title":"Requirements"},{"location":"cloud/aws/plugin-test/#creating-cloudflare-api-token","text":"To create a CloudFlare API token for your DNS zone go to https://dash.cloudflare.com/profile/api-tokens and follow these steps: Click Create Token Select Create Custom Token Provide the token a name, for example, example.com-dns-zone-readonly Grant the token the following permissions: Zone - DNS - Edit Set the zone resources to: Include - Specific Zone - example.com Complete the wizard and use the generated token at the CLOUDFLARE_API_TOKEN variable for the container","title":"Creating Cloudflare API Token"},{"location":"cloud/aws/plugin-test/#installation","text":"You can place the script at any location manually. MacOS : Don't use the /usr/local/bin/ for the script location. Create a separate folder under your user path /Users/${USER} The automatic install examples below will place the script at /usr/local/bin/ wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.sh sudo chmod +x update-cloudflare-dns.sh sudo mv update-cloudflare-dns.sh /usr/local/bin/update-cloudflare-dns Config file download wget https://raw.githubusercontent.com/fire1ce/DDNS-Cloudflare-Bash/main/update-cloudflare-dns.conf Place the config file in the directory as the update-cloudflare-dns for above example at /usr/local/bin/ sudo mv update-cloudflare-dns.conf /usr/local/bin/update-cloudflare-dns.conf","title":"Installation"},{"location":"cloud/aws/plugin-test/#config-parameters","text":"Option Example Description what_ip internal Which IP should be used for the record: internal/external dns_record ddns.example.com DNS A record which will be updated cloudflare_zone_api_token ChangeMe Cloudflare API Token KEEP IT PRIVET!!!! zoneid ChangeMe Cloudflare's Zone ID proxied false Use Cloudflare proxy on dns record true/false ttl 120 120-7200 in seconds or 1 for Auto","title":"Config Parameters"},{"location":"cloud/aws/plugin-test/#optional-notifications-parameters","text":"Option Example Description notify_me_telegram yes Use Telegram notifications yes/no telegram_chat_id ChangeMe Chat ID of the bot telegtam_bot_API_Token ChangeMe Telegtam's Bot API Token","title":"Optional Notifications Parameters"},{"location":"cloud/aws/plugin-test/#running-the-script","text":"When placed in /usr/local/bin/ update-cloudflare-dns Or manually <path>/.update-cloudflare-dns.sh","title":"Running The Script"},{"location":"cloud/aws/plugin-test/#automation-with-crontab","text":"You can run the script via crontab crontab -e","title":"Automation With Crontab"},{"location":"cloud/aws/plugin-test/#examples","text":"Run every minute * * * * * /usr/local/bin/update-cloudflare-dns Run every 2 minutes */2 * * * * /usr/local/bin/update-cloudflare-dns Run at boot @reboot /usr/local/bin/update-cloudflare-dns Run 1 minute after boot @reboot sleep 60 && /usr/local/bin/update-cloudflare-dns Run at 08:00 0 8 * * * /usr/local/bin/update-cloudflare-dns","title":"Examples"},{"location":"cloud/aws/plugin-test/#logs","text":"This Script will create a log file with only the last run information Log file will be located at the script's location. Example: /usr/local/bin/update-cloudflare-dns.log","title":"Logs"},{"location":"cloud/aws/plugin-test/#limitations","text":"Does not support IPv6","title":"Limitations"},{"location":"cloud/aws/plugin-test/#license","text":"","title":"License"},{"location":"cloud/aws/plugin-test/#mit-license","text":"Copyright\u00a9 3os.org @2020 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"MIT License"},{"location":"cloud/aws/three-tier-vpc/","text":"An AWS Three-Tier VPC Design provides a baseline to deploy software applications that consist of frontend, backend and database.This design provides Availability Zone High Availability and Fault Tolerant. In addition this design also provides the required topoligy for a highly secured environment. Public Tier \u00b6 The Public Tier has both inbound/outbound VPC External access. It is used to provide external services and an entry point into the environment Recommended Resources : * Public Application Load Balancer Users will only be allowed to access application via public Application Load Balancer * NAT Gateways Provides outbound access for private tier. This is required for software updates or patches * Bastion Hosts A bastion host provides secure management access into all three tiers. These servers should be secured with MFA. Private Tier \u00b6 The Private Tier only has outbound VPC External Access which is mainly used for software patches and updates. This is where the application servers and internal load balancer reside. Recommended Resources : * Internal Application Load Balancer This type of ALBs and NLBs are used to provide a Highly Available Service to the Public Tier ALBs * Application Servers EC2s, Lambda or EKS, ECS Local Tier \u00b6 This tier does not have inbound/outbould VPC External Access. It is meant to host database services. Services inside this tier should only be access by the application services. Recommended Resources : * Database Instances Cloudformation \u00b6 Cloudformation is a tool to quickly and consistently deploy infrastructure by building the designed resources and managing them as stacks. it is a declarative programming language with some basic features specific to this use case. Componentes \u00b6 Metadata: AWS::CloudFormation::Interface is used to modify how the AWS Cloudformation groups, labels and orders user input parameters. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs * Parametes: Parameters are used to request user input custom values which are later used by the Resources section to build infrastructure. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html Parameters : NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Conditions: Conditions are used to set parameters based on other parameter's values provided by the user. These conditions are later used to set conditial resources. ex: If Condition: Value is true, create resource. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html ## Conditions are either True or False and are used to choose whether a rosource should be created or not. Conditions : ## Build4AZs is True if NumberofAZs is set to '4' Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] ## Build4AZs is True if NumberofAZs is set to '4' ProdVPC : !Equals [ !Ref Environment , prod ] ## BuildProdEnvironemt is True if both Build4AZs and ProdVPC are True BuildProdEnvironemt : !And [ !Condition Build4AZs , !Condition ProdVPC ] Resources : PublicSubnet3 : Type : AWS::EC2::Subnet ## PublicSubnet3 will be created only if Build4AZs is True Condition : Build4AZs Built-in Intrinsic Functions \u00b6 An intrinsic function used to perform a mathematical, character, or logical operation against a data item whose value is derived automatically during execution. Fn::Cidr ( !Cidr ) \u00b6 This Subnetting calculator function returns an CIDR address block list based on the `count provided. !Cidr [ ipBlock, count, cidrBits ] Parameters ipBlock : CIDR address block to be split into smaller CIDR blocks. count : The number of smaller CIDRs blocks to generate. Valid range 1 - 256. cidrBits : The number of subnet bits for the CIDR. Example Requirementes: create 12(count) /24s(cidrBits) out of a /16 (ipBlock) and pick the 6 th (!Select) CIDR block. !Select [ 5, !Cidr [ \"10.10.0.0/16\", 12, 5 ] Generated Table - !Select - select the 6th block - starts from 0 - 7 if there are 8 blocks. ```!Select [ 5,``` - !Cidr [CidrBlock = (/16), 12 = break /16 into 12 block, what size for each block? look at host-bits... ```!Cidr [ \"10.10.0.0/16\", 12,``` - SubnetBits/cidrBits = 8 - which means host-bits of 8, (/24s) ```8]]``` ***cidrBit Table*** Suffix|IPs|CIDR|Borrowed Bits|Binary -|-|-|-|- .255|1 |/32|0|11111111 .254|2 |/31|1|11111110 .252|4 |/30|2|11111100 .248|8 |/29|3|11111000 .240|16 |/28|4|11110000 .224|32 |/27|5|11100000 .192|64 |/26|6|11000000 .128|128|/25|7|10000000 .0|256|/24|8|00000000 Count|CidrBlocks|Select -|-|- 0|10.10.0.0/24| 1|10.10.1.0/24| 2|10.10.2.0/24| 3|10.10.3.0/24| 4|10.10.4.0/24| 5|10.10.5.0/24|!Select 6|10.10.6.0/24| 7|10.10.7.0/24| 8|10.10.8.0/24| 9|10.10.9.0/24| 10|10.10.10.0/24| 11|10.10.11.0/24| 12|10.10.12.0/24| Conditional Subnetting !Select [ !If [ BuildProd , 0 , 0 ], !Cidr [ !Ref CidrBlock , !If [ BuildProd , 16 , 8 ], !If [ BuildProd , 5 , 6 ]]] Conditial !Cidr Condition !if - if BuildPord is True - Create 16 /27s (Host-Bits - 5 ) blocks - if BuildPord is False - Create 8 /26s (Host-Bits - 6 ) blocks !Select [ !If [ BuildProd , 0 , 0 ], !Cidr [ !Ref CidrBlock , !If [ BuildProd , 16 , 8 ], !If [ BuildProd , 5 , 6 ]]] !If Condition|Boolean|Value -|-|- BluidProd|True|firstValue BluidProd|False|secondValue ***!Cidr*** ipBlock|count|cidrBits -|-|- !Ref CidrBlock|!If [BuildProd, 16, 8]|!If [BuildProd, 5, 6] Fn::GetAZs (!GetAZs) \u00b6 The intrinsic function Fn::GetAZs returns a Availability Zone Name List based for a region. AZ Name to AZ ID mapping is different per account. !GetAZs \"\" in us-east-1 returns a list of all Availability Zones: [ \"us-east-1a\", \"us-east-1b\", \"us-east-1c\", \"us-east-1d\", \"us-east-1e\", \"us-east-1f\" ] 0 1 2 3 4 5 \"us-east-1a\" \"us-east-1b\" \"us-east-1c\" \"us-east-1d\" \"us-east-1e\" \"us-east-1f\" !Select can pick an AZ based on the order list. !Select [3, !GetAZs ''] returns \"us-east-1d\" . Three Tier VPC Cloudformation Template \u00b6 This template builds the Three Tier VPC based on the above topology using the built-in cloudformation functions recently mentioned. Gtz4all Three Tier VPC Template AWSTemplateFormatVersion : 2010-09-09 Description : GTZ Three Tier VPC Template Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Stack Name - --three-tier-vpc-cf (i.e jira-dev-three-tier-vpc-cf)\" - Label : default : \"|\" - Label : default : \"VPC Configuration\" Parameters : - ProjectName - Environment - CidrBlock - Label : default : \"Subnet 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required)\" Parameters : - SubnetBits - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs Parameters : ProjectName : Description : Project Name ( ex. jira / sfpt / sec ) Type : String CidrBlock : AllowedPattern : ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/(1[6-9]|2[0-8]))$ ConstraintDescription : CIDR block parameter must be in the form x.x.x.x/16-28 Description : VPC valid IP CIDR Blocks /20's, /21's and /22's( ex. 10.168.0.0/20) Default : 10.168.0.0/20 Type : String SubnetBits : Type : Number AllowedValues : - 8 - 7 - 6 Default : 8 Description : Subnet Bits 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required) NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Description : Availability Zones - 2 = 2 per Tier, 4 = 4 per Tier Environment : Description : Choose VPC Type Type : String AllowedValues : - dev - test - prod Conditions : Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] ############################################### ### Three Tier VPC #### ############################################### Resources : VPC : Type : AWS::EC2::VPC Properties : CidrBlock : { Ref : CidrBlock } EnableDnsHostnames : true EnableDnsSupport : true Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"vpc\" ]] DhcpOptions : Type : AWS::EC2::DHCPOptions Properties : DomainName : !Join [ '-' , [ !Ref ProjectName , \"three-tier.org\" ]] DomainNameServers : - AmazonProvidedDNS Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"dopt\" ]] VPCDHCPOptionsAssociation : Type : AWS::EC2::VPCDHCPOptionsAssociation Properties : VpcId : { Ref : VPC } DhcpOptionsId : { Ref : DhcpOptions } InternetGateway : Type : AWS::EC2::InternetGateway DependsOn : VPC Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"igw\" ]] VPCGatewayAttachment : Type : AWS::EC2::VPCGatewayAttachment Properties : VpcId : !Ref VPC InternetGatewayId : !Ref InternetGateway ############################################### ### Public/ALB Tier (inbound/outbound) #### ############################################### PublicRouteTableA : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1a\" ]] VpcId : !Ref VPC PublicRouteTableB : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1b\" ]] VpcId : !Ref VPC ############################################### PublicSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 0 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1a\" ]] VpcId : !Ref VPC PublicSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 1 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1b\" ]] VpcId : !Ref VPC PublicSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 2 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1c\" ]] VpcId : !Ref VPC PublicSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 3 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### PublicSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet1 PublicSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet2 PublicSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet3 PublicSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet4 ############################################### ### Private/Application Tier (inbound) #### ############################################### AppRouteTableA : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"rt-1a\" ]] VpcId : Ref : VPC AppRouteTableB : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"rt-1b\" ]] VpcId : Ref : VPC ############################################### AppSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 4 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1a\" ]] VpcId : !Ref VPC AppSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 5 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1b\" ]] VpcId : !Ref VPC AppSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 6 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1c\" ]] VpcId : !Ref VPC AppSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 7 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### AppSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref AppRouteTableA SubnetId : !Ref AppSubnet1 AppSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref AppRouteTableB SubnetId : !Ref AppSubnet2 AppSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref AppRouteTableA SubnetId : !Ref AppSubnet3 AppSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref AppRouteTableB SubnetId : !Ref AppSubnet4 ############################################### NatGatewayAEIP : Type : 'AWS::EC2::EIP' DependsOn : VPCGatewayAttachment Properties : Domain : vpc NatGatewayA : Type : 'AWS::EC2::NatGateway' DependsOn : NatGatewayAEIP Properties : AllocationId : Fn::GetAtt : - NatGatewayAEIP - AllocationId SubnetId : !Ref AppSubnet1 Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"natgw\" , \"1a\" ]] ############################################### NatGatewayBEIP : Type : 'AWS::EC2::EIP' DependsOn : VPCGatewayAttachment Properties : Domain : vpc NatGatewayB : Type : 'AWS::EC2::NatGateway' DependsOn : NatGatewayBEIP Properties : AllocationId : Fn::GetAtt : - NatGatewayBEIP - AllocationId SubnetId : !Ref AppSubnet2 Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"natgw\" , \"1b\" ]] ############################################### AppRouteTableARoute : Type : 'AWS::EC2::Route' DependsOn : VPCGatewayAttachment Properties : RouteTableId : !Ref AppRouteTableA DestinationCidrBlock : '0.0.0.0/0' NatGatewayId : !Ref NatGatewayA AppRouteTableBRoute : Type : 'AWS::EC2::Route' DependsOn : VPCGatewayAttachment Properties : RouteTableId : !Ref AppRouteTableB DestinationCidrBlock : '0.0.0.0/0' NatGatewayId : !Ref NatGatewayB ############################################### ### Local/Database Tier (local-access) #### ############################################### BDRouteTableA : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"rt-1a\" ]] VpcId : Ref : VPC BDRouteTableB : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"rt-1b\" ]] VpcId : Ref : VPC ############################################### BDSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 8 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1a\" ]] VpcId : !Ref VPC BDSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 9 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1b\" ]] VpcId : !Ref VPC BDSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 10 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1c\" ]] VpcId : !Ref VPC BDSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 11 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### BDSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref BDRouteTableA SubnetId : !Ref BDSubnet1 BDSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref BDRouteTableB SubnetId : !Ref BDSubnet2 BDSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref BDRouteTableA SubnetId : !Ref BDSubnet3 BDSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref BDRouteTableB SubnetId : !Ref BDSubnet4 ############################################### PublicRouteTableRouteA : Type : 'AWS::EC2::Route' Properties : RouteTableId : !Ref PublicRouteTableA DestinationCidrBlock : '0.0.0.0/0' GatewayId : !Ref InternetGateway PublicRouteTableRouteB : Type : 'AWS::EC2::Route' Properties : RouteTableId : !Ref PublicRouteTableB DestinationCidrBlock : '0.0.0.0/0' GatewayId : !Ref InternetGateway ```` </div> #### Cloudformation Nested Functions The above template is prone to error depending on the user inputs. Howerver there are complicated ways to reduce some of them. * ***Problem*** : Assume user provides a CidrBlock : ``` 10.168.64.0/22``` and CidrBits:```8```. In order to generate enough Cidr Blocks for 4 AZs, the templace is requesting ```12``` smaller blocks. Since The ```/22``` CidrBlock only contains 4 ```/24's```, the cloudformation stack build will fail. * ***Solution*** : One possible solution would be to pick from a list of ```AllowedValues``` in the ```Parameters`` section and use ```Conditions``` to set ```CidrBits``` based on user choice using nested conditions in ```resources```. ``` yaml Conditions : CidrBit8 : !Equals [ !Ref Cidr , 20 ] CidrBit7 : !Equals [ !Ref Cidr , 21 ] CidrBit6 : !Equals [ !Ref Cidr , 22 ] Resources : !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]] * ```!If [CidrBit8, 8, !If [CidrBit7, 7, 6]]``` if CidrBit8 == True: cidrBit == 8 elif CidrBit7 == True: cidrBit == 7 else: cidrBit = 6 ###### Cloudformation Snippet AWSTemplateFormatVersion : 2010-09-09 Description : GTZ Three Tier VPC Template Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Stack Name - --three-tier-vpc-cf (i.e jira-dev-three-tier-vpc-cf)\" - Label : default : \"|\" - Label : default : \"VPC Configuration\" Parameters : - ProjectName - Environment - CidrBlock - Label : default : \"Subnet 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required)\" Parameters : - CidrMask - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs Parameters : ProjectName : Description : Project Name ( ex. jira / sfpt / sec ) Type : String CidrBlock1 : ConstraintDescription : CIDR block parameter must be in the form x.x.x.x Description : VPC valid IP Block ( ex. 10.168.0.0) Default : 10.168.0.0 Type : String Cidr : Type : Number AllowedValues : - 20 - 22 - 21 Default : 20 Description : VPC valid IP CIDR Blocks /20's ( /24's smaller blocks ) , /21's ( /25's smaller blocks )and /22's ( /26's smaller blocks ) NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Description : Availability Zones - 2 = 2 per Tier, 4 = 4 per Tier Environment : Description : Choose VPC Type Type : String AllowedValues : - dev - test - prod Conditions : Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] CidrBit8 : !Equals [ !Ref Cidr , 20 ] CidrBit7 : !Equals [ !Ref Cidr , 21 ] CidrBit6 : !Equals [ !Ref Cidr , 22 ] ############################################### ### Three Tier VPC #### ############################################### Resources : VPC : Type : AWS::EC2::VPC Properties : CidrBlock : !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]] EnableDnsHostnames : true EnableDnsSupport : true Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"vpc\" ]] DhcpOptions : Type : AWS::EC2::DHCPOptions Properties : DomainName : !Join [ '-' , [ !Ref ProjectName , \"three-tier.org\" ]] DomainNameServers : - AmazonProvidedDNS Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"dopt\" ]] VPCDHCPOptionsAssociation : Type : AWS::EC2::VPCDHCPOptionsAssociation Properties : VpcId : { Ref : VPC } DhcpOptionsId : { Ref : DhcpOptions } InternetGateway : Type : AWS::EC2::InternetGateway DependsOn : VPC Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"igw\" ]] VPCGatewayAttachment : Type : AWS::EC2::VPCGatewayAttachment Properties : VpcId : !Ref VPC InternetGatewayId : !Ref InternetGateway ############################################### ### Public/ALB Tier (inbound/outbound) #### ############################################### PublicRouteTableA : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1a\" ]] VpcId : !Ref VPC PublicRouteTableB : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1b\" ]] VpcId : !Ref VPC ############################################### PublicSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 0 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1a\" ]] VpcId : !Ref VPC PublicSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 1 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1b\" ]] VpcId : !Ref VPC PublicSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 2 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1c\" ]] VpcId : !Ref VPC PublicSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 3 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### PublicSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet1 PublicSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet2 PublicSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet3 PublicSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet4","title":"Three tier vpc"},{"location":"cloud/aws/three-tier-vpc/#public-tier","text":"The Public Tier has both inbound/outbound VPC External access. It is used to provide external services and an entry point into the environment Recommended Resources : * Public Application Load Balancer Users will only be allowed to access application via public Application Load Balancer * NAT Gateways Provides outbound access for private tier. This is required for software updates or patches * Bastion Hosts A bastion host provides secure management access into all three tiers. These servers should be secured with MFA.","title":"Public Tier"},{"location":"cloud/aws/three-tier-vpc/#private-tier","text":"The Private Tier only has outbound VPC External Access which is mainly used for software patches and updates. This is where the application servers and internal load balancer reside. Recommended Resources : * Internal Application Load Balancer This type of ALBs and NLBs are used to provide a Highly Available Service to the Public Tier ALBs * Application Servers EC2s, Lambda or EKS, ECS","title":"Private Tier"},{"location":"cloud/aws/three-tier-vpc/#local-tier","text":"This tier does not have inbound/outbould VPC External Access. It is meant to host database services. Services inside this tier should only be access by the application services. Recommended Resources : * Database Instances","title":"Local Tier"},{"location":"cloud/aws/three-tier-vpc/#cloudformation","text":"Cloudformation is a tool to quickly and consistently deploy infrastructure by building the designed resources and managing them as stacks. it is a declarative programming language with some basic features specific to this use case.","title":"Cloudformation"},{"location":"cloud/aws/three-tier-vpc/#componentes","text":"Metadata: AWS::CloudFormation::Interface is used to modify how the AWS Cloudformation groups, labels and orders user input parameters. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/metadata-section-structure.html Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs * Parametes: Parameters are used to request user input custom values which are later used by the Resources section to build infrastructure. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/parameters-section-structure.html Parameters : NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Conditions: Conditions are used to set parameters based on other parameter's values provided by the user. These conditions are later used to set conditial resources. ex: If Condition: Value is true, create resource. https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/conditions-section-structure.html ## Conditions are either True or False and are used to choose whether a rosource should be created or not. Conditions : ## Build4AZs is True if NumberofAZs is set to '4' Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] ## Build4AZs is True if NumberofAZs is set to '4' ProdVPC : !Equals [ !Ref Environment , prod ] ## BuildProdEnvironemt is True if both Build4AZs and ProdVPC are True BuildProdEnvironemt : !And [ !Condition Build4AZs , !Condition ProdVPC ] Resources : PublicSubnet3 : Type : AWS::EC2::Subnet ## PublicSubnet3 will be created only if Build4AZs is True Condition : Build4AZs","title":"Componentes"},{"location":"cloud/aws/three-tier-vpc/#built-in-intrinsic-functions","text":"An intrinsic function used to perform a mathematical, character, or logical operation against a data item whose value is derived automatically during execution.","title":"Built-in Intrinsic Functions"},{"location":"cloud/aws/three-tier-vpc/#fncidr-cidr","text":"This Subnetting calculator function returns an CIDR address block list based on the `count provided. !Cidr [ ipBlock, count, cidrBits ] Parameters ipBlock : CIDR address block to be split into smaller CIDR blocks. count : The number of smaller CIDRs blocks to generate. Valid range 1 - 256. cidrBits : The number of subnet bits for the CIDR. Example Requirementes: create 12(count) /24s(cidrBits) out of a /16 (ipBlock) and pick the 6 th (!Select) CIDR block. !Select [ 5, !Cidr [ \"10.10.0.0/16\", 12, 5 ] Generated Table - !Select - select the 6th block - starts from 0 - 7 if there are 8 blocks. ```!Select [ 5,``` - !Cidr [CidrBlock = (/16), 12 = break /16 into 12 block, what size for each block? look at host-bits... ```!Cidr [ \"10.10.0.0/16\", 12,``` - SubnetBits/cidrBits = 8 - which means host-bits of 8, (/24s) ```8]]``` ***cidrBit Table*** Suffix|IPs|CIDR|Borrowed Bits|Binary -|-|-|-|- .255|1 |/32|0|11111111 .254|2 |/31|1|11111110 .252|4 |/30|2|11111100 .248|8 |/29|3|11111000 .240|16 |/28|4|11110000 .224|32 |/27|5|11100000 .192|64 |/26|6|11000000 .128|128|/25|7|10000000 .0|256|/24|8|00000000 Count|CidrBlocks|Select -|-|- 0|10.10.0.0/24| 1|10.10.1.0/24| 2|10.10.2.0/24| 3|10.10.3.0/24| 4|10.10.4.0/24| 5|10.10.5.0/24|!Select 6|10.10.6.0/24| 7|10.10.7.0/24| 8|10.10.8.0/24| 9|10.10.9.0/24| 10|10.10.10.0/24| 11|10.10.11.0/24| 12|10.10.12.0/24| Conditional Subnetting !Select [ !If [ BuildProd , 0 , 0 ], !Cidr [ !Ref CidrBlock , !If [ BuildProd , 16 , 8 ], !If [ BuildProd , 5 , 6 ]]] Conditial !Cidr Condition !if - if BuildPord is True - Create 16 /27s (Host-Bits - 5 ) blocks - if BuildPord is False - Create 8 /26s (Host-Bits - 6 ) blocks !Select [ !If [ BuildProd , 0 , 0 ], !Cidr [ !Ref CidrBlock , !If [ BuildProd , 16 , 8 ], !If [ BuildProd , 5 , 6 ]]] !If Condition|Boolean|Value -|-|- BluidProd|True|firstValue BluidProd|False|secondValue ***!Cidr*** ipBlock|count|cidrBits -|-|- !Ref CidrBlock|!If [BuildProd, 16, 8]|!If [BuildProd, 5, 6]","title":"Fn::Cidr ( !Cidr )"},{"location":"cloud/aws/three-tier-vpc/#fngetazs-getazs","text":"The intrinsic function Fn::GetAZs returns a Availability Zone Name List based for a region. AZ Name to AZ ID mapping is different per account. !GetAZs \"\" in us-east-1 returns a list of all Availability Zones: [ \"us-east-1a\", \"us-east-1b\", \"us-east-1c\", \"us-east-1d\", \"us-east-1e\", \"us-east-1f\" ] 0 1 2 3 4 5 \"us-east-1a\" \"us-east-1b\" \"us-east-1c\" \"us-east-1d\" \"us-east-1e\" \"us-east-1f\" !Select can pick an AZ based on the order list. !Select [3, !GetAZs ''] returns \"us-east-1d\" .","title":"Fn::GetAZs (!GetAZs)"},{"location":"cloud/aws/three-tier-vpc/#three-tier-vpc-cloudformation-template","text":"This template builds the Three Tier VPC based on the above topology using the built-in cloudformation functions recently mentioned. Gtz4all Three Tier VPC Template AWSTemplateFormatVersion : 2010-09-09 Description : GTZ Three Tier VPC Template Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Stack Name - --three-tier-vpc-cf (i.e jira-dev-three-tier-vpc-cf)\" - Label : default : \"|\" - Label : default : \"VPC Configuration\" Parameters : - ProjectName - Environment - CidrBlock - Label : default : \"Subnet 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required)\" Parameters : - SubnetBits - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs Parameters : ProjectName : Description : Project Name ( ex. jira / sfpt / sec ) Type : String CidrBlock : AllowedPattern : ^(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])(\\/(1[6-9]|2[0-8]))$ ConstraintDescription : CIDR block parameter must be in the form x.x.x.x/16-28 Description : VPC valid IP CIDR Blocks /20's, /21's and /22's( ex. 10.168.0.0/20) Default : 10.168.0.0/20 Type : String SubnetBits : Type : Number AllowedValues : - 8 - 7 - 6 Default : 8 Description : Subnet Bits 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required) NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Description : Availability Zones - 2 = 2 per Tier, 4 = 4 per Tier Environment : Description : Choose VPC Type Type : String AllowedValues : - dev - test - prod Conditions : Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] ############################################### ### Three Tier VPC #### ############################################### Resources : VPC : Type : AWS::EC2::VPC Properties : CidrBlock : { Ref : CidrBlock } EnableDnsHostnames : true EnableDnsSupport : true Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"vpc\" ]] DhcpOptions : Type : AWS::EC2::DHCPOptions Properties : DomainName : !Join [ '-' , [ !Ref ProjectName , \"three-tier.org\" ]] DomainNameServers : - AmazonProvidedDNS Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"dopt\" ]] VPCDHCPOptionsAssociation : Type : AWS::EC2::VPCDHCPOptionsAssociation Properties : VpcId : { Ref : VPC } DhcpOptionsId : { Ref : DhcpOptions } InternetGateway : Type : AWS::EC2::InternetGateway DependsOn : VPC Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"igw\" ]] VPCGatewayAttachment : Type : AWS::EC2::VPCGatewayAttachment Properties : VpcId : !Ref VPC InternetGatewayId : !Ref InternetGateway ############################################### ### Public/ALB Tier (inbound/outbound) #### ############################################### PublicRouteTableA : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1a\" ]] VpcId : !Ref VPC PublicRouteTableB : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1b\" ]] VpcId : !Ref VPC ############################################### PublicSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 0 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1a\" ]] VpcId : !Ref VPC PublicSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 1 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1b\" ]] VpcId : !Ref VPC PublicSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 2 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1c\" ]] VpcId : !Ref VPC PublicSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 3 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### PublicSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet1 PublicSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet2 PublicSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet3 PublicSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet4 ############################################### ### Private/Application Tier (inbound) #### ############################################### AppRouteTableA : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"rt-1a\" ]] VpcId : Ref : VPC AppRouteTableB : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"rt-1b\" ]] VpcId : Ref : VPC ############################################### AppSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 4 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1a\" ]] VpcId : !Ref VPC AppSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 5 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1b\" ]] VpcId : !Ref VPC AppSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 6 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1c\" ]] VpcId : !Ref VPC AppSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 7 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"private\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### AppSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref AppRouteTableA SubnetId : !Ref AppSubnet1 AppSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref AppRouteTableB SubnetId : !Ref AppSubnet2 AppSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref AppRouteTableA SubnetId : !Ref AppSubnet3 AppSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref AppRouteTableB SubnetId : !Ref AppSubnet4 ############################################### NatGatewayAEIP : Type : 'AWS::EC2::EIP' DependsOn : VPCGatewayAttachment Properties : Domain : vpc NatGatewayA : Type : 'AWS::EC2::NatGateway' DependsOn : NatGatewayAEIP Properties : AllocationId : Fn::GetAtt : - NatGatewayAEIP - AllocationId SubnetId : !Ref AppSubnet1 Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"natgw\" , \"1a\" ]] ############################################### NatGatewayBEIP : Type : 'AWS::EC2::EIP' DependsOn : VPCGatewayAttachment Properties : Domain : vpc NatGatewayB : Type : 'AWS::EC2::NatGateway' DependsOn : NatGatewayBEIP Properties : AllocationId : Fn::GetAtt : - NatGatewayBEIP - AllocationId SubnetId : !Ref AppSubnet2 Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"natgw\" , \"1b\" ]] ############################################### AppRouteTableARoute : Type : 'AWS::EC2::Route' DependsOn : VPCGatewayAttachment Properties : RouteTableId : !Ref AppRouteTableA DestinationCidrBlock : '0.0.0.0/0' NatGatewayId : !Ref NatGatewayA AppRouteTableBRoute : Type : 'AWS::EC2::Route' DependsOn : VPCGatewayAttachment Properties : RouteTableId : !Ref AppRouteTableB DestinationCidrBlock : '0.0.0.0/0' NatGatewayId : !Ref NatGatewayB ############################################### ### Local/Database Tier (local-access) #### ############################################### BDRouteTableA : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"rt-1a\" ]] VpcId : Ref : VPC BDRouteTableB : Type : AWS::EC2::RouteTable Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"rt-1b\" ]] VpcId : Ref : VPC ############################################### BDSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 8 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1a\" ]] VpcId : !Ref VPC BDSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 9 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1b\" ]] VpcId : !Ref VPC BDSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 10 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1c\" ]] VpcId : !Ref VPC BDSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 11 , !Cidr [ !Ref CidrBlock , 12 , !Ref SubnetBits ]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"local\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### BDSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref BDRouteTableA SubnetId : !Ref BDSubnet1 BDSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref BDRouteTableB SubnetId : !Ref BDSubnet2 BDSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref BDRouteTableA SubnetId : !Ref BDSubnet3 BDSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref BDRouteTableB SubnetId : !Ref BDSubnet4 ############################################### PublicRouteTableRouteA : Type : 'AWS::EC2::Route' Properties : RouteTableId : !Ref PublicRouteTableA DestinationCidrBlock : '0.0.0.0/0' GatewayId : !Ref InternetGateway PublicRouteTableRouteB : Type : 'AWS::EC2::Route' Properties : RouteTableId : !Ref PublicRouteTableB DestinationCidrBlock : '0.0.0.0/0' GatewayId : !Ref InternetGateway ```` </div> #### Cloudformation Nested Functions The above template is prone to error depending on the user inputs. Howerver there are complicated ways to reduce some of them. * ***Problem*** : Assume user provides a CidrBlock : ``` 10.168.64.0/22``` and CidrBits:```8```. In order to generate enough Cidr Blocks for 4 AZs, the templace is requesting ```12``` smaller blocks. Since The ```/22``` CidrBlock only contains 4 ```/24's```, the cloudformation stack build will fail. * ***Solution*** : One possible solution would be to pick from a list of ```AllowedValues``` in the ```Parameters`` section and use ```Conditions``` to set ```CidrBits``` based on user choice using nested conditions in ```resources```. ``` yaml Conditions : CidrBit8 : !Equals [ !Ref Cidr , 20 ] CidrBit7 : !Equals [ !Ref Cidr , 21 ] CidrBit6 : !Equals [ !Ref Cidr , 22 ] Resources : !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]] * ```!If [CidrBit8, 8, !If [CidrBit7, 7, 6]]``` if CidrBit8 == True: cidrBit == 8 elif CidrBit7 == True: cidrBit == 7 else: cidrBit = 6 ###### Cloudformation Snippet AWSTemplateFormatVersion : 2010-09-09 Description : GTZ Three Tier VPC Template Metadata : AWS::CloudFormation::Interface : ParameterGroups : - Label : default : \"Stack Name - --three-tier-vpc-cf (i.e jira-dev-three-tier-vpc-cf)\" - Label : default : \"|\" - Label : default : \"VPC Configuration\" Parameters : - ProjectName - Environment - CidrBlock - Label : default : \"Subnet 8 = /24(/20 CidrBlock Required), 7 = /25 (/21 CidrBlock Required), 6 = /26 (/22 CidrBlock Required)\" Parameters : - CidrMask - Label : default : \"Availability Zones\" Parameters : - NumberOfAZs Parameters : ProjectName : Description : Project Name ( ex. jira / sfpt / sec ) Type : String CidrBlock1 : ConstraintDescription : CIDR block parameter must be in the form x.x.x.x Description : VPC valid IP Block ( ex. 10.168.0.0) Default : 10.168.0.0 Type : String Cidr : Type : Number AllowedValues : - 20 - 22 - 21 Default : 20 Description : VPC valid IP CIDR Blocks /20's ( /24's smaller blocks ) , /21's ( /25's smaller blocks )and /22's ( /26's smaller blocks ) NumberOfAZs : Type : Number AllowedValues : - 2 - 4 Default : 2 Description : Availability Zones - 2 = 2 per Tier, 4 = 4 per Tier Environment : Description : Choose VPC Type Type : String AllowedValues : - dev - test - prod Conditions : Build4AZs : !Equals [ !Ref NumberOfAZs , 4 ] CidrBit8 : !Equals [ !Ref Cidr , 20 ] CidrBit7 : !Equals [ !Ref Cidr , 21 ] CidrBit6 : !Equals [ !Ref Cidr , 22 ] ############################################### ### Three Tier VPC #### ############################################### Resources : VPC : Type : AWS::EC2::VPC Properties : CidrBlock : !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]] EnableDnsHostnames : true EnableDnsSupport : true Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"vpc\" ]] DhcpOptions : Type : AWS::EC2::DHCPOptions Properties : DomainName : !Join [ '-' , [ !Ref ProjectName , \"three-tier.org\" ]] DomainNameServers : - AmazonProvidedDNS Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"dopt\" ]] VPCDHCPOptionsAssociation : Type : AWS::EC2::VPCDHCPOptionsAssociation Properties : VpcId : { Ref : VPC } DhcpOptionsId : { Ref : DhcpOptions } InternetGateway : Type : AWS::EC2::InternetGateway DependsOn : VPC Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , !Ref Environment , \"three-tier\" , \"igw\" ]] VPCGatewayAttachment : Type : AWS::EC2::VPCGatewayAttachment Properties : VpcId : !Ref VPC InternetGatewayId : !Ref InternetGateway ############################################### ### Public/ALB Tier (inbound/outbound) #### ############################################### PublicRouteTableA : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1a\" ]] VpcId : !Ref VPC PublicRouteTableB : Type : AWS::EC2::RouteTable DependsOn : VPCGatewayAttachment Properties : Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"rt-1b\" ]] VpcId : !Ref VPC ############################################### PublicSubnet1 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 0 , !GetAZs '' ] CidrBlock : !Select [ 0 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1a\" ]] VpcId : !Ref VPC PublicSubnet2 : Type : AWS::EC2::Subnet Properties : AvailabilityZone : !Select [ 1 , !GetAZs '' ] CidrBlock : !Select [ 1 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1b\" ]] VpcId : !Ref VPC PublicSubnet3 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 2 , !GetAZs '' ] CidrBlock : !Select [ 2 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1c\" ]] VpcId : !Ref VPC PublicSubnet4 : Type : AWS::EC2::Subnet Condition : Build4AZs Properties : AvailabilityZone : !Select [ 3 , !GetAZs '' ] CidrBlock : !Select [ 3 , !Cidr [ !Join [ '' , [ !Ref CidrBlock1 , \"/\" , !Ref Cidr ]], 12 , !If [ CidrBit8 , 8 , !If [ CidrBit7 , 7 , 6 ]]]] MapPublicIpOnLaunch : false Tags : - Key : Name Value : !Join [ '-' , [ !Ref ProjectName , \"public\" , \"subnet-1d\" ]] VpcId : !Ref VPC ############################################### PublicSubnetAssoc1 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet1 PublicSubnetAssoc2 : Type : AWS::EC2::SubnetRouteTableAssociation Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet2 PublicSubnetAssoc3 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableA SubnetId : !Ref PublicSubnet3 PublicSubnetAssoc4 : Type : AWS::EC2::SubnetRouteTableAssociation Condition : Build4AZs Properties : RouteTableId : !Ref PublicRouteTableB SubnetId : !Ref PublicSubnet4","title":"Three Tier VPC Cloudformation Template"},{"location":"cloud/azure/intro/","text":"Comming Soon \u00b6","title":"Introduction"},{"location":"cloud/azure/intro/#comming-soon","text":"","title":"Comming Soon"},{"location":"cloud/azure/landing-zones/","text":"Azure Landing Zone Architecture \u00b6 A landing zone is a hhierarchical approach used to group subscriptions to provide scalability, security, governance, networking and identity Landing Zone Description Platform centralized services such as networking, identity, security, and management services. Application environments such as corp, dmz, external applications. Sandbox labs and validation proof of concepts","title":"Landing Zones"},{"location":"cloud/azure/landing-zones/#azure-landing-zone-architecture","text":"A landing zone is a hhierarchical approach used to group subscriptions to provide scalability, security, governance, networking and identity Landing Zone Description Platform centralized services such as networking, identity, security, and management services. Application environments such as corp, dmz, external applications. Sandbox labs and validation proof of concepts","title":"Azure Landing Zone Architecture"},{"location":"cloud/azure/mgmt-groups/","text":"Management groups \u00b6 used to efficiently manage access, policies, and compliance in a multi-subscription environment. simplify management and security of subscriptions, resource groups, and resources. all associated subscriptions inherit governance conditions. A policy applied to management group that restrict resource creation to only authorized regions would be applied to all nested management groups, subscriptions and resources Management Group and Subscription Hierarchy \u00b6 Management groups can be nested to provide governance based on usage, role, or environment. This simplifies security policy management. A subscription cam be moved from one management group to another inheriting any security policy associated with the new management group. Management Groups Facts \u00b6 10,000 Management Groups per directory 6 levels of depth per management group not including the Root or Subscription level Management Groups or Subscription can only belong to a single parents. A management group can have multiple children - sub management groups and multiple subscriptions Root Management Group Facts \u00b6 A directory has a single top-level root management group call Tentant root group Root management group cannot be moved or deleted Landing Zones \u00b6 Reference: Management Groups - Landing Zone Management group Description Intermediate Root Management Group This management group is located directly under the tenant root group. Created with a prefix provided by the organization, which purposely avoids the usage of the root group so that organizations can move existing Azure subscriptions into the hierarchy. It also enables future scenarios. This management group is a parent to all the other management groups created by the Azure landing zone accelerator. Platform This management group contains all the platform child management groups, like management, connectivity, and identity. Management This management group contains a dedicated subscription for management, monitoring, and security. This subscription will host an Azure Log Analytics workspace, including associated solutions, and an Azure Automation account. Connectivity This management group contains a dedicated subscription for connectivity. This subscription will host the Azure networking resources required for the platform, like Azure Virtual WAN, Azure Firewall, and Azure DNS private zones. Identity This management group contains a dedicated subscription for identity. This subscription is a placeholder for Windows Server Active Directory Domain Services (AD DS) virtual machines (VMs) or Azure Active Directory Domain Services. The subscription also enables AuthN or AuthZ for workloads within the landing zones. Specific Azure policies are assigned to harden and manage the resources in the identity subscription. Landing Zones The parent management group for all the landing zone child management groups. It will have workload agnostic Azure policies assigned to ensure workloads are secure and compliant. Online The dedicated management group for online landing zones. This group is for workloads that might require direct internet inbound/outbound connectivity or for workloads that might not require a virtual network. Corp The dedicated management group for corporate landing zones. This group is for workloads that require connectivity or hybrid connectivity with the corporate network via the hub in the connectivity subscription. Sandboxes The dedicated management group for subscriptions that will only be used for testing and exploration by an organization. These subscriptions will be securely disconnected from the corporate and online landing zones. Sandboxes also have a less restrictive set of policies assigned to enable testing, exploration, and configuration of Azure services. Decommissioned The dedicated management group for landing zones that are being canceled. Canceled landing zones will be moved to this management group before deletion by Azure after 30-60 days. Note The above is just a proposal. Some organizations may consider making changes to this hierarchy in order to make relevant to their requirements and environment.","title":"Azure Management Groups"},{"location":"cloud/azure/mgmt-groups/#management-groups","text":"used to efficiently manage access, policies, and compliance in a multi-subscription environment. simplify management and security of subscriptions, resource groups, and resources. all associated subscriptions inherit governance conditions. A policy applied to management group that restrict resource creation to only authorized regions would be applied to all nested management groups, subscriptions and resources","title":"Management groups"},{"location":"cloud/azure/mgmt-groups/#management-group-and-subscription-hierarchy","text":"Management groups can be nested to provide governance based on usage, role, or environment. This simplifies security policy management. A subscription cam be moved from one management group to another inheriting any security policy associated with the new management group.","title":"Management Group and Subscription Hierarchy"},{"location":"cloud/azure/mgmt-groups/#management-groups-facts","text":"10,000 Management Groups per directory 6 levels of depth per management group not including the Root or Subscription level Management Groups or Subscription can only belong to a single parents. A management group can have multiple children - sub management groups and multiple subscriptions","title":"Management Groups Facts"},{"location":"cloud/azure/mgmt-groups/#root-management-group-facts","text":"A directory has a single top-level root management group call Tentant root group Root management group cannot be moved or deleted","title":"Root Management Group Facts"},{"location":"cloud/azure/mgmt-groups/#landing-zones","text":"Reference: Management Groups - Landing Zone Management group Description Intermediate Root Management Group This management group is located directly under the tenant root group. Created with a prefix provided by the organization, which purposely avoids the usage of the root group so that organizations can move existing Azure subscriptions into the hierarchy. It also enables future scenarios. This management group is a parent to all the other management groups created by the Azure landing zone accelerator. Platform This management group contains all the platform child management groups, like management, connectivity, and identity. Management This management group contains a dedicated subscription for management, monitoring, and security. This subscription will host an Azure Log Analytics workspace, including associated solutions, and an Azure Automation account. Connectivity This management group contains a dedicated subscription for connectivity. This subscription will host the Azure networking resources required for the platform, like Azure Virtual WAN, Azure Firewall, and Azure DNS private zones. Identity This management group contains a dedicated subscription for identity. This subscription is a placeholder for Windows Server Active Directory Domain Services (AD DS) virtual machines (VMs) or Azure Active Directory Domain Services. The subscription also enables AuthN or AuthZ for workloads within the landing zones. Specific Azure policies are assigned to harden and manage the resources in the identity subscription. Landing Zones The parent management group for all the landing zone child management groups. It will have workload agnostic Azure policies assigned to ensure workloads are secure and compliant. Online The dedicated management group for online landing zones. This group is for workloads that might require direct internet inbound/outbound connectivity or for workloads that might not require a virtual network. Corp The dedicated management group for corporate landing zones. This group is for workloads that require connectivity or hybrid connectivity with the corporate network via the hub in the connectivity subscription. Sandboxes The dedicated management group for subscriptions that will only be used for testing and exploration by an organization. These subscriptions will be securely disconnected from the corporate and online landing zones. Sandboxes also have a less restrictive set of policies assigned to enable testing, exploration, and configuration of Azure services. Decommissioned The dedicated management group for landing zones that are being canceled. Canceled landing zones will be moved to this management group before deletion by Azure after 30-60 days. Note The above is just a proposal. Some organizations may consider making changes to this hierarchy in order to make relevant to their requirements and environment.","title":"Landing Zones"},{"location":"cloud/azure/networking/","text":"Virtual networks \u00b6 Features \u00b6 private and secure infrastructure VM residing inside a virtual network are able to privately communicate with each other access other azure resources Network Segmentation Virtual Networks are isolated from each other Per Subscription / Region VNETs are region and subscription specific. Components \u00b6 Subnets Subnets devide a virtual network into smaller segments. These segments can have unique security policies from each other. Some services require dedicated subnets such as network gateways, Bastion, and SQL Managed Instances Network Interfaces Network interfaces are use to connect virtuals machines to virtual networks. a virtual machine can have network interfaces in different subnets Network Security Groups (NSGs) Security groups filter inbound/outbound source/destination IP address/Port traffic based on a priority list of rules. they can be associated to either subnets or network interfaces . NSGs are region specific ( just like VMs ) Application Security Groups (ASGs) ASGs are used to group network interfaces based on purpose/usage. an ASG is similar to a tag on the network interface. a Network Security Group Rule can it destination set to an ASG. graph TD subgraph D[Virtual Private Network 10.0.0.0/26] subgraph E[Subnet 10.0.1.0/24] 1[Virtual Machine 1] 2[Application Security Group: ASG1] --> 1 end subgraph F[Subnet 10.0.2.0/24] 3[Virtual Machine 3] 4[Application Security Group: ASG1] --> 3 end 5[Network Security Group: NSG1<br>Direction: Inbound<br>Source: Internet<br>Destination: ASG1<br>Service: HTTPS<br>Action: Allow] end style 4 fill:#F0FFFF style 2 fill:#F0FFFF style D fill:#FFFFFF style 5 fill:#F0FFFF style E fill:#F0F8FF style F fill:#F0F8FF Azure Firewalls \u00b6 Features \u00b6 Azure Firewall as a Service is used to provide monitor and protection based on rules between virtual network egress/ingress traffic provides defense in depth Azure firewall is deployed between VNET 1 and VNET2 and the Internet. incomming traffic from the internet will be inspected by the Azure firewall before allowing or denying access to VNET1/VNET2 graph TD subgraph D[Azure] subgraph A[Virtual Network1] subgraph AA[Subnet] AAA[VM] end end subgraph B[Virtual Network1] subgraph BB[Subnet] BBB[VM] end end subgraph C[Virtual Network1] subgraph CC[Subnet] CCC[Azure Firewall] end end end F[Internet] style D fill:#FFFFFF style A fill:#F0FFFF style B fill:#F0FFFF style C fill:#F0FFFF style AA fill:#FFFFFF style BB fill:#FFFFFF style CC fill:#FFFFFF style AAA fill:#F0FFFF style BBB fill:#F0FFFF style CCC fill:#F0FFFF Endpoint Services \u00b6 A service endpoints provide private connectivity between Virtual Networks and a range of Azure services, including Azure Storage, SQL Databases, and Key Vault. communication travels across Azure backbone graph TD subgraph D[Azure] subgraph A[fa:fa-bucket Azure Storage] end subgraph C[fa:fa-network-wired Virtual Network] subgraph CC[Subnet] CCC[Azure Firewall] end end end F[Internet] style D fill:#FFFFFF style A fill:#F0FFFF style C fill:#F0FFFF style CC fill:#FFFFFF style CCC fill:#F0FFFF Private Links \u00b6 provide private connectivity to Azure PaaS services. accessible on connected virtual networks and globally peered networks. DNS Integration supported Private Endpoint \u00b6 a managed network interface used to provide connectivity to a private link Service Endpoints Private Endpoints Provides connectivity from a subnet to an entire Azure service cannot be used by on-premises networks uses routes to direct traffic Provides connectivity to single instance of an entire Azure service supports connected routes ( transitive routing ) integrates with DNS data transfer fees(inbound/outbound) Azure Bastion \u00b6 provides a managed secure remote management portal supports RDP and SSH supports Network Security Groups (NSGs) Virtual Network Peering \u00b6 Virtual Network Peerings provide connectivity between virtual networks within regions, across regions and subscriptions Peering connections must be created in both directions Non-transitive CIDR must not overlap Default Routes - The default route list has grown and is Azure managed. Azure is using the \"more specific\" approach - if there is no more specific drop all traffic. Address Prefix Next Hop Description Virtual network address range Virtual Network routes traffic within the virtual network 0.0.0.0/0 Internet Default route to the internet 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 None Drops private Ip address ranges that are not part of the virtual network 100.64.0.0/10 None Drops shared address space traffic Custom Routes are user-defined or learned via BGP Route Tables \u00b6 can be associated to subnets in different VPCs. ( what would be a use-case for this?) Gateways \u00b6 Virtual Network Gateway provides either VPN or ExpressRoute connectivity to Azure. requires a special gateway subnet with a minimun of a /27 CIDR block Similar to an AWS VGW - its VPC specific VPN Gateway provides external connectivity - on-premises networks, cloud providers, or remote devices supports site to site, multiple sites, and point to site connections route-based VPN and policy-based connections ExpressRoute direct, private connection between on-premises network and Azure connectivity to Azure VNets using private peering or Azure services using microsoft services connection types: IPVPN - integrates with MPLS (VPLS) Point-to-Point Ethernet (Ethernet Private Links - EPLs) CloudExchange to connect from co-locations VPN Gateway Express Route - connects on-premises networks and other clouds - connects only to virtual networks - connects via the internet - connects on-premises networks - connects to virtual networks and microsoft services - connects via dedicated, private connections Virtual WAN \u00b6 Virtual WANs are used to manage communication between multiple virtual networks, on-premises networks, and remote sites. It also improves performance by using azure backbone. While the concept of Virtual WAN is global, the actual Virtual WAN resource is Resource Manager-based and deployed regionally. If the virtual WAN region itself were to have an issue, all hubs in that virtual WAN will continue to function as is, but the user won't be able to create new hubs until the virtual WAN region is available. Virtual WAN is assigned a region. However, Virtual WAN resources such as Hubs and Gateways can be in any region. managed hub-and-spoke provides connecitivity between virtual networks, on-premises networks and remote workers one hub per region regional hubs are dynamically connected to each other similar to an AWS Transit Gateway Load balancing \u00b6 Load Balancer Application Gateway - Layer 4 / TCP/IP Applications - load balancing based on source/destination - low latency - Layer 7 - HTTP/HTTPs based application - load balancing based on source/destination/hostname/path - Web Application Firewall is supported","title":"Azure Networking"},{"location":"cloud/azure/networking/#virtual-networks","text":"","title":"Virtual networks"},{"location":"cloud/azure/networking/#features","text":"private and secure infrastructure VM residing inside a virtual network are able to privately communicate with each other access other azure resources Network Segmentation Virtual Networks are isolated from each other Per Subscription / Region VNETs are region and subscription specific.","title":"Features"},{"location":"cloud/azure/networking/#components","text":"Subnets Subnets devide a virtual network into smaller segments. These segments can have unique security policies from each other. Some services require dedicated subnets such as network gateways, Bastion, and SQL Managed Instances Network Interfaces Network interfaces are use to connect virtuals machines to virtual networks. a virtual machine can have network interfaces in different subnets Network Security Groups (NSGs) Security groups filter inbound/outbound source/destination IP address/Port traffic based on a priority list of rules. they can be associated to either subnets or network interfaces . NSGs are region specific ( just like VMs ) Application Security Groups (ASGs) ASGs are used to group network interfaces based on purpose/usage. an ASG is similar to a tag on the network interface. a Network Security Group Rule can it destination set to an ASG. graph TD subgraph D[Virtual Private Network 10.0.0.0/26] subgraph E[Subnet 10.0.1.0/24] 1[Virtual Machine 1] 2[Application Security Group: ASG1] --> 1 end subgraph F[Subnet 10.0.2.0/24] 3[Virtual Machine 3] 4[Application Security Group: ASG1] --> 3 end 5[Network Security Group: NSG1<br>Direction: Inbound<br>Source: Internet<br>Destination: ASG1<br>Service: HTTPS<br>Action: Allow] end style 4 fill:#F0FFFF style 2 fill:#F0FFFF style D fill:#FFFFFF style 5 fill:#F0FFFF style E fill:#F0F8FF style F fill:#F0F8FF","title":"Components"},{"location":"cloud/azure/networking/#azure-firewalls","text":"","title":"Azure Firewalls"},{"location":"cloud/azure/networking/#features_1","text":"Azure Firewall as a Service is used to provide monitor and protection based on rules between virtual network egress/ingress traffic provides defense in depth Azure firewall is deployed between VNET 1 and VNET2 and the Internet. incomming traffic from the internet will be inspected by the Azure firewall before allowing or denying access to VNET1/VNET2 graph TD subgraph D[Azure] subgraph A[Virtual Network1] subgraph AA[Subnet] AAA[VM] end end subgraph B[Virtual Network1] subgraph BB[Subnet] BBB[VM] end end subgraph C[Virtual Network1] subgraph CC[Subnet] CCC[Azure Firewall] end end end F[Internet] style D fill:#FFFFFF style A fill:#F0FFFF style B fill:#F0FFFF style C fill:#F0FFFF style AA fill:#FFFFFF style BB fill:#FFFFFF style CC fill:#FFFFFF style AAA fill:#F0FFFF style BBB fill:#F0FFFF style CCC fill:#F0FFFF","title":"Features"},{"location":"cloud/azure/networking/#endpoint-services","text":"A service endpoints provide private connectivity between Virtual Networks and a range of Azure services, including Azure Storage, SQL Databases, and Key Vault. communication travels across Azure backbone graph TD subgraph D[Azure] subgraph A[fa:fa-bucket Azure Storage] end subgraph C[fa:fa-network-wired Virtual Network] subgraph CC[Subnet] CCC[Azure Firewall] end end end F[Internet] style D fill:#FFFFFF style A fill:#F0FFFF style C fill:#F0FFFF style CC fill:#FFFFFF style CCC fill:#F0FFFF","title":"Endpoint Services"},{"location":"cloud/azure/networking/#private-links","text":"provide private connectivity to Azure PaaS services. accessible on connected virtual networks and globally peered networks. DNS Integration supported","title":"Private Links"},{"location":"cloud/azure/networking/#private-endpoint","text":"a managed network interface used to provide connectivity to a private link Service Endpoints Private Endpoints Provides connectivity from a subnet to an entire Azure service cannot be used by on-premises networks uses routes to direct traffic Provides connectivity to single instance of an entire Azure service supports connected routes ( transitive routing ) integrates with DNS data transfer fees(inbound/outbound)","title":"Private Endpoint"},{"location":"cloud/azure/networking/#azure-bastion","text":"provides a managed secure remote management portal supports RDP and SSH supports Network Security Groups (NSGs)","title":"Azure Bastion"},{"location":"cloud/azure/networking/#virtual-network-peering","text":"Virtual Network Peerings provide connectivity between virtual networks within regions, across regions and subscriptions Peering connections must be created in both directions Non-transitive CIDR must not overlap Default Routes - The default route list has grown and is Azure managed. Azure is using the \"more specific\" approach - if there is no more specific drop all traffic. Address Prefix Next Hop Description Virtual network address range Virtual Network routes traffic within the virtual network 0.0.0.0/0 Internet Default route to the internet 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 None Drops private Ip address ranges that are not part of the virtual network 100.64.0.0/10 None Drops shared address space traffic Custom Routes are user-defined or learned via BGP","title":"Virtual Network Peering"},{"location":"cloud/azure/networking/#route-tables","text":"can be associated to subnets in different VPCs. ( what would be a use-case for this?)","title":"Route Tables"},{"location":"cloud/azure/networking/#gateways","text":"Virtual Network Gateway provides either VPN or ExpressRoute connectivity to Azure. requires a special gateway subnet with a minimun of a /27 CIDR block Similar to an AWS VGW - its VPC specific VPN Gateway provides external connectivity - on-premises networks, cloud providers, or remote devices supports site to site, multiple sites, and point to site connections route-based VPN and policy-based connections ExpressRoute direct, private connection between on-premises network and Azure connectivity to Azure VNets using private peering or Azure services using microsoft services connection types: IPVPN - integrates with MPLS (VPLS) Point-to-Point Ethernet (Ethernet Private Links - EPLs) CloudExchange to connect from co-locations VPN Gateway Express Route - connects on-premises networks and other clouds - connects only to virtual networks - connects via the internet - connects on-premises networks - connects to virtual networks and microsoft services - connects via dedicated, private connections","title":"Gateways"},{"location":"cloud/azure/networking/#virtual-wan","text":"Virtual WANs are used to manage communication between multiple virtual networks, on-premises networks, and remote sites. It also improves performance by using azure backbone. While the concept of Virtual WAN is global, the actual Virtual WAN resource is Resource Manager-based and deployed regionally. If the virtual WAN region itself were to have an issue, all hubs in that virtual WAN will continue to function as is, but the user won't be able to create new hubs until the virtual WAN region is available. Virtual WAN is assigned a region. However, Virtual WAN resources such as Hubs and Gateways can be in any region. managed hub-and-spoke provides connecitivity between virtual networks, on-premises networks and remote workers one hub per region regional hubs are dynamically connected to each other similar to an AWS Transit Gateway","title":"Virtual WAN"},{"location":"cloud/azure/networking/#load-balancing","text":"Load Balancer Application Gateway - Layer 4 / TCP/IP Applications - load balancing based on source/destination - low latency - Layer 7 - HTTP/HTTPs based application - load balancing based on source/destination/hostname/path - Web Application Firewall is supported","title":"Load balancing"},{"location":"cloud/azure/tshoo/","text":"Creating Virtual Hub \u00b6 Virtual hub is not enabled to allow Router ASN modification. However, it's not grayed out so you can change with without having the option enabled. See error below when changing it. { \"code\" : \"DeploymentFailed\" , \"message\" : \"At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.\" , \"details\" : [ { \"code\" : \"CustomAsnNotEnabledForVirtualHub\" , \"message\" : \"Virtual hub is not enabled to allow Router ASN modification. Please set ASN to 65515 or contact Support for enabling virtual hub to allow modification.\" } ] } VPN (Site to site) Gateway: This gateway is being updated. It may take upto 30 minutes for the update .","title":"Azure Troubleshooting Notes"},{"location":"cloud/azure/tshoo/#creating-virtual-hub","text":"Virtual hub is not enabled to allow Router ASN modification. However, it's not grayed out so you can change with without having the option enabled. See error below when changing it. { \"code\" : \"DeploymentFailed\" , \"message\" : \"At least one resource deployment operation failed. Please list deployment operations for details. Please see https://aka.ms/DeployOperations for usage details.\" , \"details\" : [ { \"code\" : \"CustomAsnNotEnabledForVirtualHub\" , \"message\" : \"Virtual hub is not enabled to allow Router ASN modification. Please set ASN to 65515 or contact Support for enabling virtual hub to allow modification.\" } ] } VPN (Site to site) Gateway: This gateway is being updated. It may take upto 30 minutes for the update .","title":"Creating Virtual Hub"},{"location":"cloud/gcp/gcloud/","text":"Review current configuration \u00b6 Current configuration $ gcloud config configurations list NAME IS_ACTIVE ACCOUNT PROJECT COMPUTE_DEFAULT_ZONE COMPUTE_DEFAULT_REGION default True kg48037@mykronos.com shd-cus-host01-7f07 update account $ gcloud config set account kg48037@mykronos.com Updated property [ core/account ] . update project $ gcloud config set project rdy-dev-cld-usa-dev01 Updated property [ core/project ] . New configuration shell $ gcloud config configurations list NAME IS_ACTIVE ACCOUNT PROJECT COMPUTE_DEFAULT_ZONE COMPUTE_DEFAULT_REGION default True kg48037@mykronos.com rdy-dev-cld-usa-dev01","title":"Gcloud Command Overview"},{"location":"cloud/gcp/gcloud/#review-current-configuration","text":"Current configuration $ gcloud config configurations list NAME IS_ACTIVE ACCOUNT PROJECT COMPUTE_DEFAULT_ZONE COMPUTE_DEFAULT_REGION default True kg48037@mykronos.com shd-cus-host01-7f07 update account $ gcloud config set account kg48037@mykronos.com Updated property [ core/account ] . update project $ gcloud config set project rdy-dev-cld-usa-dev01 Updated property [ core/project ] . New configuration shell $ gcloud config configurations list NAME IS_ACTIVE ACCOUNT PROJECT COMPUTE_DEFAULT_ZONE COMPUTE_DEFAULT_REGION default True kg48037@mykronos.com rdy-dev-cld-usa-dev01","title":"Review current configuration"},{"location":"cloud/gcp/intro/","text":"Comming Soon \u00b6","title":"Introduction"},{"location":"cloud/gcp/intro/#comming-soon","text":"","title":"Comming Soon"},{"location":"contact-us/aboutme/","text":"Gtz4All \u00b6 Gtz4all is designed to provide step by step procedures in multiple areas in an enterprise environment with a focus on automation and simplicity.","title":"Aboutme"},{"location":"contact-us/aboutme/#gtz4all","text":"Gtz4all is designed to provide step by step procedures in multiple areas in an enterprise environment with a focus on automation and simplicity.","title":"Gtz4All"},{"location":"contact-us/intro/","text":"Gtz4All \u00b6 The objective of this guide is to provide an guidance and best practices","title":"About Me"},{"location":"contact-us/intro/#gtz4all","text":"The objective of this guide is to provide an guidance and best practices","title":"Gtz4All"},{"location":"devops/intro/","text":"Scripting and Automation. \u00b6 Terraform Documentation terraform is currently the leading devops provider. Ansible Documentation ansible is currently the leading devops provider. Docker Documentation docker is currently the leading devops provider. Kubernetes Documentation kubernetes is currently the leading devops provider. Web Services Documentation python is currently the leading devops provider.","title":"Introduction"},{"location":"devops/intro/#scripting-and-automation","text":"Terraform Documentation terraform is currently the leading devops provider. Ansible Documentation ansible is currently the leading devops provider. Docker Documentation docker is currently the leading devops provider. Kubernetes Documentation kubernetes is currently the leading devops provider. Web Services Documentation python is currently the leading devops provider.","title":"Scripting and Automation."},{"location":"devops/ansible/intro/","text":"Ansible Documentation ansible is currently the leading devops provider.","title":"Introduction"},{"location":"devops/databases/intro/","text":"Databases \u00b6","title":"Introduction"},{"location":"devops/databases/intro/#databases","text":"","title":"Databases"},{"location":"devops/databases/mongodb/","text":"Over the past years, I've been searching for an easy to use database that can interact with other tools like ansible and python. Since I didnt have one at the moment, I started using CVS files with the plan to migrate to a database in the future. MongoDB is an open-source, document-oriented, NoSQL database program which uses JSON-like document schemas, making it easy for other tools to work with it. MongoDB provides tools that can import/export CSV files. MongoDB being an non-rational database can be used to store different type of data such as key-value pairs, JSON data, CLI configuration and even images https://www.mongodb.com Document model Database Document-Oriented NoSQL DB stores and retrieves data as a Key-value pair, but the value part is stored as a document in JSON or XML formats. Some MongoDB Advatanges Store unstructured, semi-structured, or structured data. Uses easy to update,flexible schemas and fields. Open Source Mongo DB Structure Type description usage Databases hold one or more collections of documents no create option instead you just try to use it and it gets created. Collection stores documents, analogous to rational database tables same as database, applies to MongoDB CLI and Python. Mongo-Express Mongo-Express is an open-source Web-based MongoDB admin interface written with Node.js, Express and Bootstrap3. It provides an easy to read, visual represtation of our databases https://github.com/mongo-express/mongo-express MongoDB Test Drive \u00b6 Using docker to test drive both mongodb and mongo-express Mongo Dockerfile This dockerfile creates both a mongodb and mongo-express instance version : '3.1' services : mongodb : container_name : mongodb image : mongo restart : always environment : ## MongoDB Credentials MONGO_INITDB_ROOT_USERNAME : ${DBUSER} MONGO_INITDB_ROOT_PASSWORD : ${DBPASS} mongo-express : container_name : mongogui image : mongo-express restart : always ports : - 8081:8081 environment : ## MongoDB Container Name ME_CONFIG_MONGODB_SERVER : mongodb ## MongoDB Credentials ME_CONFIG_MONGODB_ADMINUSERNAME : ${DBUSER} ME_CONFIG_MONGODB_ADMINPASSWORD : ${DBPASS} ## MongoDB Web UI Credentials ME_CONFIG_BASICAUTH_USERNAME : ${DBUSER} ME_CONFIG_BASICAUTH_PASSWORD : ${DBPASS} Run Containers DBUSER = admin DBPASS = admin docker-compose up -d MongoDB CLI \u00b6 Install sudo apt update && sudo apt install mongodb-clients -y Export Credentials export DBUSER = admin DBPASS = admin echo $DBUSER echo $DBPASS Mongo Container IP export MONGODB_IP = $( docker inspect mongodb --format '{range.NetworkSettings.Networks }{.IPAddress}{ end }' ) echo $MONGODB_IP Connect to MongoDB mongo mongodb:// $MONGODB_IP :27017/ -u $DBUSER -p $DBPASS --authenticationDatabase \"admin\" MongoDB CLI connection output :~$ mongo mongodb:// $MONGODB_IP :27017/ -u $DBUSER -p $DBPASS --authenticationDatabase \"admin\" MongoDB shell version v3.6.3 connecting to: mongodb://172.18.0.2:27017/ MongoDB server version: 4 .4.6 WARNING: shell and server versions do not match Server has startup warnings: { \"t\" : { \" $date \" : \"2021-06-07T18:10:19.421+00:00\" } , \"s\" : \"I\" , \"c\" : \"STORAGE\" , \"id\" :22297, \"ctx\" : \"initandlisten\" , \"msg\" : \"Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\" , \"tags\" : [ \"startupWarnings\" ]} { \"t\" : { \" $date \" : \"2021-06-07T18:10:20.787+00:00\" } , \"s\" : \"W\" , \"c\" : \"CONTROL\" , \"id\" :22167, \"ctx\" : \"initandlisten\" , \"msg\" : \"You are running on a NUMA machine. We suggest launching mongod like this to avoid performance problems: numactl --interleave=all mongod [other options]\" , \"tags\" : [ \"startupWarnings\" ]} > List all databases > db.adminCommand ( { listDatabases: 1 } ) { \"databases\" : [ { \"name\" : \"admin\" , \"sizeOnDisk\" : 102400 , \"empty\" : false } , { \"name\" : \"config\" , \"sizeOnDisk\" : 12288 , \"empty\" : false } , { \"name\" : \"local\" , \"sizeOnDisk\" : 73728 , \"empty\" : false } ] , \"totalSize\" : 188416 , \"ok\" : 1 } > Create new database use DataCenterDB create a collection and insert items ## use - creates database use DataCenterDB ## db.[collection-name].insert - creates collection if it does not already exist db.DataCenter1.insert ([ { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } , { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } , { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } , { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } ]) Insert output BulkWriteResult ({ \"writeErrors\" : [ ] , \"writeConcernErrors\" : [ ] , \"nInserted\" : 4 , \"nUpserted\" : 0 , \"nMatched\" : 0 , \"nModified\" : 0 , \"nRemoved\" : 0 , \"upserted\" : [ ] }) Query database find() : query data from MongoDB collection. pretty() : display the results in a JSON formatted way. ## db.[collection-name].find() use DataCenterDB > db.DataCenter1.find () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b958\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b959\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } > db.DataCenter1.find () .pretty () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b958\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b959\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } ## Find an specific item > db.DataCenter1.find ({ \"tag\" : \"DIST\" }) .pretty () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } > MongoDB Python 3 Interactive Mode \u00b6 Install pip3 install pymongo Interactive Mode import os import pymongo dbpass = os . environ . get ( 'DBPASS' ) dbuser = os . environ . get ( 'DBUSER' ) dbip = os . environ . get ( 'MONGODB_IP' ) dbclient = pymongo . MongoClient ( f \"mongodb:// { dbip } :27017/\" , username = dbuser , password = dbpass ) list database option 1 for db in dbclient . list_databases (): print ( db ) * list database option 2 print ( list ( dbclient . list_databases ())) create database \"DataCenterDB\" DCdb = dbclient [ \"DataCenterDB\" ] create \"DataCenter1\" collection inside \"DataCenterDB\" DC1 = DCdb [ \"DataCenter1\" ] ## Add items to Collection updatedb = DC1 . insert ([ { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.1\" }, { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64512\" , \"lo0\" : \"10.168.1.2\" }, { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ]) create \"DataCenter1\" collection inside \"DataCenterDB\" DC2 = DCdb [ \"DataCenter2\" ] ## Add items to Collection updatedb = DC2 . insert ([ { \"name\" : \"COREROUTER2\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.2.1\" }, { \"name\" : \"COREROUTER2\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.2.2\" }, { \"name\" : \"DISTROUTER2\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.2.3\" }, { \"name\" : \"DISTROUTER2\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.2.2\" } ]) list collections print ( DCdb . list_collection_names ()) ## list output [ 'DataCenter2' , 'DataCenter1' ] query all items in collection print ( list ( DC1 . find ())) ## output [ { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda4\"\")\" , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.1\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda5\"\")\" , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64512\" , \"lo0\" : \"10.168.1.2\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda6\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda7\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ] query an item in collection print ( list ( DC1 . find ({ \"tag\" : \"DIST\" }))) ## output [ { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda6\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda7\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ] Conclusion This is the end of the mongoDB demo","title":"MongoDB"},{"location":"devops/databases/mongodb/#mongodb-test-drive","text":"Using docker to test drive both mongodb and mongo-express Mongo Dockerfile This dockerfile creates both a mongodb and mongo-express instance version : '3.1' services : mongodb : container_name : mongodb image : mongo restart : always environment : ## MongoDB Credentials MONGO_INITDB_ROOT_USERNAME : ${DBUSER} MONGO_INITDB_ROOT_PASSWORD : ${DBPASS} mongo-express : container_name : mongogui image : mongo-express restart : always ports : - 8081:8081 environment : ## MongoDB Container Name ME_CONFIG_MONGODB_SERVER : mongodb ## MongoDB Credentials ME_CONFIG_MONGODB_ADMINUSERNAME : ${DBUSER} ME_CONFIG_MONGODB_ADMINPASSWORD : ${DBPASS} ## MongoDB Web UI Credentials ME_CONFIG_BASICAUTH_USERNAME : ${DBUSER} ME_CONFIG_BASICAUTH_PASSWORD : ${DBPASS} Run Containers DBUSER = admin DBPASS = admin docker-compose up -d","title":"MongoDB Test Drive"},{"location":"devops/databases/mongodb/#mongodb-cli","text":"Install sudo apt update && sudo apt install mongodb-clients -y Export Credentials export DBUSER = admin DBPASS = admin echo $DBUSER echo $DBPASS Mongo Container IP export MONGODB_IP = $( docker inspect mongodb --format '{range.NetworkSettings.Networks }{.IPAddress}{ end }' ) echo $MONGODB_IP Connect to MongoDB mongo mongodb:// $MONGODB_IP :27017/ -u $DBUSER -p $DBPASS --authenticationDatabase \"admin\" MongoDB CLI connection output :~$ mongo mongodb:// $MONGODB_IP :27017/ -u $DBUSER -p $DBPASS --authenticationDatabase \"admin\" MongoDB shell version v3.6.3 connecting to: mongodb://172.18.0.2:27017/ MongoDB server version: 4 .4.6 WARNING: shell and server versions do not match Server has startup warnings: { \"t\" : { \" $date \" : \"2021-06-07T18:10:19.421+00:00\" } , \"s\" : \"I\" , \"c\" : \"STORAGE\" , \"id\" :22297, \"ctx\" : \"initandlisten\" , \"msg\" : \"Using the XFS filesystem is strongly recommended with the WiredTiger storage engine. See http://dochub.mongodb.org/core/prodnotes-filesystem\" , \"tags\" : [ \"startupWarnings\" ]} { \"t\" : { \" $date \" : \"2021-06-07T18:10:20.787+00:00\" } , \"s\" : \"W\" , \"c\" : \"CONTROL\" , \"id\" :22167, \"ctx\" : \"initandlisten\" , \"msg\" : \"You are running on a NUMA machine. We suggest launching mongod like this to avoid performance problems: numactl --interleave=all mongod [other options]\" , \"tags\" : [ \"startupWarnings\" ]} > List all databases > db.adminCommand ( { listDatabases: 1 } ) { \"databases\" : [ { \"name\" : \"admin\" , \"sizeOnDisk\" : 102400 , \"empty\" : false } , { \"name\" : \"config\" , \"sizeOnDisk\" : 12288 , \"empty\" : false } , { \"name\" : \"local\" , \"sizeOnDisk\" : 73728 , \"empty\" : false } ] , \"totalSize\" : 188416 , \"ok\" : 1 } > Create new database use DataCenterDB create a collection and insert items ## use - creates database use DataCenterDB ## db.[collection-name].insert - creates collection if it does not already exist db.DataCenter1.insert ([ { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } , { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } , { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } , { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } ]) Insert output BulkWriteResult ({ \"writeErrors\" : [ ] , \"writeConcernErrors\" : [ ] , \"nInserted\" : 4 , \"nUpserted\" : 0 , \"nMatched\" : 0 , \"nModified\" : 0 , \"nRemoved\" : 0 , \"upserted\" : [ ] }) Query database find() : query data from MongoDB collection. pretty() : display the results in a JSON formatted way. ## db.[collection-name].find() use DataCenterDB > db.DataCenter1.find () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b958\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b959\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } > db.DataCenter1.find () .pretty () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b958\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.1\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b959\" ) , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.1.2\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } ## Find an specific item > db.DataCenter1.find ({ \"tag\" : \"DIST\" }) .pretty () { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95a\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.1.3\" } { \"_id\" : ObjectId ( \"60be987af6652ebfdef9b95b\" ) , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.1.2\" } >","title":"MongoDB CLI"},{"location":"devops/databases/mongodb/#mongodb-python-3-interactive-mode","text":"Install pip3 install pymongo Interactive Mode import os import pymongo dbpass = os . environ . get ( 'DBPASS' ) dbuser = os . environ . get ( 'DBUSER' ) dbip = os . environ . get ( 'MONGODB_IP' ) dbclient = pymongo . MongoClient ( f \"mongodb:// { dbip } :27017/\" , username = dbuser , password = dbpass ) list database option 1 for db in dbclient . list_databases (): print ( db ) * list database option 2 print ( list ( dbclient . list_databases ())) create database \"DataCenterDB\" DCdb = dbclient [ \"DataCenterDB\" ] create \"DataCenter1\" collection inside \"DataCenterDB\" DC1 = DCdb [ \"DataCenter1\" ] ## Add items to Collection updatedb = DC1 . insert ([ { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.1\" }, { \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64512\" , \"lo0\" : \"10.168.1.2\" }, { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ]) create \"DataCenter1\" collection inside \"DataCenterDB\" DC2 = DCdb [ \"DataCenter2\" ] ## Add items to Collection updatedb = DC2 . insert ([ { \"name\" : \"COREROUTER2\" , \"tag\" : \"CORE\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.2.1\" }, { \"name\" : \"COREROUTER2\" , \"tag\" : \"CORE\" , \"asn\" : \"64522\" , \"lo0\" : \"10.168.2.2\" }, { \"name\" : \"DISTROUTER2\" , \"tag\" : \"DIST\" , \"asn\" : \"64523\" , \"lo0\" : \"10.168.2.3\" }, { \"name\" : \"DISTROUTER2\" , \"tag\" : \"DIST\" , \"asn\" : \"64521\" , \"lo0\" : \"10.168.2.2\" } ]) list collections print ( DCdb . list_collection_names ()) ## list output [ 'DataCenter2' , 'DataCenter1' ] query all items in collection print ( list ( DC1 . find ())) ## output [ { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda4\"\")\" , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.1\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda5\"\")\" , \"name\" : \"COREROUTER1\" , \"tag\" : \"CORE\" , \"asn\" : \"64512\" , \"lo0\" : \"10.168.1.2\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda6\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda7\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ] query an item in collection print ( list ( DC1 . find ({ \"tag\" : \"DIST\" }))) ## output [ { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda6\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64513\" , \"lo0\" : \"10.168.1.3\" }, { \"_id\" : \"ObjectId(\"\"60beaac074d25b62b989fda7\"\")\" , \"name\" : \"DISTROUTER1\" , \"tag\" : \"DIST\" , \"asn\" : \"64511\" , \"lo0\" : \"10.168.1.2\" } ] Conclusion This is the end of the mongoDB demo","title":"MongoDB Python 3 Interactive Mode"},{"location":"devops/docker/hugo.docker.container/","text":"Building a Docker Image \u00b6 Hugo Multi-Stage Dockerfile \u00b6 Multi-stage builds can use multiple FROM statements in the Dockerfile. Each FROM instruction can use its own base image. Any artifacts from each FROM can be copied to another stage. The last FROM statement is used as final image. Everything else is destroyed. ############################################ # Multi Stage- Hugo Static Page ############################################ ## Stage 1 - name 'build' FROM nginx:alpine as build ## Setting Arguments ARG HUGO_VERSION = \"0.72.0\" ARG STATIC_PAGE = \"\" ## Running commands inside container during build RUN apk add --update wget RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && \\ tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ mv hugo /usr/bin ## Copying local Hugo Static Site Directory to Container directory COPY ./ ${ STATIC_PAGE } /site WORKDIR /site ## Building Site RUN hugo ## Stage 2. FROM nginx:alpine ## copy /site/public folder created by the 'hugo' RUN command in Stage 1 to the nginx working directory. COPY --from = build /site/public /usr/share/nginx/html WORKDIR /usr/share/nginx/html * Changin config.toml baseURL value Local Testing : export BASE_URL =/ Gitlab Pages : export BASE_URL = https : // netgtz . gitlab . io / Since the BASE_URL variable includes \"/\" using \"|\" as delimiter instead shell command : sed - i \"s|BASE_URL|$BASE_URL|g\" config . toml sed -i \"s|BASE_URL| $BASE_URL |g\" netgtz.gitlab.io/config.toml * Building a Docker Image based on Dockerfile docker build --build-arg STATIC_PAGE = netgtz.gitlab.io -t hugo . * Running a container using the recently built image exposing container port 80 on local host port 80 docker run --rm -p 80 :80 -d --name hugoapp hugo Running a Docker Image \u00b6 Commonly used Docker commands docker run [OPTIONS] IMAGE [COMMAND] docker run [--rm -p 80:80 -dit --name hugoapp] hugo [/bin/ash] docker run --rm -p 80 :80 -dit --name hugoapp hugo /bin/ash ``` ###### OPTIONS Name | shorthand | Description -- | -- | -- --detach | -d | Run container in background and print container ID --interactive | -i | Keep STDIN open even if not attached --publish | -p | Publish local port to container port - -p 8080 :80 - 8080 = local_port, 80 = container_port --rm | --rm | Automatically remove the container when it exits --tty | -t | Allocate a pseudo-TTY --name | --name | Assign a name to the container * To attach to an already running container: ``` sh ## ubuntu - /bin/bash, Alpine - /bin/ash docker exec -it hugoapp /bin/ash Run the container in deattached (-d), interactive (-i) , terminal(-t) node \u00b6 this will allow the ducker to continue running /bin/bash docker run -it -d IMAGE_NAME bin/bash Create Multiple Directories ( -p) \u00b6 sh mkdir -p sbox/docker","title":"Building a Hugo Docker Containers"},{"location":"devops/docker/hugo.docker.container/#building-a-docker-image","text":"","title":"Building a Docker Image"},{"location":"devops/docker/hugo.docker.container/#hugo-multi-stage-dockerfile","text":"Multi-stage builds can use multiple FROM statements in the Dockerfile. Each FROM instruction can use its own base image. Any artifacts from each FROM can be copied to another stage. The last FROM statement is used as final image. Everything else is destroyed. ############################################ # Multi Stage- Hugo Static Page ############################################ ## Stage 1 - name 'build' FROM nginx:alpine as build ## Setting Arguments ARG HUGO_VERSION = \"0.72.0\" ARG STATIC_PAGE = \"\" ## Running commands inside container during build RUN apk add --update wget RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && \\ tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ mv hugo /usr/bin ## Copying local Hugo Static Site Directory to Container directory COPY ./ ${ STATIC_PAGE } /site WORKDIR /site ## Building Site RUN hugo ## Stage 2. FROM nginx:alpine ## copy /site/public folder created by the 'hugo' RUN command in Stage 1 to the nginx working directory. COPY --from = build /site/public /usr/share/nginx/html WORKDIR /usr/share/nginx/html * Changin config.toml baseURL value Local Testing : export BASE_URL =/ Gitlab Pages : export BASE_URL = https : // netgtz . gitlab . io / Since the BASE_URL variable includes \"/\" using \"|\" as delimiter instead shell command : sed - i \"s|BASE_URL|$BASE_URL|g\" config . toml sed -i \"s|BASE_URL| $BASE_URL |g\" netgtz.gitlab.io/config.toml * Building a Docker Image based on Dockerfile docker build --build-arg STATIC_PAGE = netgtz.gitlab.io -t hugo . * Running a container using the recently built image exposing container port 80 on local host port 80 docker run --rm -p 80 :80 -d --name hugoapp hugo","title":"Hugo Multi-Stage Dockerfile"},{"location":"devops/docker/hugo.docker.container/#running-a-docker-image","text":"Commonly used Docker commands docker run [OPTIONS] IMAGE [COMMAND] docker run [--rm -p 80:80 -dit --name hugoapp] hugo [/bin/ash] docker run --rm -p 80 :80 -dit --name hugoapp hugo /bin/ash ``` ###### OPTIONS Name | shorthand | Description -- | -- | -- --detach | -d | Run container in background and print container ID --interactive | -i | Keep STDIN open even if not attached --publish | -p | Publish local port to container port - -p 8080 :80 - 8080 = local_port, 80 = container_port --rm | --rm | Automatically remove the container when it exits --tty | -t | Allocate a pseudo-TTY --name | --name | Assign a name to the container * To attach to an already running container: ``` sh ## ubuntu - /bin/bash, Alpine - /bin/ash docker exec -it hugoapp /bin/ash","title":"Running a Docker Image"},{"location":"devops/docker/hugo.docker.container/#run-the-container-in-deattached-d-interactive-i-terminal-t-node","text":"this will allow the ducker to continue running /bin/bash docker run -it -d IMAGE_NAME bin/bash","title":"Run the container in deattached (-d), interactive (-i) , terminal(-t) node"},{"location":"devops/docker/hugo.docker.container/#create-multiple-directories-p","text":"sh mkdir -p sbox/docker","title":"Create Multiple Directories ( -p)"},{"location":"devops/docker/hugo.docker.troubleshooting/","text":"Building The Hugo Docker Image \u00b6 Hugo Single-Stage Dockerfile \u00b6 We are just removing the second stage in order to take a closer look FROM nginx:alpine as build RUN apk add --update \\ wget ARG HUGO_VERSION = \"0.72.0\" ARG STATIC_PAGE = \"\" RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && \\ tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ mv hugo /usr/bin COPY ./ ${ STATIC_PAGE } /site WORKDIR /site RUN hugo Build image and override multiple arguments (ARG) \u00b6 docker build --build-arg STATIC_PAGE = \"netgtz.gitlab.io\" --build-arg HUGO_VERSION = \"0.83.1\" -t hugo . Output \u00b6 :~/lab$ docker build --build-arg STATIC_PAGE = \"netgtz.gitlab.io\" --build-arg HUGO_VERSION = \"0.83.1\" -t hugo . Sending build context to Docker daemon 8 .536MB Step 1 /8 : FROM nginx:alpine as build alpine: Pulling from library/nginx 540db60ca938: Pull complete 0ae30075c5da: Pull complete 9da81141e74e: Pull complete b2e41dd2ded0: Pull complete 7f40e809fb2d: Pull complete 758848c48411: Pull complete Digest: sha256:0f8595aa040ec107821e0409a1dd3f7a5e989501d5c8d5b5ca1f955f33ac81a0 Status: Downloaded newer image for nginx:alpine ---> a6eb2a334a9f Step 2 /8 : RUN apk add --update wget ---> Running in 96e7303147c7 fetch https://dl-cdn.alpinelinux.org/alpine/v3.13/main/x86_64/APKINDEX.tar.gz fetch https://dl-cdn.alpinelinux.org/alpine/v3.13/community/x86_64/APKINDEX.tar.gz ( 1 /3 ) Installing libunistring ( 0 .9.10-r0 ) ( 2 /3 ) Installing libidn2 ( 2 .3.0-r0 ) ( 3 /3 ) Installing wget ( 1 .21.1-r1 ) Executing busybox-1.32.1-r6.trigger OK: 27 MiB in 45 packages Removing intermediate container 96e7303147c7 ---> 8c9b6b201585 Step 3 /8 : ARG HUGO_VERSION = \"0.72.0\" ---> Running in a4c26ace44df Removing intermediate container a4c26ace44df ---> 3ca9889ae589 Step 4 /8 : ARG STATIC_PAGE = \"\" ---> Running in b062a028b5b4 Removing intermediate container b062a028b5b4 ---> 44b5e545b113 Step 5 /8 : RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && mv hugo /usr/bin ---> Running in f172e6a54f49 Removing intermediate container f172e6a54f49 ---> 08ffd9933d8e Step 6 /8 : COPY ./ ${ STATIC_PAGE } /site ---> b99bdbfef0e1 Step 7 /8 : WORKDIR /site ---> Running in 55bbd1daf43d Removing intermediate container 55bbd1daf43d ---> cb83bc651786 Step 8 /8 : RUN hugo ---> Running in 19c79b409639 Start building sites \u2026 | EN -------------------+----- Pages | 32 Paginator pages | 0 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 372 ms Removing intermediate container 19c79b409639 ---> 772bcf6d1bf9 Successfully built 772bcf6d1bf9 Successfully tagged hugo:latest Current images \u00b6 ~/lab$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE hugo latest 772bcf6d1bf9 About a minute ago 81 .4MB nginx alpine a6eb2a334a9f 10 days ago 22 .6MB Running a container using the hugo image \u00b6 Using the command '/bin/ash' to keep the container running Exposing container port 80 on local port 80 Passing --rm to delete container after stopping it - no need to do 'docker rm [Container ID]' docker run --rm -p 80 :80 -dit --name hugoapp hugo /bin/ash Attaching to running container docker exec -it hugoapp /bin/ash Rerunning hugo command to generate site and get its Output ~/lab$ docker exec -it hugoapp /bin/ash /site # ls archetypes assets config.toml content i18n layouts public resources static themes /site # hugo Start building sites \u2026 | EN -------------------+----- Pages | 32 Paginator pages | 0 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 362 ms Moving hugo public folder content to nginx working directory mv public/* /usr/share/nginx/html/ Running the nginx server /usr/sbin/nginx Nginx Output sh /site # /usr/sbin/nginx 2021/06/04 22:01:54 [notice] 18#18: using the \"epoll\" event method 2021/06/04 22:01:54 [notice] 18#18: nginx/1.21.0 2021/06/04 22:01:54 [notice] 18#18: built by gcc 10.2.1 20201203 (Alpine 10.2.1_pre1) 2021/06/04 22:01:54 [notice] 18#18: OS: Linux 4.15.0-20-generic 2021/06/04 22:01:54 [notice] 18#18: getrlimit(RLIMIT_NOFILE): 1048576:1048576 /site # 2021/06/04 22:01:54 [notice] 19#19: start worker processes 2021/06/04 22:01:54 [notice] 19#19: start worker process 20","title":"Working with Hugo Container"},{"location":"devops/docker/hugo.docker.troubleshooting/#building-the-hugo-docker-image","text":"","title":"Building The Hugo Docker Image"},{"location":"devops/docker/hugo.docker.troubleshooting/#hugo-single-stage-dockerfile","text":"We are just removing the second stage in order to take a closer look FROM nginx:alpine as build RUN apk add --update \\ wget ARG HUGO_VERSION = \"0.72.0\" ARG STATIC_PAGE = \"\" RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && \\ tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && \\ mv hugo /usr/bin COPY ./ ${ STATIC_PAGE } /site WORKDIR /site RUN hugo","title":"Hugo Single-Stage Dockerfile"},{"location":"devops/docker/hugo.docker.troubleshooting/#build-image-and-override-multiple-arguments-arg","text":"docker build --build-arg STATIC_PAGE = \"netgtz.gitlab.io\" --build-arg HUGO_VERSION = \"0.83.1\" -t hugo .","title":"Build image and override multiple arguments (ARG)"},{"location":"devops/docker/hugo.docker.troubleshooting/#output","text":":~/lab$ docker build --build-arg STATIC_PAGE = \"netgtz.gitlab.io\" --build-arg HUGO_VERSION = \"0.83.1\" -t hugo . Sending build context to Docker daemon 8 .536MB Step 1 /8 : FROM nginx:alpine as build alpine: Pulling from library/nginx 540db60ca938: Pull complete 0ae30075c5da: Pull complete 9da81141e74e: Pull complete b2e41dd2ded0: Pull complete 7f40e809fb2d: Pull complete 758848c48411: Pull complete Digest: sha256:0f8595aa040ec107821e0409a1dd3f7a5e989501d5c8d5b5ca1f955f33ac81a0 Status: Downloaded newer image for nginx:alpine ---> a6eb2a334a9f Step 2 /8 : RUN apk add --update wget ---> Running in 96e7303147c7 fetch https://dl-cdn.alpinelinux.org/alpine/v3.13/main/x86_64/APKINDEX.tar.gz fetch https://dl-cdn.alpinelinux.org/alpine/v3.13/community/x86_64/APKINDEX.tar.gz ( 1 /3 ) Installing libunistring ( 0 .9.10-r0 ) ( 2 /3 ) Installing libidn2 ( 2 .3.0-r0 ) ( 3 /3 ) Installing wget ( 1 .21.1-r1 ) Executing busybox-1.32.1-r6.trigger OK: 27 MiB in 45 packages Removing intermediate container 96e7303147c7 ---> 8c9b6b201585 Step 3 /8 : ARG HUGO_VERSION = \"0.72.0\" ---> Running in a4c26ace44df Removing intermediate container a4c26ace44df ---> 3ca9889ae589 Step 4 /8 : ARG STATIC_PAGE = \"\" ---> Running in b062a028b5b4 Removing intermediate container b062a028b5b4 ---> 44b5e545b113 Step 5 /8 : RUN wget --quiet \"https://github.com/gohugoio/hugo/releases/download/v ${ HUGO_VERSION } /hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz\" && tar xzf hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && rm -r hugo_ ${ HUGO_VERSION } _Linux-64bit.tar.gz && mv hugo /usr/bin ---> Running in f172e6a54f49 Removing intermediate container f172e6a54f49 ---> 08ffd9933d8e Step 6 /8 : COPY ./ ${ STATIC_PAGE } /site ---> b99bdbfef0e1 Step 7 /8 : WORKDIR /site ---> Running in 55bbd1daf43d Removing intermediate container 55bbd1daf43d ---> cb83bc651786 Step 8 /8 : RUN hugo ---> Running in 19c79b409639 Start building sites \u2026 | EN -------------------+----- Pages | 32 Paginator pages | 0 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 372 ms Removing intermediate container 19c79b409639 ---> 772bcf6d1bf9 Successfully built 772bcf6d1bf9 Successfully tagged hugo:latest","title":"Output"},{"location":"devops/docker/hugo.docker.troubleshooting/#current-images","text":"~/lab$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE hugo latest 772bcf6d1bf9 About a minute ago 81 .4MB nginx alpine a6eb2a334a9f 10 days ago 22 .6MB","title":"Current images"},{"location":"devops/docker/hugo.docker.troubleshooting/#running-a-container-using-the-hugo-image","text":"Using the command '/bin/ash' to keep the container running Exposing container port 80 on local port 80 Passing --rm to delete container after stopping it - no need to do 'docker rm [Container ID]' docker run --rm -p 80 :80 -dit --name hugoapp hugo /bin/ash Attaching to running container docker exec -it hugoapp /bin/ash Rerunning hugo command to generate site and get its Output ~/lab$ docker exec -it hugoapp /bin/ash /site # ls archetypes assets config.toml content i18n layouts public resources static themes /site # hugo Start building sites \u2026 | EN -------------------+----- Pages | 32 Paginator pages | 0 Non-page files | 0 Static files | 13 Processed images | 0 Aliases | 0 Sitemaps | 1 Cleaned | 0 Total in 362 ms Moving hugo public folder content to nginx working directory mv public/* /usr/share/nginx/html/ Running the nginx server /usr/sbin/nginx Nginx Output sh /site # /usr/sbin/nginx 2021/06/04 22:01:54 [notice] 18#18: using the \"epoll\" event method 2021/06/04 22:01:54 [notice] 18#18: nginx/1.21.0 2021/06/04 22:01:54 [notice] 18#18: built by gcc 10.2.1 20201203 (Alpine 10.2.1_pre1) 2021/06/04 22:01:54 [notice] 18#18: OS: Linux 4.15.0-20-generic 2021/06/04 22:01:54 [notice] 18#18: getrlimit(RLIMIT_NOFILE): 1048576:1048576 /site # 2021/06/04 22:01:54 [notice] 19#19: start worker processes 2021/06/04 22:01:54 [notice] 19#19: start worker process 20","title":"Running a container using the hugo image"},{"location":"devops/docker/intro/","text":"Docker Documentation docker is currently the leading devops provider. Hugo Docker Image \u00b6 My netgtz.gitlab.io site has the baseURL as baseURL = \" https://netgtz.gitlab.io/ \". Using this will not render the site correctly... * Requirements ``` config.toml \u00b6 baseURL = \"/\" ```","title":"Introduction"},{"location":"devops/docker/intro/#hugo-docker-image","text":"My netgtz.gitlab.io site has the baseURL as baseURL = \" https://netgtz.gitlab.io/ \". Using this will not render the site correctly... * Requirements ```","title":"Hugo Docker Image"},{"location":"devops/docker/intro/#configtoml","text":"baseURL = \"/\" ```","title":"config.toml"},{"location":"devops/kubernetes/intro/","text":"Kubernetes Documentation kubernetes is currently the leading devops provider. Kubernetes at a Glance \u00b6 What is Kubernetes? Kubernetes is an open source container management and orchestration system which provides built in cloud navite features: * Managing clusters of containers * Providing tools for deploying applications * Auto Scaling applications as and when needed * Managing changes to the existing containerized applications * Helping to optimize the use of underlying hardware beneath your container * Enableing the application component to restart and move across the system as and when needed Kubernetes Architecture and Componets \u00b6 Kubernetes includes multiple components to manage and control the cluster: Backend System Pods root@f8aca9a6c11c:/home/cloud_user# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-584795fc57-qd468 1 /1 Running 0 25m coredns-584795fc57-whf8j 1 /1 Running 0 25m etcd-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m kube-apiserver-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m kube-controller-manager-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 24m kube-flannel-ds-amd64-dk4bm 1 /1 Running 0 10m kube-flannel-ds-amd64-rbz6w 1 /1 Running 0 10m kube-flannel-ds-amd64-xgvnv 1 /1 Running 0 10m kube-proxy-hc6xr 1 /1 Running 0 19m kube-proxy-hlmlk 1 /1 Running 0 25m kube-proxy-wpmhm 1 /1 Running 0 20m kube-scheduler-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m Kube Master Control Plane \u00b6 etcd : provides distrubuted synchronized data storage for the cluster state. Information about the cluster such as pods, nodes, etc are stored here. kube-apiserver : Primary interface for the cluster which is a simple REST based web API. kubectl this API to interact with the cluster. kube-controller-manager : bundles several backend components doing all the behind the scenes work of controlling the cluster. kube-scheduler : determines when to run pods and what nodes to run them on based on deployments or other automation Individual Kube Node Components \u00b6 kubelet : agent used to interact between the kubernetes's API and contanier's runtime. Masters control place communicates to node kubelets which instruct docker to create/run the container. Master and worker nodes have this agent installed kubelet runs as a service root@f8aca9a6c11c:/home/cloud_user# sudo systemctl status kubelet \u25cf kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded ( /lib/systemd/system/kubelet.service ; enabled ; vendor preset: enabled ) Drop-In: /etc/systemd/system/kubelet.service.d \u2514\u250010-kubeadm.conf Active: active ( running ) since Sun 2021 -07-11 13 :41:35 UTC ; 1h 18min ago Docs: https://kubernetes.io/docs/home/ Main PID: 7174 ( kubelet ) Tasks: 17 ( limit: 2312 ) CGroup: /system.slice/kubelet.service \u2514\u25007174 /usr/bin/kubelet --bootstrap-kubeconfig = /etc/kubernetes/bootstrap-kubelet.conf --kubeconfig = /etc/kubernetes/kubelet.conf --config = /var/lib/kubelet/conf Jul 11 13 :56:51 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:51.107949 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason Jul 11 13 :56:55 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : W0711 13 :56:55.713797 7174 cni.go:213 ] Unable to update cni config: No networks found in /etc/cni/net.d Jul 11 13 :56:56 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:56.109215 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason Jul 11 13 :56:59 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:59.901445 7174 reflector.go:126 ] object- \"kube-system\" / \"flannel-token-sxgpr\" : Failed to list *v Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.049225 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.052181 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.052995 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.058499 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : W0711 13 :57:00.714022 7174 cni.go:213 ] Unable to update cni config: No networks found in /etc/cni/net.d Jul 11 13 :57:01 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :57:01.110293 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason r * ****kube-proxy***: each nodes ( master and workers ) needs its own, handles virtual network communication between nodes by adding firewall routing rules when pods are trying to communicate across nodes.","title":"Introduction"},{"location":"devops/kubernetes/intro/#kubernetes-at-a-glance","text":"What is Kubernetes? Kubernetes is an open source container management and orchestration system which provides built in cloud navite features: * Managing clusters of containers * Providing tools for deploying applications * Auto Scaling applications as and when needed * Managing changes to the existing containerized applications * Helping to optimize the use of underlying hardware beneath your container * Enableing the application component to restart and move across the system as and when needed","title":"Kubernetes at a Glance"},{"location":"devops/kubernetes/intro/#kubernetes-architecture-and-componets","text":"Kubernetes includes multiple components to manage and control the cluster: Backend System Pods root@f8aca9a6c11c:/home/cloud_user# kubectl get pods -n kube-system NAME READY STATUS RESTARTS AGE coredns-584795fc57-qd468 1 /1 Running 0 25m coredns-584795fc57-whf8j 1 /1 Running 0 25m etcd-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m kube-apiserver-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m kube-controller-manager-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 24m kube-flannel-ds-amd64-dk4bm 1 /1 Running 0 10m kube-flannel-ds-amd64-rbz6w 1 /1 Running 0 10m kube-flannel-ds-amd64-xgvnv 1 /1 Running 0 10m kube-proxy-hc6xr 1 /1 Running 0 19m kube-proxy-hlmlk 1 /1 Running 0 25m kube-proxy-wpmhm 1 /1 Running 0 20m kube-scheduler-f8aca9a6c11c.mylabserver.com 1 /1 Running 0 25m","title":"Kubernetes Architecture and Componets"},{"location":"devops/kubernetes/intro/#kube-master-control-plane","text":"etcd : provides distrubuted synchronized data storage for the cluster state. Information about the cluster such as pods, nodes, etc are stored here. kube-apiserver : Primary interface for the cluster which is a simple REST based web API. kubectl this API to interact with the cluster. kube-controller-manager : bundles several backend components doing all the behind the scenes work of controlling the cluster. kube-scheduler : determines when to run pods and what nodes to run them on based on deployments or other automation","title":"Kube Master Control Plane"},{"location":"devops/kubernetes/intro/#individual-kube-node-components","text":"kubelet : agent used to interact between the kubernetes's API and contanier's runtime. Masters control place communicates to node kubelets which instruct docker to create/run the container. Master and worker nodes have this agent installed kubelet runs as a service root@f8aca9a6c11c:/home/cloud_user# sudo systemctl status kubelet \u25cf kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded ( /lib/systemd/system/kubelet.service ; enabled ; vendor preset: enabled ) Drop-In: /etc/systemd/system/kubelet.service.d \u2514\u250010-kubeadm.conf Active: active ( running ) since Sun 2021 -07-11 13 :41:35 UTC ; 1h 18min ago Docs: https://kubernetes.io/docs/home/ Main PID: 7174 ( kubelet ) Tasks: 17 ( limit: 2312 ) CGroup: /system.slice/kubelet.service \u2514\u25007174 /usr/bin/kubelet --bootstrap-kubeconfig = /etc/kubernetes/bootstrap-kubelet.conf --kubeconfig = /etc/kubernetes/kubelet.conf --config = /var/lib/kubelet/conf Jul 11 13 :56:51 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:51.107949 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason Jul 11 13 :56:55 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : W0711 13 :56:55.713797 7174 cni.go:213 ] Unable to update cni config: No networks found in /etc/cni/net.d Jul 11 13 :56:56 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:56.109215 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason Jul 11 13 :56:59 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :56:59.901445 7174 reflector.go:126 ] object- \"kube-system\" / \"flannel-token-sxgpr\" : Failed to list *v Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.049225 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.052181 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.052995 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : I0711 13 :57:00.058499 7174 reconciler.go:207 ] operationExecutor.VerifyControllerAttachedVolume started for Jul 11 13 :57:00 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : W0711 13 :57:00.714022 7174 cni.go:213 ] Unable to update cni config: No networks found in /etc/cni/net.d Jul 11 13 :57:01 f8aca9a6c11c.mylabserver.com kubelet [ 7174 ] : E0711 13 :57:01.110293 7174 kubelet.go:2170 ] Container runtime network not ready: NetworkReady = false reason r * ****kube-proxy***: each nodes ( master and workers ) needs its own, handles virtual network communication between nodes by adding firewall routing rules when pods are trying to communicate across nodes.","title":"Individual Kube Node Components"},{"location":"devops/kubernetes/kubernetes-cluster/","text":"Creating a Kubernetes Cluster using Kubeadm \u00b6 Kubeadm is a tool to easily bootstrap a kubernetes cluster with the minimun requirements. Info all nodes includes nodes and master nodes. graph TD subgraph \"Kubernetes Cluster\" A{Master Node} -->|Node1|B(Node One) A{Master Node} -->|Node2|C(Node Two) A{Master Node} -->|Node3|D(Node Three) end Requirements \u00b6 Instance - Ubuntu 18.04 Bionic Beaver LTS Docker Kubeadm, Kubelet, and Kubectl Docker install \u00b6 Install Docker on all nodes including master node: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) \\ stable\" sudo apt-get update sudo apt-get install -y docker-ce = 18 .06.1~ce~3-0~ubuntu sudo apt-mark hold docker-ce if running any other linux flavor use the convenience script provided by docker. ~$ curl -fsSL https://get.docker.com -o get-docker.sh ~$ sudo sh get-docker.sh ``` 3 . Verify that Docker is up and running with: ``` bash ~$ sudo systemctl status docker \u25cf docker.service - Docker Application Container Engine Loaded: loaded ( /lib/systemd/system/docker.service ; enabled ; vendor preset: enabled ) Active: active ( running ) since Fri 2021 -07-16 19 :47:37 UTC ; 3h 49min ago Docs: https://docs.docker.com Main PID: 909 ( dockerd ) Make sure the Docker service status is active (running) ! ~$ sudo docker version Client: Version: 18 .06.1-ce API version: 1 .38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17 :24:51 2018 OS/Arch: linux/amd64 Experimental: false Server: Engine: Version: 18 .06.1-ce API version: 1 .38 ( minimum version 1 .12 ) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17 :23:15 2018 OS/Arch: linux/amd64 Experimental: false Install Kubeadm, Kubelet, and Kubectl on all nodes. \u00b6 kubeadm: cluster bootstrapper. kubelet: creates pods and containers, run on all members of the cluster. kubectl: communicates with cluster's API. Install the Kubernetes components by running this on all nodes: curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet = 1 .14.5-00 kubeadm = 1 .14.5-00 kubectl = 1 .14.5-00 sudo apt-mark hold kubelet kubeadm kubectl Bootstrap the cluster on the Kube master node. \u00b6 On the Kube master node, do this: sudo kubeadm init --pod-network-cidr = 10 .10.0.0/16 That command may take a few minutes to complete. output Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 172 .31.109.72:6443 --token ku77lq.2aupucmcqy3mmjuz \\ --discovery-token-ca-cert-hash sha256:533e64c88c12b7f40b8bf2283ac15dc1b080003ad92c8f53e1742c86e94d6f4c running kubectl as non-root user: mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config optionally export KUBECONFIG = /etc/kubernetes/admin.conf Take note that the kubeadm init command printed a long kubeadm join command to the screen. You will need that kubeadm join command in the next step! Run the following commmand on the Kube master node to verify it is up and running: kubectl version This command should return both a Client Version and a Server Version . Join the two Kube worker nodes to the cluster. \u00b6 Copy the kubeadm join command that was printed by the kubeadm init command earlier, with the token and hash. Run this command on both worker nodes, but make sure you add sudo in front of it: sudo kubeadm join $some_ip :6443 --token $some_token --discovery-token-ca-cert-hash $some_hash Now, on the Kube master node, make sure your nodes joined the cluster successfully: kubectl get nodes Verify that all of your nodes are listed. It will look something like this: NAME STATUS ROLES AGE VERSION ip-10-0-1-101 NotReady master 30s v1.12.2 ip-10-0-1-102 NotReady & lt ; none> 8s v1.12.2 ip-10-0-1-103 NotReady & lt ; none> 5s v1.12.2 Note that the nodes are expected to be in the NotReady state for now. Set up cluster networking with flannel. \u00b6 Turn on iptables bridge calls on all nodes: echo \"net.bridge.bridge-nf-call-iptables=1\" | sudo tee -a /etc/sysctl.conf sudo sysctl -p Next, run this only on the Kube master node: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml Now flannel is installed! Make sure it is working by checking the node status again: kubectl get nodes After a short time, all nodes should be in the Ready state. If they are not all Ready the first time you run kubectl get nodes , wait a few moments and try again. It should look something like this: bash NAME STATUS ROLES AGE VERSION ip-10-0-1-101 Ready master 85s v1.12.2 ip-10-0-1-102 Ready &lt;none> 63s v1.12.2 ip-10-0-1-103 Ready &lt;none> 60s v1.12.2","title":"Kubernetes Cluster"},{"location":"devops/kubernetes/kubernetes-cluster/#creating-a-kubernetes-cluster-using-kubeadm","text":"Kubeadm is a tool to easily bootstrap a kubernetes cluster with the minimun requirements. Info all nodes includes nodes and master nodes. graph TD subgraph \"Kubernetes Cluster\" A{Master Node} -->|Node1|B(Node One) A{Master Node} -->|Node2|C(Node Two) A{Master Node} -->|Node3|D(Node Three) end","title":"Creating a Kubernetes Cluster using Kubeadm"},{"location":"devops/kubernetes/kubernetes-cluster/#requirements","text":"Instance - Ubuntu 18.04 Bionic Beaver LTS Docker Kubeadm, Kubelet, and Kubectl","title":"Requirements"},{"location":"devops/kubernetes/kubernetes-cluster/#docker-install","text":"Install Docker on all nodes including master node: curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $( lsb_release -cs ) \\ stable\" sudo apt-get update sudo apt-get install -y docker-ce = 18 .06.1~ce~3-0~ubuntu sudo apt-mark hold docker-ce if running any other linux flavor use the convenience script provided by docker. ~$ curl -fsSL https://get.docker.com -o get-docker.sh ~$ sudo sh get-docker.sh ``` 3 . Verify that Docker is up and running with: ``` bash ~$ sudo systemctl status docker \u25cf docker.service - Docker Application Container Engine Loaded: loaded ( /lib/systemd/system/docker.service ; enabled ; vendor preset: enabled ) Active: active ( running ) since Fri 2021 -07-16 19 :47:37 UTC ; 3h 49min ago Docs: https://docs.docker.com Main PID: 909 ( dockerd ) Make sure the Docker service status is active (running) ! ~$ sudo docker version Client: Version: 18 .06.1-ce API version: 1 .38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17 :24:51 2018 OS/Arch: linux/amd64 Experimental: false Server: Engine: Version: 18 .06.1-ce API version: 1 .38 ( minimum version 1 .12 ) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17 :23:15 2018 OS/Arch: linux/amd64 Experimental: false","title":"Docker install"},{"location":"devops/kubernetes/kubernetes-cluster/#install-kubeadm-kubelet-and-kubectl-on-all-nodes","text":"kubeadm: cluster bootstrapper. kubelet: creates pods and containers, run on all members of the cluster. kubectl: communicates with cluster's API. Install the Kubernetes components by running this on all nodes: curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF sudo apt-get update sudo apt-get install -y kubelet = 1 .14.5-00 kubeadm = 1 .14.5-00 kubectl = 1 .14.5-00 sudo apt-mark hold kubelet kubeadm kubectl","title":"Install Kubeadm, Kubelet, and Kubectl on all nodes."},{"location":"devops/kubernetes/kubernetes-cluster/#bootstrap-the-cluster-on-the-kube-master-node","text":"On the Kube master node, do this: sudo kubeadm init --pod-network-cidr = 10 .10.0.0/16 That command may take a few minutes to complete. output Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config You should now deploy a pod network to the cluster. Run \"kubectl apply -f [podnetwork].yaml\" with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 172 .31.109.72:6443 --token ku77lq.2aupucmcqy3mmjuz \\ --discovery-token-ca-cert-hash sha256:533e64c88c12b7f40b8bf2283ac15dc1b080003ad92c8f53e1742c86e94d6f4c running kubectl as non-root user: mkdir -p $HOME /.kube sudo cp -i /etc/kubernetes/admin.conf $HOME /.kube/config sudo chown $( id -u ) : $( id -g ) $HOME /.kube/config optionally export KUBECONFIG = /etc/kubernetes/admin.conf Take note that the kubeadm init command printed a long kubeadm join command to the screen. You will need that kubeadm join command in the next step! Run the following commmand on the Kube master node to verify it is up and running: kubectl version This command should return both a Client Version and a Server Version .","title":"Bootstrap the cluster on the Kube master node."},{"location":"devops/kubernetes/kubernetes-cluster/#join-the-two-kube-worker-nodes-to-the-cluster","text":"Copy the kubeadm join command that was printed by the kubeadm init command earlier, with the token and hash. Run this command on both worker nodes, but make sure you add sudo in front of it: sudo kubeadm join $some_ip :6443 --token $some_token --discovery-token-ca-cert-hash $some_hash Now, on the Kube master node, make sure your nodes joined the cluster successfully: kubectl get nodes Verify that all of your nodes are listed. It will look something like this: NAME STATUS ROLES AGE VERSION ip-10-0-1-101 NotReady master 30s v1.12.2 ip-10-0-1-102 NotReady & lt ; none> 8s v1.12.2 ip-10-0-1-103 NotReady & lt ; none> 5s v1.12.2 Note that the nodes are expected to be in the NotReady state for now.","title":"Join the two Kube worker nodes to the cluster."},{"location":"devops/kubernetes/kubernetes-cluster/#set-up-cluster-networking-with-flannel","text":"Turn on iptables bridge calls on all nodes: echo \"net.bridge.bridge-nf-call-iptables=1\" | sudo tee -a /etc/sysctl.conf sudo sysctl -p Next, run this only on the Kube master node: kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml Now flannel is installed! Make sure it is working by checking the node status again: kubectl get nodes After a short time, all nodes should be in the Ready state. If they are not all Ready the first time you run kubectl get nodes , wait a few moments and try again. It should look something like this: bash NAME STATUS ROLES AGE VERSION ip-10-0-1-101 Ready master 85s v1.12.2 ip-10-0-1-102 Ready &lt;none> 63s v1.12.2 ip-10-0-1-103 Ready &lt;none> 60s v1.12.2","title":"Set up cluster networking with flannel."},{"location":"devops/kubernetes/kubernetes-deployments/","text":"Kubernetes Deployments \u00b6 Deployments provide a way to spin up and automate multiple pods by specifying a desired state to be maintained by the cluster. * Scaling the deployment will either create or delete pods in order to meet the number of replicas requested. The deployment can dynamically adjust itself without impacting appliaction. * Rolling Updates : the deployment can be adjusted to a new image version. it will gradually spin up new containers with the new vesrion to replace existing containers. * Self-Healing : if any of pods in the deployment is destroyed, the deployment will create new ones in order to meet desired number of replicas. deployment \u00b6 apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx-app spec: replicas: 2 selector: matchLabels: app: nginx-app template: metadata: labels: app: nginx-app spec: containers: - name: nginx image: nginx:1.20.1 ports: - containerPort: 80 use kubectl create -f <deployment-file.yml> to build deployment. # kubectl create -f ./kube-deployment.yml deployment.apps/nginx-deployment created # kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 2 /2 2 2 9s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-6fb8795c7d-dq9zp 1 /1 Running 0 22s nginx-deployment-6fb8795c7d-r8bwk 1 /1 Running 0 22s the kubectl describe deployment <deployment-name> provides detailed information about the deployment. the event section provides any deployment changes such scaling, self-healing, and rolling-updates # kubectl describe deployment nginx-deployment Name: nginx-deployment Namespace: default CreationTimestamp: Thu, 15 Jul 2021 23 :57:20 +0000 Labels: app = nginx-app Annotations: deployment.kubernetes.io/revision: 1 Selector: app = nginx-app Replicas: 2 desired | 2 updated | 2 total | 2 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25 % max unavailable, 25 % max surge Pod Template: Labels: app = nginx-app Containers: nginx: Image: nginx:1.20.1 Port: 80 /TCP Host Port: 0 /TCP Environment: <none> Mounts: <none> Volumes: <none> Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: <none> NewReplicaSet: nginx-deployment-7d569cb5f5 ( 2 /2 replicas created ) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 16s deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 2 ``` #### Deployment Scaling the deployment will either create or delete pods in order to meet the number of replicas requested. The deployment can dynamically adjust itself without impacting appliaction. ###### Scale up * Edit the ``` deployment.yml ``` file spec: replicas from ``` 2 ``` to ``` 6 ``` . Optionally, we can edit the deployment running-config using ``` kubectl edit deployment.v1.apps/nginx-deployment ``` ``` yml ##omitted sections spec: replicas: 6 * apply changes # kubectl apply -f kube-deployment.yml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply deployment.apps/nginx-deployment configured * Optionally, we can edit the deployment running-config using kubectl edit deployment.v1.apps/nginx-deployment use i to edit and [ESC] followed by :wq! to apply changes we can do it with a single command kubectl scale deployments/nginx-deployment --replicas=6 # kubectl edit deployment.v1.apps/nginx-deployment deployment.apps/nginx-deployment edited * Validating # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-cqdqg 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-h7x79 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-l2pbh 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-wtbsw 0 /1 ContainerCreating 0 2s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-h7x79 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-wtbsw 1 /1 Running 0 4s Scale Down \u00b6 update kubectl edit deployment.v1.apps/nginx-deployment replicas from 6 to 2 # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 0/1 Terminating 0 2m15s nginx-deployment-7d569cb5f5-cqdqg 1/1 Running 0 2m15s nginx-deployment-7d569cb5f5-h7x79 1/1 Running 0 28m nginx-deployment-7d569cb5f5-l2pbh 1/1 Running 0 2m15s nginx-deployment-7d569cb5f5-r2ln4 1/1 Running 0 28m nginx-deployment-7d569cb5f5-wtbsw 0/1 Terminating 0 2m15s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1/1 Running 0 2m20s nginx-deployment-7d569cb5f5-h7x79 1/1 Running 0 28m nginx-deployment-7d569cb5f5-l2pbh 1/1 Running 0 2m20s nginx-deployment-7d569cb5f5-r2ln4 1/1 Running 0 28m Scaling Loggs \u00b6 # kubectl describe deployment nginx-deployment ### ommitted output ### Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 30m deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 2 Normal ScalingReplicaSet 7m12s deployment-controller Scaled down replica set nginx-deployment-7d569cb5f5 to 2 Normal ScalingReplicaSet 3m25s ( x3 over 16m ) deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 6 Normal ScalingReplicaSet 72s ( x2 over 11m ) deployment-controller Scaled down replica set nginx-deployment-7d569cb5f5 to 4 Deployment Self-Healing \u00b6 if any of pods in the deployment is destroyed, the deployment will create new ones in order to meet desired number of replicas # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 8m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 8m nginx-deployment-7d569cb5f5-nbb4w 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 34m # kubectl delete pod nginx-deployment-7d569cb5f5-r2ln4 pod \"nginx-deployment-7d569cb5f5-r2ln4\" deleted # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 8m38s nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 8m38s nginx-deployment-7d569cb5f5-nbb4w 1 /1 Running 0 42s nginx-deployment-7d569cb5f5-tjsnw 1 /1 Running 0 3s the cluster build a new container right after I requested the deletion immediately. I couldnt catch the cluster creating the new container but we can tell by looking at the AGE value. nginx-deployment-7d569cb5f5-tjsnw was created when I deleted nginx-deployment-7d569cb5f5-r2ln4 . Deployment Rolling Updates \u00b6 the deployment can be adjusted to a new image version. it will gradually spin up new containers with the new vesrion to replace existing containers. Upgrading from image: nginx:1.20.1 to nginx=nginx:1.21.1 . The cluster will create new containers with the new image once those containers are running it will terminate the containers running the old image: # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1 /1 Running 0 7s nginx-deployment-5cfcccdb74-lvgq2 0 /1 ContainerCreating 0 2s nginx-deployment-5cfcccdb74-v2k4g 0 /1 ContainerCreating 0 1s nginx-deployment-5cfcccdb74-zn666 1 /1 Running 0 7s nginx-deployment-7d569cb5f5-cqdqg 1 /1 Terminating 0 17m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 17m nginx-deployment-7d569cb5f5-nbb4w 0 /1 Terminating 0 9m29s Conclusion \u00b6 Edittig the running-config vs editing the actual file and apply the changes works the same way.","title":"Kubernetes Deployments"},{"location":"devops/kubernetes/kubernetes-deployments/#kubernetes-deployments","text":"Deployments provide a way to spin up and automate multiple pods by specifying a desired state to be maintained by the cluster. * Scaling the deployment will either create or delete pods in order to meet the number of replicas requested. The deployment can dynamically adjust itself without impacting appliaction. * Rolling Updates : the deployment can be adjusted to a new image version. it will gradually spin up new containers with the new vesrion to replace existing containers. * Self-Healing : if any of pods in the deployment is destroyed, the deployment will create new ones in order to meet desired number of replicas.","title":"Kubernetes Deployments"},{"location":"devops/kubernetes/kubernetes-deployments/#deployment","text":"apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment labels: app: nginx-app spec: replicas: 2 selector: matchLabels: app: nginx-app template: metadata: labels: app: nginx-app spec: containers: - name: nginx image: nginx:1.20.1 ports: - containerPort: 80 use kubectl create -f <deployment-file.yml> to build deployment. # kubectl create -f ./kube-deployment.yml deployment.apps/nginx-deployment created # kubectl get deployment NAME READY UP-TO-DATE AVAILABLE AGE nginx-deployment 2 /2 2 2 9s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-6fb8795c7d-dq9zp 1 /1 Running 0 22s nginx-deployment-6fb8795c7d-r8bwk 1 /1 Running 0 22s the kubectl describe deployment <deployment-name> provides detailed information about the deployment. the event section provides any deployment changes such scaling, self-healing, and rolling-updates # kubectl describe deployment nginx-deployment Name: nginx-deployment Namespace: default CreationTimestamp: Thu, 15 Jul 2021 23 :57:20 +0000 Labels: app = nginx-app Annotations: deployment.kubernetes.io/revision: 1 Selector: app = nginx-app Replicas: 2 desired | 2 updated | 2 total | 2 available | 0 unavailable StrategyType: RollingUpdate MinReadySeconds: 0 RollingUpdateStrategy: 25 % max unavailable, 25 % max surge Pod Template: Labels: app = nginx-app Containers: nginx: Image: nginx:1.20.1 Port: 80 /TCP Host Port: 0 /TCP Environment: <none> Mounts: <none> Volumes: <none> Conditions: Type Status Reason ---- ------ ------ Available True MinimumReplicasAvailable Progressing True NewReplicaSetAvailable OldReplicaSets: <none> NewReplicaSet: nginx-deployment-7d569cb5f5 ( 2 /2 replicas created ) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 16s deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 2 ``` #### Deployment Scaling the deployment will either create or delete pods in order to meet the number of replicas requested. The deployment can dynamically adjust itself without impacting appliaction. ###### Scale up * Edit the ``` deployment.yml ``` file spec: replicas from ``` 2 ``` to ``` 6 ``` . Optionally, we can edit the deployment running-config using ``` kubectl edit deployment.v1.apps/nginx-deployment ``` ``` yml ##omitted sections spec: replicas: 6 * apply changes # kubectl apply -f kube-deployment.yml Warning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply deployment.apps/nginx-deployment configured * Optionally, we can edit the deployment running-config using kubectl edit deployment.v1.apps/nginx-deployment use i to edit and [ESC] followed by :wq! to apply changes we can do it with a single command kubectl scale deployments/nginx-deployment --replicas=6 # kubectl edit deployment.v1.apps/nginx-deployment deployment.apps/nginx-deployment edited * Validating # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-cqdqg 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-h7x79 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-l2pbh 0 /1 ContainerCreating 0 2s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-wtbsw 0 /1 ContainerCreating 0 2s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-h7x79 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 26m nginx-deployment-7d569cb5f5-wtbsw 1 /1 Running 0 4s","title":"deployment"},{"location":"devops/kubernetes/kubernetes-deployments/#scale-down","text":"update kubectl edit deployment.v1.apps/nginx-deployment replicas from 6 to 2 # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-5kc9r 0/1 Terminating 0 2m15s nginx-deployment-7d569cb5f5-cqdqg 1/1 Running 0 2m15s nginx-deployment-7d569cb5f5-h7x79 1/1 Running 0 28m nginx-deployment-7d569cb5f5-l2pbh 1/1 Running 0 2m15s nginx-deployment-7d569cb5f5-r2ln4 1/1 Running 0 28m nginx-deployment-7d569cb5f5-wtbsw 0/1 Terminating 0 2m15s # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1/1 Running 0 2m20s nginx-deployment-7d569cb5f5-h7x79 1/1 Running 0 28m nginx-deployment-7d569cb5f5-l2pbh 1/1 Running 0 2m20s nginx-deployment-7d569cb5f5-r2ln4 1/1 Running 0 28m","title":"Scale Down"},{"location":"devops/kubernetes/kubernetes-deployments/#scaling-loggs","text":"# kubectl describe deployment nginx-deployment ### ommitted output ### Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ScalingReplicaSet 30m deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 2 Normal ScalingReplicaSet 7m12s deployment-controller Scaled down replica set nginx-deployment-7d569cb5f5 to 2 Normal ScalingReplicaSet 3m25s ( x3 over 16m ) deployment-controller Scaled up replica set nginx-deployment-7d569cb5f5 to 6 Normal ScalingReplicaSet 72s ( x2 over 11m ) deployment-controller Scaled down replica set nginx-deployment-7d569cb5f5 to 4","title":"Scaling Loggs"},{"location":"devops/kubernetes/kubernetes-deployments/#deployment-self-healing","text":"if any of pods in the deployment is destroyed, the deployment will create new ones in order to meet desired number of replicas # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 8m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 8m nginx-deployment-7d569cb5f5-nbb4w 1 /1 Running 0 4s nginx-deployment-7d569cb5f5-r2ln4 1 /1 Running 0 34m # kubectl delete pod nginx-deployment-7d569cb5f5-r2ln4 pod \"nginx-deployment-7d569cb5f5-r2ln4\" deleted # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-7d569cb5f5-cqdqg 1 /1 Running 0 8m38s nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 8m38s nginx-deployment-7d569cb5f5-nbb4w 1 /1 Running 0 42s nginx-deployment-7d569cb5f5-tjsnw 1 /1 Running 0 3s the cluster build a new container right after I requested the deletion immediately. I couldnt catch the cluster creating the new container but we can tell by looking at the AGE value. nginx-deployment-7d569cb5f5-tjsnw was created when I deleted nginx-deployment-7d569cb5f5-r2ln4 .","title":"Deployment Self-Healing"},{"location":"devops/kubernetes/kubernetes-deployments/#deployment-rolling-updates","text":"the deployment can be adjusted to a new image version. it will gradually spin up new containers with the new vesrion to replace existing containers. Upgrading from image: nginx:1.20.1 to nginx=nginx:1.21.1 . The cluster will create new containers with the new image once those containers are running it will terminate the containers running the old image: # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1 /1 Running 0 7s nginx-deployment-5cfcccdb74-lvgq2 0 /1 ContainerCreating 0 2s nginx-deployment-5cfcccdb74-v2k4g 0 /1 ContainerCreating 0 1s nginx-deployment-5cfcccdb74-zn666 1 /1 Running 0 7s nginx-deployment-7d569cb5f5-cqdqg 1 /1 Terminating 0 17m nginx-deployment-7d569cb5f5-l2pbh 1 /1 Running 0 17m nginx-deployment-7d569cb5f5-nbb4w 0 /1 Terminating 0 9m29s","title":"Deployment Rolling Updates"},{"location":"devops/kubernetes/kubernetes-deployments/#conclusion","text":"Edittig the running-config vs editing the actual file and apply the changes works the same way.","title":"Conclusion"},{"location":"devops/kubernetes/kubernetes_services/","text":"Kubernetes Services \u00b6 Kubernetes Services provides an abstraction layer to expose pods created by the deployment. Duo to the pod dynamic nature where pods are dynamically destroyed and created by scaling up/down or rolling updates. Services load balance client connections making sure traffic is only routed to active/running pods that are part of the the service graph LR subgraph \"Kubernetes Cluster\" Kubernetes_Service -->B{nginx-deployment} B -->|Pod1|E[nginx-deployment-5cfcccdb74-ck2nj ] B -->|Pod2|E.A[nginx-deployment-5cfcccdb74-lvgq2] B -->|Pod3|E.B[nginx-deployment-5cfcccdb74-v2k4g] B -->|Pod4|E.C[nginx-deployment-5cfcccdb74-zn666] end kind: Service apiVersion: v1 metadata: name: nginx-service spec: selector: app: nginx-app ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30080 type: NodePort validate service is running $# kubectl create -f kube-service.yml service/nginx-service created $# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 5d8h nginx-service NodePort 10 .100.81.26 <none> 80 :32180/TCP 5s $# curl localhost:32180 <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> <style> body { width: 35em ; margin: 0 auto ; font-family: Tahoma, Verdana, Arial, sans-serif ; } </style> </head> <body> <h1>Welcome to nginx!</h1> <p>If you see this page, the nginx web server is successfully installed and working. Further configuration is required.</p> <p>For online documentation and support please refer to <a href = \"http://nginx.org/\" >nginx.org</a>.<br/> Commercial support is available at <a href = \"http://nginx.com/\" >nginx.com</a>.</p> <p><em>Thank you for using nginx.</em></p> </body> </html> Validating \u00b6 kubectl describe svc can provide an Endpoint list of all running pods # kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 5d8h nginx-service NodePort 10 .100.81.26 <none> 80 :32180/TCP 19m root@f8aca9a6c11c:/home/cloud_user# kubectl describe svc nginx-service Name: nginx-service Namespace: default Labels: <none> Annotations: <none> Selector: app = nginx-app Type: NodePort IP: 10 .100.81.26 Port: <unset> 80 /TCP TargetPort: 80 /TCP NodePort: <unset> 32180 /TCP Endpoints: 10 .244.1.20:80,10.244.1.22:80,10.244.2.14:80 + 1 more.. Session Affinity: None External Traffic Policy: Cluster Events: <none> In order to validate only running pods are in the Endpoint list, scale down the deployment: * current state # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-lvgq2 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-v2k4g 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-zn666 1 /1 Running 2 21h use kubectl scale deployments/nginx-deployment --replicas=2 to scale down from 4 to 2 ```bash kubectl scale deployments/nginx-deployment --replicas=2 \u00b6 deployment.extensions/nginx-deployment scaled kubectl get pods \u00b6 NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1/1 Running 2 21h nginx-deployment-5cfcccdb74-lvgq2 1/1 Terminating 2 21h nginx-deployment-5cfcccdb74-v2k4g 1/1 Running 2 21h nginx-deployment-5cfcccdb74-zn666 0/1 Terminating 2 21h kubectl describe svc nginx-service \u00b6 Name: nginx-service Namespace: default Labels: Annotations: Selector: app=nginx-app Type: NodePort IP: 10.100.81.26 Port: 80/TCP TargetPort: 80/TCP NodePort: 32180/TCP Endpoints: 10.244.2.14:80,10.244.2.15:80 Session Affinity: None External Traffic Policy: Cluster Events: ```","title":"Kubernetes Services"},{"location":"devops/kubernetes/kubernetes_services/#kubernetes-services","text":"Kubernetes Services provides an abstraction layer to expose pods created by the deployment. Duo to the pod dynamic nature where pods are dynamically destroyed and created by scaling up/down or rolling updates. Services load balance client connections making sure traffic is only routed to active/running pods that are part of the the service graph LR subgraph \"Kubernetes Cluster\" Kubernetes_Service -->B{nginx-deployment} B -->|Pod1|E[nginx-deployment-5cfcccdb74-ck2nj ] B -->|Pod2|E.A[nginx-deployment-5cfcccdb74-lvgq2] B -->|Pod3|E.B[nginx-deployment-5cfcccdb74-v2k4g] B -->|Pod4|E.C[nginx-deployment-5cfcccdb74-zn666] end kind: Service apiVersion: v1 metadata: name: nginx-service spec: selector: app: nginx-app ports: - protocol: TCP port: 80 targetPort: 80 nodePort: 30080 type: NodePort validate service is running $# kubectl create -f kube-service.yml service/nginx-service created $# kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 5d8h nginx-service NodePort 10 .100.81.26 <none> 80 :32180/TCP 5s $# curl localhost:32180 <!DOCTYPE html> <html> <head> <title>Welcome to nginx!</title> <style> body { width: 35em ; margin: 0 auto ; font-family: Tahoma, Verdana, Arial, sans-serif ; } </style> </head> <body> <h1>Welcome to nginx!</h1> <p>If you see this page, the nginx web server is successfully installed and working. Further configuration is required.</p> <p>For online documentation and support please refer to <a href = \"http://nginx.org/\" >nginx.org</a>.<br/> Commercial support is available at <a href = \"http://nginx.com/\" >nginx.com</a>.</p> <p><em>Thank you for using nginx.</em></p> </body> </html>","title":"Kubernetes Services"},{"location":"devops/kubernetes/kubernetes_services/#validating","text":"kubectl describe svc can provide an Endpoint list of all running pods # kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT ( S ) AGE kubernetes ClusterIP 10 .96.0.1 <none> 443 /TCP 5d8h nginx-service NodePort 10 .100.81.26 <none> 80 :32180/TCP 19m root@f8aca9a6c11c:/home/cloud_user# kubectl describe svc nginx-service Name: nginx-service Namespace: default Labels: <none> Annotations: <none> Selector: app = nginx-app Type: NodePort IP: 10 .100.81.26 Port: <unset> 80 /TCP TargetPort: 80 /TCP NodePort: <unset> 32180 /TCP Endpoints: 10 .244.1.20:80,10.244.1.22:80,10.244.2.14:80 + 1 more.. Session Affinity: None External Traffic Policy: Cluster Events: <none> In order to validate only running pods are in the Endpoint list, scale down the deployment: * current state # kubectl get pods NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-lvgq2 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-v2k4g 1 /1 Running 2 21h nginx-deployment-5cfcccdb74-zn666 1 /1 Running 2 21h use kubectl scale deployments/nginx-deployment --replicas=2 to scale down from 4 to 2 ```bash","title":"Validating"},{"location":"devops/kubernetes/kubernetes_services/#kubectl-scale-deploymentsnginx-deployment-replicas2","text":"deployment.extensions/nginx-deployment scaled","title":"kubectl scale deployments/nginx-deployment --replicas=2"},{"location":"devops/kubernetes/kubernetes_services/#kubectl-get-pods","text":"NAME READY STATUS RESTARTS AGE nginx-deployment-5cfcccdb74-ck2nj 1/1 Running 2 21h nginx-deployment-5cfcccdb74-lvgq2 1/1 Terminating 2 21h nginx-deployment-5cfcccdb74-v2k4g 1/1 Running 2 21h nginx-deployment-5cfcccdb74-zn666 0/1 Terminating 2 21h","title":"kubectl get pods"},{"location":"devops/kubernetes/kubernetes_services/#kubectl-describe-svc-nginx-service","text":"Name: nginx-service Namespace: default Labels: Annotations: Selector: app=nginx-app Type: NodePort IP: 10.100.81.26 Port: 80/TCP TargetPort: 80/TCP NodePort: 32180/TCP Endpoints: 10.244.2.14:80,10.244.2.15:80 Session Affinity: None External Traffic Policy: Cluster Events: ```","title":"kubectl describe svc nginx-service"},{"location":"devops/terraform/intro/","text":"Terraform Documentation terraform is currently the leading devops provider.","title":"Introduction"},{"location":"devops/webservices/environmentvars/","text":"Enabling CGI on Apache2 \u00b6 Install Apache2 \u00b6 sudo apt update -y sudo apt install apache2 -y Enable CGI \u00b6 sudo ln -s /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/ sudo systemctl restart apache2 HTTP Envelop Scripts \u00b6 - cd /usr/lib/cgi-bin/ - nano http-env Perl Python #!/usr/bin/perl print \"Content-type: text/html \\n\\n \" ; print \"<pre> \\n \" ; foreach $ key ( sort keys ( % ENV )) { print \"$key = $ENV{$key}<p>\" ; } print \"</pre> \\n \" ; #!/usr/bin/python3 import os def main (): print ( \"Content-type:text/html \\r\\n\\r\\n \" ) for var in sorted ( os . environ . keys ()): print ( ' %s = %s </br/>' % ( var , os . environ [ var ])) return 0 if __name__ == '__main__' : main () Make http-env exectuable chmod +x /usr/lib/cgi-bin/http-env Bash Script \u00b6 set executable permissions sudo chmod +x http-env.sh ./http-env.sh http-env.sh \u00b6 ```python echo \" ### Apache2 - Install Apache ### \" sudo apt update -y sudo apt install apache2 -y echo \" ### Apache2 - Enable CGI ### \" sudo ln -s /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/ sudo systemctl restart apache2 echo \" ### Apache2 - Create HTTP-ENV Script ### \" cat < /usr/lib/cgi-bin/http-env !/usr/bin/python3 \u00b6 import os def main(): print(\"Content-type:text/html\\r\\n\\r\\n\") for var in sorted ( os . environ . keys ()) : print ( '%s = %s</br/>' % ( var , os . environ [ var ] )) return 0 if name == ' main ': main() EOT echo \" ### Apache2 - Set Permissions on HTTP-ENV Script ### \" sudo chmod 755 /usr/lib/cgi-bin/http-env echo \" ### Apache2 - Verification ### \" verification= \\((curl http://127.0.0.1/cgi-bin/http-env) echo \"\\) verification\" echo","title":"Apache Environment Variables"},{"location":"devops/webservices/environmentvars/#enabling-cgi-on-apache2","text":"","title":"Enabling CGI on Apache2"},{"location":"devops/webservices/environmentvars/#install-apache2","text":"sudo apt update -y sudo apt install apache2 -y","title":"Install Apache2"},{"location":"devops/webservices/environmentvars/#enable-cgi","text":"sudo ln -s /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/ sudo systemctl restart apache2","title":"Enable CGI"},{"location":"devops/webservices/environmentvars/#http-envelop-scripts","text":"- cd /usr/lib/cgi-bin/ - nano http-env Perl Python #!/usr/bin/perl print \"Content-type: text/html \\n\\n \" ; print \"<pre> \\n \" ; foreach $ key ( sort keys ( % ENV )) { print \"$key = $ENV{$key}<p>\" ; } print \"</pre> \\n \" ; #!/usr/bin/python3 import os def main (): print ( \"Content-type:text/html \\r\\n\\r\\n \" ) for var in sorted ( os . environ . keys ()): print ( ' %s = %s </br/>' % ( var , os . environ [ var ])) return 0 if __name__ == '__main__' : main () Make http-env exectuable chmod +x /usr/lib/cgi-bin/http-env","title":"HTTP Envelop Scripts"},{"location":"devops/webservices/environmentvars/#bash-script","text":"set executable permissions sudo chmod +x http-env.sh ./http-env.sh","title":"Bash Script"},{"location":"devops/webservices/environmentvars/#http-envsh","text":"```python echo \" ### Apache2 - Install Apache ### \" sudo apt update -y sudo apt install apache2 -y echo \" ### Apache2 - Enable CGI ### \" sudo ln -s /etc/apache2/mods-available/cgi.load /etc/apache2/mods-enabled/ sudo systemctl restart apache2 echo \" ### Apache2 - Create HTTP-ENV Script ### \" cat < /usr/lib/cgi-bin/http-env","title":"http-env.sh"},{"location":"devops/webservices/environmentvars/#usrbinpython3","text":"import os def main(): print(\"Content-type:text/html\\r\\n\\r\\n\") for var in sorted ( os . environ . keys ()) : print ( '%s = %s</br/>' % ( var , os . environ [ var ] )) return 0 if name == ' main ': main() EOT echo \" ### Apache2 - Set Permissions on HTTP-ENV Script ### \" sudo chmod 755 /usr/lib/cgi-bin/http-env echo \" ### Apache2 - Verification ### \" verification= \\((curl http://127.0.0.1/cgi-bin/http-env) echo \"\\) verification\" echo","title":"!/usr/bin/python3"},{"location":"devops/webservices/http-server-with-dynamic-content/","text":"Apache HTTPD CGI \u00b6 Apache is an open-source HTTP server (httpd) that has been around since 1995. The HTTPD CGI (Common Gateway Interface) module provides a method to display dynamic content on web sites using scripts written in any language such as python, perl or bash. https://httpd.apache.org/ Python CGI module The CGI Module can be use to evaluate and process user input submitted through an HTML or javascript function() using the FieldStorage class. The FieldStorage supports indexed Python dictionary, standard dictionary method keys() and the built-in function len(). Form fields containing empty strings are ignored and do not appear in the dictionary; to keep such values, provide a true value for the optional keep_blank_values keyword parameter when creating the FieldStorage instance. # create key/value pairs form fields passed by javascript/html form = cgi . FieldStorage () form_vars = {} for key in form . keys (): form_vars [ key ] = form [ key ] . value Building an Apache-CGI Docker Image using a Dockerfile \u00b6 Docker is virtualization tool used to create lightweight, portable images and containers. Docker images are self-contained, meaning they dont have any dependencies on the uderlaying OS. As long as you have docker installed, you'll be able to build a container with any docker image. Instructions \u00b6 There are many prebuild httpd-cgi docker images out there(Docker Hub). However I took a few for a test drive and noticed they didnt have what I needed. In order to address some of these limitations, I had two options: Build an image on top of those prebuilt images or build one from scratch. I decided to build one from scratch in order to fully customize it to my needs. Some of the packages are for future use such as requests and boto3. Alpine Base image \u00b6 Alpine Linux is a 3MB lightweight Linux Image with a large selection of packages it is package manager apk. https://alpinelinux.org/about/ Software requirements \u00b6 These software requirements are specific to my webform needs. I use Python3 CGI to collect submitted form key,values, Jinja2 to generate dynamic HTML pages, request to make Rest API calls, and boto3 to directly make use of AWS resources. Nano is a plain and simple text editor. Software Description apache2 HTTP Server python3 CGI Script prefered programing language pip3 Used to install other python modules jinja2 Used to HTML render templates request used to make HTTP GET/POST calls to Rest APIs boto3 Used to interact with AWS Resources nano Simple text editor Enable CGI by Modifying HTTPD Config - httpd.config \u00b6 Since I dont spend too much time doing web development work. I try to avoid making extensive changes to the default httpd.config file in order to avoid unexpected behavior. ## omitted some not so relevant items ##** Enabled CGI Module **## LoadModule cgi_module modules/mod_cgi.so ##** send logs to stdout - docker logs **## CustomLog /proc/self/fd/1 format ##** Avoids attempting to invoke directoy as script **## Alias \"/\" \"/var/www/localhost/cgi-bin/\" ##** only runs cgi,pl,py as scripts **## AddHandler cgi-script cgi pl py sh Options ExecCGI Dockerfile \u00b6 A Dockerfile is a text document that contains all the commands to assemble an image. The docker build command executes the command-line instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image(if necessary) before finally outputting the new image ID. If necessary, the image can by modified by editing the Dockerfile and rerunning the docker build command using the same tag provided during the initial built. ###--------------------START-------------------------------------# ################################################################ # httpd:Alpine # Features: CGI, Python3 - Jinja2, Requests, Boto3 ################################################################ # Base Image - Official Alpine FROM alpine:latest LABEL vendor = \"Gtz4All\" LABEL maintainer = \"netgtz\" # Upgrade existing packages in the base image RUN apk --no-cache upgrade # Install apache from packages with out caching install files RUN apk add --update --no-cache nano apache2 python3 && ln -sf python3 /usr/bin/python RUN python3 -m ensurepip RUN pip3 install --no-cache --upgrade pip setuptools jinja2 requests boto3 # backup httpd.conf RUN mv /etc/apache2/httpd.conf /etc/apache2/httpd.conf.bk # Copy custom files COPY httpd.conf /etc/apache2/httpd.conf COPY cgi-bin/ /var/www/localhost/cgi-bin # Open port for httpd access EXPOSE 80 # Run httpd FOREGROUND in the background(-D option) CMD [ \"-D\" , \"FOREGROUND\" ] # Start httpd ENTRYPOINT [ \"/usr/sbin/httpd\" ] ###--------------------END-------------------------------------# Building the docker image \u00b6 Image Tags - you can create multiple tags for the same docker image, they will show up in 'docker images'. Since they are just that, tags, they are not consuming any additional disk space. Options Description -t image tag name -f custom Dockerfile name . Default Dockerfile name docker build -t custom-httpd-cgi . Docker Image Built Summary \u00b6 The Custom Dockerfile pulled the latest alpine image and installed apache2, python3, pip3, jinja2, requests, boto3 and nano. It renamed the original httpd.config file and copied the custom version. Final image size - 150MB . Running The Docker Container \u00b6 These are some of the commonly options used when working with containers. Options|Description --|-- -d|deattach -i|interactive -t|terminal -p|portmapping [local-port]:[container-port] --name|custom name --rm|Clean up (--rm) removes container after stopping it run container in deattach mode \u00b6 This command runs the container in deattached mode, mapping local port 8080 to container port 80 docker run -d --name webserver -p 8080 :80 custom-httpd-cgi * Verify image is running $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4ca72abac592 custom-httpd-cgi \"/usr/sbin/httpd -D \u2026\" About a minute ago Up About a minute 0 .0.0.0:8080->80/tcp, :::8080->80/tcp webserver * Verify webserver is running Output came from /cgi-bin/index.html $ curl localhost:8080 <!DOCTYPE html> <html> <head> <title>Gtz4All</title> </head> <body> <h1><center>Welcome to Gtz4All Demo Page</center></h1> <p><center>To learn more, please visit <a href = \"https://netgtz.gitlab.io/\" >Gtz4All Blog</center></a></p> </body> </html> Environment Variables $ curl localhost:8080/show-env.py CONTEXT_DOCUMENT_ROOT = /var/www/localhost/cgi-bin/</br/> CONTEXT_PREFIX = /</br/> DOCUMENT_ROOT = /var/www/localhost/htdocs</br/> GATEWAY_INTERFACE = CGI/1.1</br/> HTTP_ACCEPT = */*</br/> HTTP_HOST = localhost:8080</br/> HTTP_USER_AGENT = curl/7.58.0</br/> PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</br/> QUERY_STRING = </br/> REMOTE_ADDR = 172 .17.0.1</br/> REMOTE_PORT = 49684 </br/> REQUEST_METHOD = GET</br/> REQUEST_SCHEME = http</br/> REQUEST_URI = /show-env.py</br/> SCRIPT_FILENAME = /var/www/localhost/cgi-bin/show-env.py</br/> SCRIPT_NAME = /show-env.py</br/> SERVER_ADDR = 172 .17.0.2</br/> SERVER_ADMIN = you@example.com</br/> SERVER_NAME = localhost</br/> SERVER_PORT = 8080 </br/> SERVER_PROTOCOL = HTTP/1.1</br/> SERVER_SIGNATURE = <address>Apache/2.4.48 ( Unix ) Server at localhost Port 8080 </address> </br/> SERVER_SOFTWARE = Apache/2.4.48 ( Unix ) </br/> Attach to Container terminal Every image has its own shell terminal - ubuntu = /bin/bash, Alpine = /bin/sh docker exec -it webserver /bin/sh Mounting webservices folder \u00b6 This folder contains a sample webform used as a base to provision/build/deploy resources. It makes use of Javascript,Jinja templates, and CGI. Mounting folder keeps all files changes local [local-folder]:[container-folder] [container-name] map local folder to container's cgi-bin folder \u00b6 docker run -d -p 8080:80 -v $(pwd)/webservices:/var/www/localhost/cgi-bin/webservices --name webserver custom-httpd-cgi registry.gitlab.com \u00b6 Pushing image to registry.gitlab.com \u00b6 Login to Docker registry docker login registry.gitlab.com --username netgtz Current Image - Rename to Standard docker rename custom-httpd-cgi registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi Build Docker Image docker build -t registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi . Push Docker Image docker push registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi Pull image from registry.gitlab.com \u00b6 Login to Docker registry docker login registry.gitlab.com --username netgtz Pull Image docker pull registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi","title":"HTTP Server with Dynamic Content"},{"location":"devops/webservices/http-server-with-dynamic-content/#apache-httpd-cgi","text":"Apache is an open-source HTTP server (httpd) that has been around since 1995. The HTTPD CGI (Common Gateway Interface) module provides a method to display dynamic content on web sites using scripts written in any language such as python, perl or bash. https://httpd.apache.org/ Python CGI module The CGI Module can be use to evaluate and process user input submitted through an HTML or javascript function() using the FieldStorage class. The FieldStorage supports indexed Python dictionary, standard dictionary method keys() and the built-in function len(). Form fields containing empty strings are ignored and do not appear in the dictionary; to keep such values, provide a true value for the optional keep_blank_values keyword parameter when creating the FieldStorage instance. # create key/value pairs form fields passed by javascript/html form = cgi . FieldStorage () form_vars = {} for key in form . keys (): form_vars [ key ] = form [ key ] . value","title":"Apache HTTPD CGI"},{"location":"devops/webservices/http-server-with-dynamic-content/#building-an-apache-cgi-docker-image-using-a-dockerfile","text":"Docker is virtualization tool used to create lightweight, portable images and containers. Docker images are self-contained, meaning they dont have any dependencies on the uderlaying OS. As long as you have docker installed, you'll be able to build a container with any docker image.","title":"Building an Apache-CGI Docker Image using a Dockerfile"},{"location":"devops/webservices/http-server-with-dynamic-content/#instructions","text":"There are many prebuild httpd-cgi docker images out there(Docker Hub). However I took a few for a test drive and noticed they didnt have what I needed. In order to address some of these limitations, I had two options: Build an image on top of those prebuilt images or build one from scratch. I decided to build one from scratch in order to fully customize it to my needs. Some of the packages are for future use such as requests and boto3.","title":"Instructions"},{"location":"devops/webservices/http-server-with-dynamic-content/#alpine-base-image","text":"Alpine Linux is a 3MB lightweight Linux Image with a large selection of packages it is package manager apk. https://alpinelinux.org/about/","title":"Alpine Base image"},{"location":"devops/webservices/http-server-with-dynamic-content/#software-requirements","text":"These software requirements are specific to my webform needs. I use Python3 CGI to collect submitted form key,values, Jinja2 to generate dynamic HTML pages, request to make Rest API calls, and boto3 to directly make use of AWS resources. Nano is a plain and simple text editor. Software Description apache2 HTTP Server python3 CGI Script prefered programing language pip3 Used to install other python modules jinja2 Used to HTML render templates request used to make HTTP GET/POST calls to Rest APIs boto3 Used to interact with AWS Resources nano Simple text editor","title":"Software requirements"},{"location":"devops/webservices/http-server-with-dynamic-content/#enable-cgi-by-modifying-httpd-config-httpdconfig","text":"Since I dont spend too much time doing web development work. I try to avoid making extensive changes to the default httpd.config file in order to avoid unexpected behavior. ## omitted some not so relevant items ##** Enabled CGI Module **## LoadModule cgi_module modules/mod_cgi.so ##** send logs to stdout - docker logs **## CustomLog /proc/self/fd/1 format ##** Avoids attempting to invoke directoy as script **## Alias \"/\" \"/var/www/localhost/cgi-bin/\" ##** only runs cgi,pl,py as scripts **## AddHandler cgi-script cgi pl py sh Options ExecCGI","title":"Enable CGI by Modifying HTTPD Config - httpd.config"},{"location":"devops/webservices/http-server-with-dynamic-content/#dockerfile","text":"A Dockerfile is a text document that contains all the commands to assemble an image. The docker build command executes the command-line instructions in the Dockerfile one-by-one, committing the result of each instruction to a new image(if necessary) before finally outputting the new image ID. If necessary, the image can by modified by editing the Dockerfile and rerunning the docker build command using the same tag provided during the initial built. ###--------------------START-------------------------------------# ################################################################ # httpd:Alpine # Features: CGI, Python3 - Jinja2, Requests, Boto3 ################################################################ # Base Image - Official Alpine FROM alpine:latest LABEL vendor = \"Gtz4All\" LABEL maintainer = \"netgtz\" # Upgrade existing packages in the base image RUN apk --no-cache upgrade # Install apache from packages with out caching install files RUN apk add --update --no-cache nano apache2 python3 && ln -sf python3 /usr/bin/python RUN python3 -m ensurepip RUN pip3 install --no-cache --upgrade pip setuptools jinja2 requests boto3 # backup httpd.conf RUN mv /etc/apache2/httpd.conf /etc/apache2/httpd.conf.bk # Copy custom files COPY httpd.conf /etc/apache2/httpd.conf COPY cgi-bin/ /var/www/localhost/cgi-bin # Open port for httpd access EXPOSE 80 # Run httpd FOREGROUND in the background(-D option) CMD [ \"-D\" , \"FOREGROUND\" ] # Start httpd ENTRYPOINT [ \"/usr/sbin/httpd\" ] ###--------------------END-------------------------------------#","title":"Dockerfile"},{"location":"devops/webservices/http-server-with-dynamic-content/#building-the-docker-image","text":"Image Tags - you can create multiple tags for the same docker image, they will show up in 'docker images'. Since they are just that, tags, they are not consuming any additional disk space. Options Description -t image tag name -f custom Dockerfile name . Default Dockerfile name docker build -t custom-httpd-cgi .","title":"Building the docker image"},{"location":"devops/webservices/http-server-with-dynamic-content/#docker-image-built-summary","text":"The Custom Dockerfile pulled the latest alpine image and installed apache2, python3, pip3, jinja2, requests, boto3 and nano. It renamed the original httpd.config file and copied the custom version. Final image size - 150MB .","title":"Docker Image Built Summary"},{"location":"devops/webservices/http-server-with-dynamic-content/#running-the-docker-container","text":"These are some of the commonly options used when working with containers. Options|Description --|-- -d|deattach -i|interactive -t|terminal -p|portmapping [local-port]:[container-port] --name|custom name --rm|Clean up (--rm) removes container after stopping it","title":"Running The Docker Container"},{"location":"devops/webservices/http-server-with-dynamic-content/#run-container-in-deattach-mode","text":"This command runs the container in deattached mode, mapping local port 8080 to container port 80 docker run -d --name webserver -p 8080 :80 custom-httpd-cgi * Verify image is running $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4ca72abac592 custom-httpd-cgi \"/usr/sbin/httpd -D \u2026\" About a minute ago Up About a minute 0 .0.0.0:8080->80/tcp, :::8080->80/tcp webserver * Verify webserver is running Output came from /cgi-bin/index.html $ curl localhost:8080 <!DOCTYPE html> <html> <head> <title>Gtz4All</title> </head> <body> <h1><center>Welcome to Gtz4All Demo Page</center></h1> <p><center>To learn more, please visit <a href = \"https://netgtz.gitlab.io/\" >Gtz4All Blog</center></a></p> </body> </html> Environment Variables $ curl localhost:8080/show-env.py CONTEXT_DOCUMENT_ROOT = /var/www/localhost/cgi-bin/</br/> CONTEXT_PREFIX = /</br/> DOCUMENT_ROOT = /var/www/localhost/htdocs</br/> GATEWAY_INTERFACE = CGI/1.1</br/> HTTP_ACCEPT = */*</br/> HTTP_HOST = localhost:8080</br/> HTTP_USER_AGENT = curl/7.58.0</br/> PATH = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin</br/> QUERY_STRING = </br/> REMOTE_ADDR = 172 .17.0.1</br/> REMOTE_PORT = 49684 </br/> REQUEST_METHOD = GET</br/> REQUEST_SCHEME = http</br/> REQUEST_URI = /show-env.py</br/> SCRIPT_FILENAME = /var/www/localhost/cgi-bin/show-env.py</br/> SCRIPT_NAME = /show-env.py</br/> SERVER_ADDR = 172 .17.0.2</br/> SERVER_ADMIN = you@example.com</br/> SERVER_NAME = localhost</br/> SERVER_PORT = 8080 </br/> SERVER_PROTOCOL = HTTP/1.1</br/> SERVER_SIGNATURE = <address>Apache/2.4.48 ( Unix ) Server at localhost Port 8080 </address> </br/> SERVER_SOFTWARE = Apache/2.4.48 ( Unix ) </br/> Attach to Container terminal Every image has its own shell terminal - ubuntu = /bin/bash, Alpine = /bin/sh docker exec -it webserver /bin/sh","title":"run container in deattach mode"},{"location":"devops/webservices/http-server-with-dynamic-content/#mounting-webservices-folder","text":"This folder contains a sample webform used as a base to provision/build/deploy resources. It makes use of Javascript,Jinja templates, and CGI. Mounting folder keeps all files changes local [local-folder]:[container-folder] [container-name]","title":"Mounting webservices folder"},{"location":"devops/webservices/http-server-with-dynamic-content/#map-local-folder-to-containers-cgi-bin-folder","text":"docker run -d -p 8080:80 -v $(pwd)/webservices:/var/www/localhost/cgi-bin/webservices --name webserver custom-httpd-cgi","title":"map local folder to container's cgi-bin folder"},{"location":"devops/webservices/http-server-with-dynamic-content/#registrygitlabcom","text":"","title":"registry.gitlab.com"},{"location":"devops/webservices/http-server-with-dynamic-content/#pushing-image-to-registrygitlabcom","text":"Login to Docker registry docker login registry.gitlab.com --username netgtz Current Image - Rename to Standard docker rename custom-httpd-cgi registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi Build Docker Image docker build -t registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi . Push Docker Image docker push registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi","title":"Pushing image to registry.gitlab.com"},{"location":"devops/webservices/http-server-with-dynamic-content/#pull-image-from-registrygitlabcom","text":"Login to Docker registry docker login registry.gitlab.com --username netgtz Pull Image docker pull registry.gitlab.com/netgtz/httpd-cgi/custom-httpd-cgi","title":"Pull image from registry.gitlab.com"},{"location":"devops/webservices/intro/","text":"Web Services Documentation python is currently the leading devops provider.","title":"Introduction"},{"location":"networking/intro/","text":"cisco Documentation cisco is currently the leading networking provider. arista Documentation arista is currently the leading networking provider.","title":"Introduction"},{"location":"networking/arista/intro/","text":"arista Documentation arista is currently the leading networking provider.","title":"Introduction"},{"location":"networking/cisco/intro/","text":"cisco Documentation cisco is currently the leading networking provider.","title":"Introduction"},{"location":"tips-tricks/intro/","text":"Reference \u00b6 The purpose of this section is to provide code snippets, tips and solution to simple issues. Git Commands git add -A .; git commit -m \"new content\"; git push -u origin master Side by Side Code Block The usual Markdown Cheatsheet does not cover some of the more advanced Markdown tricks, but here is one. You can combine verbatim HTML with your Markdown. This is particularly useful for tables. Notice that with empty separating lines we can use Markdown inside HTML: Json 1 Json 2 { \"id\" : 5 , \"username\" : \"mary\" , \"email\" : \"mary@example.com\" , \"order_id\" : \"f7177da\" } { \"id\" : 5 , \"username\" : \"mary\" , \"email\" : \"mary@example.com\" , \"order_id\" : \"f7177da\" } Mermaid Sample Code Vertical Horizonal graph TD; subgraph \"Device Connectivity\" 1(DISTRT1)---|Gi1/12|3(ACCSW1); 2(DISTRT2)---|Gi1/12|3(ACCSW1); 1(DISTRT1)---|Gi1/13|4(ACCSW2); 2(DISTRT2)---|Gi1/13|4(ACCSW2); 1(DISTRT1)---|Gi1/14|5(ACCSW3); 2(DISTRT2)---|Gi1/14|5(ACCSW3); 1(DISTRT1)---|Gi1/15|6(ACCSW4); 2(DISTRT2)---|Gi1/15|6(ACCSW4); 1(DISTRT1)---|Gi1/16|7(ACCSW5); 2(DISTRT2)---|Gi1/16|7(ACCSW5); 1(DISTRT1)---|Gi1/17|8(ACCSW6); 2(DISTRT2)---|Gi1/17|8(ACCSW6); end graph LR subgraph \"Requester Pre Provision Trigger URL\" Requester-URL \u2192|Provision|B{CI/CD Complete Provisioning} B \u2192|Switch Variables|E[Pull Switch Vars from Archive] B \u2192|Validate Switch|E.A[Pull switch variables] B \u2192|Validate Switch Code|E.B[Build Code Standard Variables] B \u2192|Email Notification|E.C[Generate Requester Token/Email] E.C \u2192|Requester Email|1[Email w/Token, Switch OSPF/Initial Cfg] end Manage Docker containers/images List All Container IDs \u00b6 ## list all containes docker ps -a ## list all containers IDs ( -q = IDs) docker ps -aq Stop All Running Containers \u00b6 ## list all running containers docker ps ### stop all containers docker stop $(docker ps -aq) Remove All Containers \u00b6 ## Remove all stopped containers docker rm $(docker ps -aq) Remove All Images \u00b6 docker rmi $(docker images -q) Connect to Pod Shell Testing \u00b6 cloud_user# kubectl exec --stdin --tty nginx-deployment-5cfcccdb74-ck2nj -- /bin/bash root@nginx-deployment-5cfcccdb74-ck2nj:/# hugo server -D --bind=192.168.1.55 --baseURL= http://192.168.1.55 grep -RiIl '25000' | xargs sed -i 's/25000/1000/g' grep -rnw 'CUST01/' -e '25000' echo theme = \\\"ananke\\\" >> config.toml","title":"Tips and Tricks"},{"location":"tips-tricks/intro/#reference","text":"The purpose of this section is to provide code snippets, tips and solution to simple issues. Git Commands git add -A .; git commit -m \"new content\"; git push -u origin master Side by Side Code Block The usual Markdown Cheatsheet does not cover some of the more advanced Markdown tricks, but here is one. You can combine verbatim HTML with your Markdown. This is particularly useful for tables. Notice that with empty separating lines we can use Markdown inside HTML: Json 1 Json 2 { \"id\" : 5 , \"username\" : \"mary\" , \"email\" : \"mary@example.com\" , \"order_id\" : \"f7177da\" } { \"id\" : 5 , \"username\" : \"mary\" , \"email\" : \"mary@example.com\" , \"order_id\" : \"f7177da\" } Mermaid Sample Code Vertical Horizonal graph TD; subgraph \"Device Connectivity\" 1(DISTRT1)---|Gi1/12|3(ACCSW1); 2(DISTRT2)---|Gi1/12|3(ACCSW1); 1(DISTRT1)---|Gi1/13|4(ACCSW2); 2(DISTRT2)---|Gi1/13|4(ACCSW2); 1(DISTRT1)---|Gi1/14|5(ACCSW3); 2(DISTRT2)---|Gi1/14|5(ACCSW3); 1(DISTRT1)---|Gi1/15|6(ACCSW4); 2(DISTRT2)---|Gi1/15|6(ACCSW4); 1(DISTRT1)---|Gi1/16|7(ACCSW5); 2(DISTRT2)---|Gi1/16|7(ACCSW5); 1(DISTRT1)---|Gi1/17|8(ACCSW6); 2(DISTRT2)---|Gi1/17|8(ACCSW6); end graph LR subgraph \"Requester Pre Provision Trigger URL\" Requester-URL \u2192|Provision|B{CI/CD Complete Provisioning} B \u2192|Switch Variables|E[Pull Switch Vars from Archive] B \u2192|Validate Switch|E.A[Pull switch variables] B \u2192|Validate Switch Code|E.B[Build Code Standard Variables] B \u2192|Email Notification|E.C[Generate Requester Token/Email] E.C \u2192|Requester Email|1[Email w/Token, Switch OSPF/Initial Cfg] end Manage Docker containers/images","title":"Reference"},{"location":"tips-tricks/intro/#list-all-container-ids","text":"## list all containes docker ps -a ## list all containers IDs ( -q = IDs) docker ps -aq","title":"List All Container IDs"},{"location":"tips-tricks/intro/#stop-all-running-containers","text":"## list all running containers docker ps ### stop all containers docker stop $(docker ps -aq)","title":"Stop All Running Containers"},{"location":"tips-tricks/intro/#remove-all-containers","text":"## Remove all stopped containers docker rm $(docker ps -aq)","title":"Remove All Containers"},{"location":"tips-tricks/intro/#remove-all-images","text":"docker rmi $(docker images -q) Connect to Pod Shell","title":"Remove All Images"},{"location":"tips-tricks/intro/#testing","text":"cloud_user# kubectl exec --stdin --tty nginx-deployment-5cfcccdb74-ck2nj -- /bin/bash root@nginx-deployment-5cfcccdb74-ck2nj:/# hugo server -D --bind=192.168.1.55 --baseURL= http://192.168.1.55 grep -RiIl '25000' | xargs sed -i 's/25000/1000/g' grep -rnw 'CUST01/' -e '25000' echo theme = \\\"ananke\\\" >> config.toml","title":"Testing"}]}